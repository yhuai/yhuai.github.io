<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>pyspark.sql</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.0.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="pyspark-module.html">Package&nbsp;pyspark</a> ::
        Module&nbsp;sql
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="pyspark.sql-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="pyspark.sql-module.html">Module pyspark.sql</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">   1</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L2"></a><tt class="py-lineno">   2</tt>  <tt class="py-line"><tt class="py-comment"># Licensed to the Apache Software Foundation (ASF) under one or more</tt> </tt>
<a name="L3"></a><tt class="py-lineno">   3</tt>  <tt class="py-line"><tt class="py-comment"># contributor license agreements.  See the NOTICE file distributed with</tt> </tt>
<a name="L4"></a><tt class="py-lineno">   4</tt>  <tt class="py-line"><tt class="py-comment"># this work for additional information regarding copyright ownership.</tt> </tt>
<a name="L5"></a><tt class="py-lineno">   5</tt>  <tt class="py-line"><tt class="py-comment"># The ASF licenses this file to You under the Apache License, Version 2.0</tt> </tt>
<a name="L6"></a><tt class="py-lineno">   6</tt>  <tt class="py-line"><tt class="py-comment"># (the "License"); you may not use this file except in compliance with</tt> </tt>
<a name="L7"></a><tt class="py-lineno">   7</tt>  <tt class="py-line"><tt class="py-comment"># the License.  You may obtain a copy of the License at</tt> </tt>
<a name="L8"></a><tt class="py-lineno">   8</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L9"></a><tt class="py-lineno">   9</tt>  <tt class="py-line"><tt class="py-comment">#    http://www.apache.org/licenses/LICENSE-2.0</tt> </tt>
<a name="L10"></a><tt class="py-lineno">  10</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L11"></a><tt class="py-lineno">  11</tt>  <tt class="py-line"><tt class="py-comment"># Unless required by applicable law or agreed to in writing, software</tt> </tt>
<a name="L12"></a><tt class="py-lineno">  12</tt>  <tt class="py-line"><tt class="py-comment"># distributed under the License is distributed on an "AS IS" BASIS,</tt> </tt>
<a name="L13"></a><tt class="py-lineno">  13</tt>  <tt class="py-line"><tt class="py-comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</tt> </tt>
<a name="L14"></a><tt class="py-lineno">  14</tt>  <tt class="py-line"><tt class="py-comment"># See the License for the specific language governing permissions and</tt> </tt>
<a name="L15"></a><tt class="py-lineno">  15</tt>  <tt class="py-line"><tt class="py-comment"># limitations under the License.</tt> </tt>
<a name="L16"></a><tt class="py-lineno">  16</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L17"></a><tt class="py-lineno">  17</tt>  <tt class="py-line"> </tt>
<a name="L18"></a><tt class="py-lineno">  18</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-0" class="py-name" targets="Package pyspark=pyspark-module.html"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-0', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-1" class="py-name" targets="Module pyspark.rdd=pyspark.rdd-module.html"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-1', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-keyword">import</tt> <tt id="link-2" class="py-name" targets="Class pyspark.rdd.RDD=pyspark.rdd.RDD-class.html"><a title="pyspark.rdd.RDD" class="py-name" href="#" onclick="return doclink('link-2', 'RDD', 'link-2');">RDD</a></tt><tt class="py-op">,</tt> <tt class="py-name">PipelinedRDD</tt> </tt>
<a name="L19"></a><tt class="py-lineno">  19</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-3" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-3', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-4" class="py-name" targets="Module pyspark.serializers=pyspark.serializers-module.html"><a title="pyspark.serializers" class="py-name" href="#" onclick="return doclink('link-4', 'serializers', 'link-4');">serializers</a></tt> <tt class="py-keyword">import</tt> <tt class="py-name">BatchedSerializer</tt><tt class="py-op">,</tt> <tt id="link-5" class="py-name" targets="Class pyspark.serializers.PickleSerializer=pyspark.serializers.PickleSerializer-class.html"><a title="pyspark.serializers.PickleSerializer" class="py-name" href="#" onclick="return doclink('link-5', 'PickleSerializer', 'link-5');">PickleSerializer</a></tt> </tt>
<a name="L20"></a><tt class="py-lineno">  20</tt>  <tt class="py-line"> </tt>
<a name="L21"></a><tt class="py-lineno">  21</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">py4j</tt><tt class="py-op">.</tt><tt class="py-name">protocol</tt> <tt class="py-keyword">import</tt> <tt class="py-name">Py4JError</tt> </tt>
<a name="L22"></a><tt class="py-lineno">  22</tt>  <tt class="py-line"> </tt>
<a name="L23"></a><tt class="py-lineno">  23</tt>  <tt class="py-line"><tt class="py-name">__all__</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt> </tt>
<a name="L24"></a><tt class="py-lineno">  24</tt>  <tt class="py-line">    <tt class="py-string">"StringType"</tt><tt class="py-op">,</tt> <tt class="py-string">"BinaryType"</tt><tt class="py-op">,</tt> <tt class="py-string">"BooleanType"</tt><tt class="py-op">,</tt> <tt class="py-string">"DecimalType"</tt><tt class="py-op">,</tt> <tt class="py-string">"DoubleType"</tt><tt class="py-op">,</tt> </tt>
<a name="L25"></a><tt class="py-lineno">  25</tt>  <tt class="py-line">    <tt class="py-string">"FloatType"</tt><tt class="py-op">,</tt> <tt class="py-string">"ByteType"</tt><tt class="py-op">,</tt> <tt class="py-string">"IntegerType"</tt><tt class="py-op">,</tt> <tt class="py-string">"LongType"</tt><tt class="py-op">,</tt> <tt class="py-string">"ShortType"</tt><tt class="py-op">,</tt> </tt>
<a name="L26"></a><tt class="py-lineno">  26</tt>  <tt class="py-line">    <tt class="py-string">"ArrayType"</tt><tt class="py-op">,</tt> <tt class="py-string">"MapType"</tt><tt class="py-op">,</tt> <tt class="py-string">"StructField"</tt><tt class="py-op">,</tt> <tt class="py-string">"StructType"</tt><tt class="py-op">,</tt> </tt>
<a name="L27"></a><tt class="py-lineno">  27</tt>  <tt class="py-line">    <tt class="py-string">"SQLContext"</tt><tt class="py-op">,</tt> <tt class="py-string">"HiveContext"</tt><tt class="py-op">,</tt> <tt class="py-string">"LocalHiveContext"</tt><tt class="py-op">,</tt> <tt class="py-string">"TestHiveContext"</tt><tt class="py-op">,</tt> <tt class="py-string">"SchemaRDD"</tt><tt class="py-op">,</tt> <tt class="py-string">"Row"</tt><tt class="py-op">]</tt> </tt>
<a name="PrimitiveTypeSingleton"></a><div id="PrimitiveTypeSingleton-def"><a name="L28"></a><tt class="py-lineno">  28</tt>  <tt class="py-line"> </tt>
<a name="L29"></a><tt class="py-lineno">  29</tt> <a class="py-toggle" href="#" id="PrimitiveTypeSingleton-toggle" onclick="return toggle('PrimitiveTypeSingleton');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.PrimitiveTypeSingleton-class.html">PrimitiveTypeSingleton</a><tt class="py-op">(</tt><tt class="py-base-class">type</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PrimitiveTypeSingleton-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="PrimitiveTypeSingleton-expanded"><a name="L30"></a><tt class="py-lineno">  30</tt>  <tt class="py-line">    <tt id="link-6" class="py-name" targets="Variable pyspark.sql.PrimitiveTypeSingleton._instances=pyspark.sql.PrimitiveTypeSingleton-class.html#_instances"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-6', '_instances', 'link-6');">_instances</a></tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-op">}</tt> </tt>
<a name="PrimitiveTypeSingleton.__call__"></a><div id="PrimitiveTypeSingleton.__call__-def"><a name="L31"></a><tt class="py-lineno">  31</tt> <a class="py-toggle" href="#" id="PrimitiveTypeSingleton.__call__-toggle" onclick="return toggle('PrimitiveTypeSingleton.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.PrimitiveTypeSingleton-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">cls</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PrimitiveTypeSingleton.__call__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="PrimitiveTypeSingleton.__call__-expanded"><a name="L32"></a><tt class="py-lineno">  32</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">cls</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt class="py-name">cls</tt><tt class="py-op">.</tt><tt id="link-7" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-7', '_instances', 'link-6');">_instances</a></tt><tt class="py-op">:</tt> </tt>
<a name="L33"></a><tt class="py-lineno">  33</tt>  <tt class="py-line">            <tt class="py-name">cls</tt><tt class="py-op">.</tt><tt id="link-8" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-8', '_instances', 'link-6');">_instances</a></tt><tt class="py-op">[</tt><tt class="py-name">cls</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-9" class="py-name" targets="Class pyspark.sql.PrimitiveTypeSingleton=pyspark.sql.PrimitiveTypeSingleton-class.html"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-9', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt><tt class="py-op">,</tt> <tt class="py-name">cls</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-10" class="py-name" targets="Method pyspark.sql.PrimitiveTypeSingleton.__call__()=pyspark.sql.PrimitiveTypeSingleton-class.html#__call__"><a title="pyspark.sql.PrimitiveTypeSingleton.__call__" class="py-name" href="#" onclick="return doclink('link-10', '__call__', 'link-10');">__call__</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L34"></a><tt class="py-lineno">  34</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">cls</tt><tt class="py-op">.</tt><tt id="link-11" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-11', '_instances', 'link-6');">_instances</a></tt><tt class="py-op">[</tt><tt class="py-name">cls</tt><tt class="py-op">]</tt> </tt>
</div></div><a name="L35"></a><tt class="py-lineno">  35</tt>  <tt class="py-line"> </tt>
<a name="StringType"></a><div id="StringType-def"><a name="L36"></a><tt class="py-lineno">  36</tt> <a class="py-toggle" href="#" id="StringType-toggle" onclick="return toggle('StringType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.StringType-class.html">StringType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StringType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="StringType-expanded"><a name="L37"></a><tt class="py-lineno">  37</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL StringType</tt> </tt>
<a name="L38"></a><tt class="py-lineno">  38</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L39"></a><tt class="py-lineno">  39</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing string values.</tt> </tt>
<a name="L40"></a><tt class="py-lineno">  40</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L41"></a><tt class="py-lineno">  41</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L42"></a><tt class="py-lineno">  42</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-12" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-12', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L43"></a><tt class="py-lineno">  43</tt>  <tt class="py-line"> </tt>
<a name="StringType._get_scala_type_string"></a><div id="StringType._get_scala_type_string-def"><a name="L44"></a><tt class="py-lineno">  44</tt> <a class="py-toggle" href="#" id="StringType._get_scala_type_string-toggle" onclick="return toggle('StringType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StringType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StringType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StringType._get_scala_type_string-expanded"><a name="L45"></a><tt class="py-lineno">  45</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"StringType"</tt> </tt>
</div></div><a name="L46"></a><tt class="py-lineno">  46</tt>  <tt class="py-line"> </tt>
<a name="BinaryType"></a><div id="BinaryType-def"><a name="L47"></a><tt class="py-lineno">  47</tt> <a class="py-toggle" href="#" id="BinaryType-toggle" onclick="return toggle('BinaryType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.BinaryType-class.html">BinaryType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="BinaryType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="BinaryType-expanded"><a name="L48"></a><tt class="py-lineno">  48</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL BinaryType</tt> </tt>
<a name="L49"></a><tt class="py-lineno">  49</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L50"></a><tt class="py-lineno">  50</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing bytes values and bytearray values.</tt> </tt>
<a name="L51"></a><tt class="py-lineno">  51</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L52"></a><tt class="py-lineno">  52</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L53"></a><tt class="py-lineno">  53</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-13" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-13', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L54"></a><tt class="py-lineno">  54</tt>  <tt class="py-line"> </tt>
<a name="BinaryType._get_scala_type_string"></a><div id="BinaryType._get_scala_type_string-def"><a name="L55"></a><tt class="py-lineno">  55</tt> <a class="py-toggle" href="#" id="BinaryType._get_scala_type_string-toggle" onclick="return toggle('BinaryType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.BinaryType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="BinaryType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="BinaryType._get_scala_type_string-expanded"><a name="L56"></a><tt class="py-lineno">  56</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"BinaryType"</tt> </tt>
</div></div><a name="L57"></a><tt class="py-lineno">  57</tt>  <tt class="py-line"> </tt>
<a name="BooleanType"></a><div id="BooleanType-def"><a name="L58"></a><tt class="py-lineno">  58</tt> <a class="py-toggle" href="#" id="BooleanType-toggle" onclick="return toggle('BooleanType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.BooleanType-class.html">BooleanType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="BooleanType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="BooleanType-expanded"><a name="L59"></a><tt class="py-lineno">  59</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL BooleanType</tt> </tt>
<a name="L60"></a><tt class="py-lineno">  60</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L61"></a><tt class="py-lineno">  61</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing bool values.</tt> </tt>
<a name="L62"></a><tt class="py-lineno">  62</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L63"></a><tt class="py-lineno">  63</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L64"></a><tt class="py-lineno">  64</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-14" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-14', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L65"></a><tt class="py-lineno">  65</tt>  <tt class="py-line"> </tt>
<a name="BooleanType._get_scala_type_string"></a><div id="BooleanType._get_scala_type_string-def"><a name="L66"></a><tt class="py-lineno">  66</tt> <a class="py-toggle" href="#" id="BooleanType._get_scala_type_string-toggle" onclick="return toggle('BooleanType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.BooleanType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="BooleanType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="BooleanType._get_scala_type_string-expanded"><a name="L67"></a><tt class="py-lineno">  67</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"BooleanType"</tt> </tt>
</div></div><a name="L68"></a><tt class="py-lineno">  68</tt>  <tt class="py-line"> </tt>
<a name="TimestampType"></a><div id="TimestampType-def"><a name="L69"></a><tt class="py-lineno">  69</tt> <a class="py-toggle" href="#" id="TimestampType-toggle" onclick="return toggle('TimestampType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.TimestampType-class.html">TimestampType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="TimestampType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="TimestampType-expanded"><a name="L70"></a><tt class="py-lineno">  70</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL TimestampType"""</tt> </tt>
<a name="L71"></a><tt class="py-lineno">  71</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-15" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-15', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L72"></a><tt class="py-lineno">  72</tt>  <tt class="py-line"> </tt>
<a name="TimestampType._get_scala_type_string"></a><div id="TimestampType._get_scala_type_string-def"><a name="L73"></a><tt class="py-lineno">  73</tt> <a class="py-toggle" href="#" id="TimestampType._get_scala_type_string-toggle" onclick="return toggle('TimestampType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.TimestampType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="TimestampType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="TimestampType._get_scala_type_string-expanded"><a name="L74"></a><tt class="py-lineno">  74</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"TimestampType"</tt> </tt>
</div></div><a name="L75"></a><tt class="py-lineno">  75</tt>  <tt class="py-line"> </tt>
<a name="DecimalType"></a><div id="DecimalType-def"><a name="L76"></a><tt class="py-lineno">  76</tt> <a class="py-toggle" href="#" id="DecimalType-toggle" onclick="return toggle('DecimalType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.DecimalType-class.html">DecimalType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DecimalType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="DecimalType-expanded"><a name="L77"></a><tt class="py-lineno">  77</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL DecimalType</tt> </tt>
<a name="L78"></a><tt class="py-lineno">  78</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L79"></a><tt class="py-lineno">  79</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing decimal.Decimal values.</tt> </tt>
<a name="L80"></a><tt class="py-lineno">  80</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L81"></a><tt class="py-lineno">  81</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L82"></a><tt class="py-lineno">  82</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-16" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-16', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L83"></a><tt class="py-lineno">  83</tt>  <tt class="py-line"> </tt>
<a name="DecimalType._get_scala_type_string"></a><div id="DecimalType._get_scala_type_string-def"><a name="L84"></a><tt class="py-lineno">  84</tt> <a class="py-toggle" href="#" id="DecimalType._get_scala_type_string-toggle" onclick="return toggle('DecimalType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.DecimalType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DecimalType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="DecimalType._get_scala_type_string-expanded"><a name="L85"></a><tt class="py-lineno">  85</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"DecimalType"</tt> </tt>
</div></div><a name="L86"></a><tt class="py-lineno">  86</tt>  <tt class="py-line"> </tt>
<a name="DoubleType"></a><div id="DoubleType-def"><a name="L87"></a><tt class="py-lineno">  87</tt> <a class="py-toggle" href="#" id="DoubleType-toggle" onclick="return toggle('DoubleType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.DoubleType-class.html">DoubleType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DoubleType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="DoubleType-expanded"><a name="L88"></a><tt class="py-lineno">  88</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL DoubleType</tt> </tt>
<a name="L89"></a><tt class="py-lineno">  89</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L90"></a><tt class="py-lineno">  90</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing float values. Because a float value</tt> </tt>
<a name="L91"></a><tt class="py-lineno">  91</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L92"></a><tt class="py-lineno">  92</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L93"></a><tt class="py-lineno">  93</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-17" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-17', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L94"></a><tt class="py-lineno">  94</tt>  <tt class="py-line"> </tt>
<a name="DoubleType._get_scala_type_string"></a><div id="DoubleType._get_scala_type_string-def"><a name="L95"></a><tt class="py-lineno">  95</tt> <a class="py-toggle" href="#" id="DoubleType._get_scala_type_string-toggle" onclick="return toggle('DoubleType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.DoubleType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DoubleType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="DoubleType._get_scala_type_string-expanded"><a name="L96"></a><tt class="py-lineno">  96</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"DoubleType"</tt> </tt>
</div></div><a name="L97"></a><tt class="py-lineno">  97</tt>  <tt class="py-line"> </tt>
<a name="FloatType"></a><div id="FloatType-def"><a name="L98"></a><tt class="py-lineno">  98</tt> <a class="py-toggle" href="#" id="FloatType-toggle" onclick="return toggle('FloatType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.FloatType-class.html">FloatType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FloatType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="FloatType-expanded"><a name="L99"></a><tt class="py-lineno">  99</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL FloatType</tt> </tt>
<a name="L100"></a><tt class="py-lineno"> 100</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L101"></a><tt class="py-lineno"> 101</tt>  <tt class="py-line"><tt class="py-docstring">    For PySpark, please use L{DoubleType} instead of using L{FloatType}.</tt> </tt>
<a name="L102"></a><tt class="py-lineno"> 102</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L103"></a><tt class="py-lineno"> 103</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L104"></a><tt class="py-lineno"> 104</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-18" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-18', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L105"></a><tt class="py-lineno"> 105</tt>  <tt class="py-line"> </tt>
<a name="FloatType._get_scala_type_string"></a><div id="FloatType._get_scala_type_string-def"><a name="L106"></a><tt class="py-lineno"> 106</tt> <a class="py-toggle" href="#" id="FloatType._get_scala_type_string-toggle" onclick="return toggle('FloatType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.FloatType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FloatType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="FloatType._get_scala_type_string-expanded"><a name="L107"></a><tt class="py-lineno"> 107</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"FloatType"</tt> </tt>
</div></div><a name="L108"></a><tt class="py-lineno"> 108</tt>  <tt class="py-line"> </tt>
<a name="ByteType"></a><div id="ByteType-def"><a name="L109"></a><tt class="py-lineno"> 109</tt> <a class="py-toggle" href="#" id="ByteType-toggle" onclick="return toggle('ByteType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.ByteType-class.html">ByteType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ByteType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="ByteType-expanded"><a name="L110"></a><tt class="py-lineno"> 110</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL ByteType</tt> </tt>
<a name="L111"></a><tt class="py-lineno"> 111</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L112"></a><tt class="py-lineno"> 112</tt>  <tt class="py-line"><tt class="py-docstring">    For PySpark, please use L{IntegerType} instead of using L{ByteType}.</tt> </tt>
<a name="L113"></a><tt class="py-lineno"> 113</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L114"></a><tt class="py-lineno"> 114</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L115"></a><tt class="py-lineno"> 115</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-19" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-19', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L116"></a><tt class="py-lineno"> 116</tt>  <tt class="py-line"> </tt>
<a name="ByteType._get_scala_type_string"></a><div id="ByteType._get_scala_type_string-def"><a name="L117"></a><tt class="py-lineno"> 117</tt> <a class="py-toggle" href="#" id="ByteType._get_scala_type_string-toggle" onclick="return toggle('ByteType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ByteType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ByteType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ByteType._get_scala_type_string-expanded"><a name="L118"></a><tt class="py-lineno"> 118</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"ByteType"</tt> </tt>
</div></div><a name="L119"></a><tt class="py-lineno"> 119</tt>  <tt class="py-line"> </tt>
<a name="IntegerType"></a><div id="IntegerType-def"><a name="L120"></a><tt class="py-lineno"> 120</tt> <a class="py-toggle" href="#" id="IntegerType-toggle" onclick="return toggle('IntegerType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.IntegerType-class.html">IntegerType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="IntegerType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="IntegerType-expanded"><a name="L121"></a><tt class="py-lineno"> 121</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL IntegerType</tt> </tt>
<a name="L122"></a><tt class="py-lineno"> 122</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L123"></a><tt class="py-lineno"> 123</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing int values.</tt> </tt>
<a name="L124"></a><tt class="py-lineno"> 124</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L125"></a><tt class="py-lineno"> 125</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L126"></a><tt class="py-lineno"> 126</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-20" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-20', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L127"></a><tt class="py-lineno"> 127</tt>  <tt class="py-line"> </tt>
<a name="IntegerType._get_scala_type_string"></a><div id="IntegerType._get_scala_type_string-def"><a name="L128"></a><tt class="py-lineno"> 128</tt> <a class="py-toggle" href="#" id="IntegerType._get_scala_type_string-toggle" onclick="return toggle('IntegerType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.IntegerType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="IntegerType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="IntegerType._get_scala_type_string-expanded"><a name="L129"></a><tt class="py-lineno"> 129</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"IntegerType"</tt> </tt>
</div></div><a name="L130"></a><tt class="py-lineno"> 130</tt>  <tt class="py-line"> </tt>
<a name="LongType"></a><div id="LongType-def"><a name="L131"></a><tt class="py-lineno"> 131</tt> <a class="py-toggle" href="#" id="LongType-toggle" onclick="return toggle('LongType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.LongType-class.html">LongType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LongType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="LongType-expanded"><a name="L132"></a><tt class="py-lineno"> 132</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL LongType</tt> </tt>
<a name="L133"></a><tt class="py-lineno"> 133</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L134"></a><tt class="py-lineno"> 134</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing long values. If the any value is beyond the range of</tt> </tt>
<a name="L135"></a><tt class="py-lineno"> 135</tt>  <tt class="py-line"><tt class="py-docstring">    [-9223372036854775808, 9223372036854775807], please use DecimalType.</tt> </tt>
<a name="L136"></a><tt class="py-lineno"> 136</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L137"></a><tt class="py-lineno"> 137</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L138"></a><tt class="py-lineno"> 138</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-21" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-21', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L139"></a><tt class="py-lineno"> 139</tt>  <tt class="py-line"> </tt>
<a name="LongType._get_scala_type_string"></a><div id="LongType._get_scala_type_string-def"><a name="L140"></a><tt class="py-lineno"> 140</tt> <a class="py-toggle" href="#" id="LongType._get_scala_type_string-toggle" onclick="return toggle('LongType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.LongType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LongType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="LongType._get_scala_type_string-expanded"><a name="L141"></a><tt class="py-lineno"> 141</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"LongType"</tt> </tt>
</div></div><a name="L142"></a><tt class="py-lineno"> 142</tt>  <tt class="py-line"> </tt>
<a name="ShortType"></a><div id="ShortType-def"><a name="L143"></a><tt class="py-lineno"> 143</tt> <a class="py-toggle" href="#" id="ShortType-toggle" onclick="return toggle('ShortType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.ShortType-class.html">ShortType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ShortType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="ShortType-expanded"><a name="L144"></a><tt class="py-lineno"> 144</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL ShortType</tt> </tt>
<a name="L145"></a><tt class="py-lineno"> 145</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L146"></a><tt class="py-lineno"> 146</tt>  <tt class="py-line"><tt class="py-docstring">    For PySpark, please use L{IntegerType} instead of using L{ShortType}.</tt> </tt>
<a name="L147"></a><tt class="py-lineno"> 147</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L148"></a><tt class="py-lineno"> 148</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L149"></a><tt class="py-lineno"> 149</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-22" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-22', 'PrimitiveTypeSingleton', 'link-9');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L150"></a><tt class="py-lineno"> 150</tt>  <tt class="py-line"> </tt>
<a name="ShortType._get_scala_type_string"></a><div id="ShortType._get_scala_type_string-def"><a name="L151"></a><tt class="py-lineno"> 151</tt> <a class="py-toggle" href="#" id="ShortType._get_scala_type_string-toggle" onclick="return toggle('ShortType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ShortType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ShortType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ShortType._get_scala_type_string-expanded"><a name="L152"></a><tt class="py-lineno"> 152</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"ShortType"</tt> </tt>
</div></div><a name="L153"></a><tt class="py-lineno"> 153</tt>  <tt class="py-line"> </tt>
<a name="ArrayType"></a><div id="ArrayType-def"><a name="L154"></a><tt class="py-lineno"> 154</tt> <a class="py-toggle" href="#" id="ArrayType-toggle" onclick="return toggle('ArrayType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html">ArrayType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="ArrayType-expanded"><a name="L155"></a><tt class="py-lineno"> 155</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL ArrayType</tt> </tt>
<a name="L156"></a><tt class="py-lineno"> 156</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L157"></a><tt class="py-lineno"> 157</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing list values.</tt> </tt>
<a name="L158"></a><tt class="py-lineno"> 158</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L159"></a><tt class="py-lineno"> 159</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="ArrayType.__init__"></a><div id="ArrayType.__init__-def"><a name="L160"></a><tt class="py-lineno"> 160</tt> <a class="py-toggle" href="#" id="ArrayType.__init__-toggle" onclick="return toggle('ArrayType.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">elementType</tt><tt class="py-op">,</tt> <tt class="py-param">containsNull</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ArrayType.__init__-expanded"><a name="L161"></a><tt class="py-lineno"> 161</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates an ArrayType</tt> </tt>
<a name="L162"></a><tt class="py-lineno"> 162</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L163"></a><tt class="py-lineno"> 163</tt>  <tt class="py-line"><tt class="py-docstring">        :param elementType: the data type of elements.</tt> </tt>
<a name="L164"></a><tt class="py-lineno"> 164</tt>  <tt class="py-line"><tt class="py-docstring">        :param containsNull: indicates whether the list contains null values.</tt> </tt>
<a name="L165"></a><tt class="py-lineno"> 165</tt>  <tt class="py-line"><tt class="py-docstring">        :return:</tt> </tt>
<a name="L166"></a><tt class="py-lineno"> 166</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L167"></a><tt class="py-lineno"> 167</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ArrayType(StringType, True) == ArrayType(StringType, False)</tt> </tt>
<a name="L168"></a><tt class="py-lineno"> 168</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L169"></a><tt class="py-lineno"> 169</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ArrayType(StringType, True) == ArrayType(StringType, True)</tt> </tt>
<a name="L170"></a><tt class="py-lineno"> 170</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L171"></a><tt class="py-lineno"> 171</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L172"></a><tt class="py-lineno"> 172</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt> <tt class="py-op">=</tt> <tt class="py-name">elementType</tt> </tt>
<a name="L173"></a><tt class="py-lineno"> 173</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">containsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">containsNull</tt> </tt>
</div><a name="L174"></a><tt class="py-lineno"> 174</tt>  <tt class="py-line"> </tt>
<a name="ArrayType._get_scala_type_string"></a><div id="ArrayType._get_scala_type_string-def"><a name="L175"></a><tt class="py-lineno"> 175</tt> <a class="py-toggle" href="#" id="ArrayType._get_scala_type_string-toggle" onclick="return toggle('ArrayType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ArrayType._get_scala_type_string-expanded"><a name="L176"></a><tt class="py-lineno"> 176</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"ArrayType("</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">","</tt> <tt class="py-op">+</tt> \ </tt>
<a name="L177"></a><tt class="py-lineno"> 177</tt>  <tt class="py-line">               <tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">containsNull</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">")"</tt> </tt>
</div><a name="L178"></a><tt class="py-lineno"> 178</tt>  <tt class="py-line"> </tt>
<a name="ArrayType.__eq__"></a><div id="ArrayType.__eq__-def"><a name="L179"></a><tt class="py-lineno"> 179</tt> <a class="py-toggle" href="#" id="ArrayType.__eq__-toggle" onclick="return toggle('ArrayType.__eq__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html#__eq__">__eq__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType.__eq__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ArrayType.__eq__-expanded"><a name="L180"></a><tt class="py-lineno"> 180</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L181"></a><tt class="py-lineno"> 181</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L182"></a><tt class="py-lineno"> 182</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">containsNull</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">containsNull</tt><tt class="py-op">)</tt> </tt>
</div><a name="L183"></a><tt class="py-lineno"> 183</tt>  <tt class="py-line"> </tt>
<a name="ArrayType.__ne__"></a><div id="ArrayType.__ne__-def"><a name="L184"></a><tt class="py-lineno"> 184</tt> <a class="py-toggle" href="#" id="ArrayType.__ne__-toggle" onclick="return toggle('ArrayType.__ne__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html#__ne__">__ne__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType.__ne__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ArrayType.__ne__-expanded"><a name="L185"></a><tt class="py-lineno"> 185</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">not</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-23" class="py-name" targets="Method pyspark.mllib.linalg.SparseVector.__eq__()=pyspark.mllib.linalg.SparseVector-class.html#__eq__,Method pyspark.sql.ArrayType.__eq__()=pyspark.sql.ArrayType-class.html#__eq__,Method pyspark.sql.MapType.__eq__()=pyspark.sql.MapType-class.html#__eq__,Method pyspark.sql.StructField.__eq__()=pyspark.sql.StructField-class.html#__eq__,Method pyspark.sql.StructType.__eq__()=pyspark.sql.StructType-class.html#__eq__"><a title="pyspark.mllib.linalg.SparseVector.__eq__
pyspark.sql.ArrayType.__eq__
pyspark.sql.MapType.__eq__
pyspark.sql.StructField.__eq__
pyspark.sql.StructType.__eq__" class="py-name" href="#" onclick="return doclink('link-23', '__eq__', 'link-23');">__eq__</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L186"></a><tt class="py-lineno"> 186</tt>  <tt class="py-line"> </tt>
<a name="MapType"></a><div id="MapType-def"><a name="L187"></a><tt class="py-lineno"> 187</tt>  <tt class="py-line"> </tt>
<a name="L188"></a><tt class="py-lineno"> 188</tt> <a class="py-toggle" href="#" id="MapType-toggle" onclick="return toggle('MapType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html">MapType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="MapType-expanded"><a name="L189"></a><tt class="py-lineno"> 189</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL MapType</tt> </tt>
<a name="L190"></a><tt class="py-lineno"> 190</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L191"></a><tt class="py-lineno"> 191</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing dict values.</tt> </tt>
<a name="L192"></a><tt class="py-lineno"> 192</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L193"></a><tt class="py-lineno"> 193</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="MapType.__init__"></a><div id="MapType.__init__-def"><a name="L194"></a><tt class="py-lineno"> 194</tt> <a class="py-toggle" href="#" id="MapType.__init__-toggle" onclick="return toggle('MapType.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">keyType</tt><tt class="py-op">,</tt> <tt class="py-param">valueType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="MapType.__init__-expanded"><a name="L195"></a><tt class="py-lineno"> 195</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a MapType</tt> </tt>
<a name="L196"></a><tt class="py-lineno"> 196</tt>  <tt class="py-line"><tt class="py-docstring">        :param keyType: the data type of keys.</tt> </tt>
<a name="L197"></a><tt class="py-lineno"> 197</tt>  <tt class="py-line"><tt class="py-docstring">        :param valueType: the data type of values.</tt> </tt>
<a name="L198"></a><tt class="py-lineno"> 198</tt>  <tt class="py-line"><tt class="py-docstring">        :return:</tt> </tt>
<a name="L199"></a><tt class="py-lineno"> 199</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L200"></a><tt class="py-lineno"> 200</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; MapType(StringType, IntegerType) == MapType(StringType, IntegerType)</tt> </tt>
<a name="L201"></a><tt class="py-lineno"> 201</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L202"></a><tt class="py-lineno"> 202</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; MapType(StringType, IntegerType) == MapType(StringType, FloatType)</tt> </tt>
<a name="L203"></a><tt class="py-lineno"> 203</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L204"></a><tt class="py-lineno"> 204</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L205"></a><tt class="py-lineno"> 205</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">keyType</tt> <tt class="py-op">=</tt> <tt class="py-name">keyType</tt> </tt>
<a name="L206"></a><tt class="py-lineno"> 206</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt> <tt class="py-op">=</tt> <tt class="py-name">valueType</tt> </tt>
</div><a name="L207"></a><tt class="py-lineno"> 207</tt>  <tt class="py-line"> </tt>
<a name="MapType._get_scala_type_string"></a><div id="MapType._get_scala_type_string-def"><a name="L208"></a><tt class="py-lineno"> 208</tt> <a class="py-toggle" href="#" id="MapType._get_scala_type_string-toggle" onclick="return toggle('MapType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="MapType._get_scala_type_string-expanded"><a name="L209"></a><tt class="py-lineno"> 209</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"MapType("</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">keyType</tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">","</tt> <tt class="py-op">+</tt> \ </tt>
<a name="L210"></a><tt class="py-lineno"> 210</tt>  <tt class="py-line">               <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">")"</tt> </tt>
</div><a name="L211"></a><tt class="py-lineno"> 211</tt>  <tt class="py-line"> </tt>
<a name="MapType.__eq__"></a><div id="MapType.__eq__-def"><a name="L212"></a><tt class="py-lineno"> 212</tt> <a class="py-toggle" href="#" id="MapType.__eq__-toggle" onclick="return toggle('MapType.__eq__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html#__eq__">__eq__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType.__eq__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="MapType.__eq__-expanded"><a name="L213"></a><tt class="py-lineno"> 213</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L214"></a><tt class="py-lineno"> 214</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">keyType</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">keyType</tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L215"></a><tt class="py-lineno"> 215</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">)</tt> </tt>
</div><a name="L216"></a><tt class="py-lineno"> 216</tt>  <tt class="py-line"> </tt>
<a name="MapType.__ne__"></a><div id="MapType.__ne__-def"><a name="L217"></a><tt class="py-lineno"> 217</tt> <a class="py-toggle" href="#" id="MapType.__ne__-toggle" onclick="return toggle('MapType.__ne__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html#__ne__">__ne__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType.__ne__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="MapType.__ne__-expanded"><a name="L218"></a><tt class="py-lineno"> 218</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">not</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-24" class="py-name"><a title="pyspark.mllib.linalg.SparseVector.__eq__
pyspark.sql.ArrayType.__eq__
pyspark.sql.MapType.__eq__
pyspark.sql.StructField.__eq__
pyspark.sql.StructType.__eq__" class="py-name" href="#" onclick="return doclink('link-24', '__eq__', 'link-23');">__eq__</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L219"></a><tt class="py-lineno"> 219</tt>  <tt class="py-line"> </tt>
<a name="StructField"></a><div id="StructField-def"><a name="L220"></a><tt class="py-lineno"> 220</tt> <a class="py-toggle" href="#" id="StructField-toggle" onclick="return toggle('StructField');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html">StructField</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="StructField-expanded"><a name="L221"></a><tt class="py-lineno"> 221</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL StructField</tt> </tt>
<a name="L222"></a><tt class="py-lineno"> 222</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L223"></a><tt class="py-lineno"> 223</tt>  <tt class="py-line"><tt class="py-docstring">    Represents a field in a StructType.</tt> </tt>
<a name="L224"></a><tt class="py-lineno"> 224</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L225"></a><tt class="py-lineno"> 225</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="StructField.__init__"></a><div id="StructField.__init__-def"><a name="L226"></a><tt class="py-lineno"> 226</tt> <a class="py-toggle" href="#" id="StructField.__init__-toggle" onclick="return toggle('StructField.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">name</tt><tt class="py-op">,</tt> <tt class="py-param">dataType</tt><tt class="py-op">,</tt> <tt class="py-param">nullable</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructField.__init__-expanded"><a name="L227"></a><tt class="py-lineno"> 227</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a StructField</tt> </tt>
<a name="L228"></a><tt class="py-lineno"> 228</tt>  <tt class="py-line"><tt class="py-docstring">        :param name: the name of this field.</tt> </tt>
<a name="L229"></a><tt class="py-lineno"> 229</tt>  <tt class="py-line"><tt class="py-docstring">        :param dataType: the data type of this field.</tt> </tt>
<a name="L230"></a><tt class="py-lineno"> 230</tt>  <tt class="py-line"><tt class="py-docstring">        :param nullable: indicates whether values of this field can be null.</tt> </tt>
<a name="L231"></a><tt class="py-lineno"> 231</tt>  <tt class="py-line"><tt class="py-docstring">        :return:</tt> </tt>
<a name="L232"></a><tt class="py-lineno"> 232</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L233"></a><tt class="py-lineno"> 233</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; StructField("f1", StringType, True) == StructField("f1", StringType, True)</tt> </tt>
<a name="L234"></a><tt class="py-lineno"> 234</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L235"></a><tt class="py-lineno"> 235</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; StructField("f1", StringType, True) == StructField("f2", StringType, True)</tt> </tt>
<a name="L236"></a><tt class="py-lineno"> 236</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L237"></a><tt class="py-lineno"> 237</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L238"></a><tt class="py-lineno"> 238</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-25" class="py-name" targets="Method pyspark.rdd.RDD.name()=pyspark.rdd.RDD-class.html#name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-25', 'name', 'link-25');">name</a></tt> <tt class="py-op">=</tt> <tt id="link-26" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-26', 'name', 'link-25');">name</a></tt> </tt>
<a name="L239"></a><tt class="py-lineno"> 239</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt> <tt class="py-op">=</tt> <tt class="py-name">dataType</tt> </tt>
<a name="L240"></a><tt class="py-lineno"> 240</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">nullable</tt> <tt class="py-op">=</tt> <tt class="py-name">nullable</tt> </tt>
</div><a name="L241"></a><tt class="py-lineno"> 241</tt>  <tt class="py-line"> </tt>
<a name="StructField._get_scala_type_string"></a><div id="StructField._get_scala_type_string-def"><a name="L242"></a><tt class="py-lineno"> 242</tt> <a class="py-toggle" href="#" id="StructField._get_scala_type_string-toggle" onclick="return toggle('StructField._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructField._get_scala_type_string-expanded"><a name="L243"></a><tt class="py-lineno"> 243</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"StructField("</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-27" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-27', 'name', 'link-25');">name</a></tt> <tt class="py-op">+</tt> <tt class="py-string">","</tt> <tt class="py-op">+</tt> \ </tt>
<a name="L244"></a><tt class="py-lineno"> 244</tt>  <tt class="py-line">               <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">","</tt> <tt class="py-op">+</tt> \ </tt>
<a name="L245"></a><tt class="py-lineno"> 245</tt>  <tt class="py-line">               <tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">nullable</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">")"</tt> </tt>
</div><a name="L246"></a><tt class="py-lineno"> 246</tt>  <tt class="py-line"> </tt>
<a name="StructField.__eq__"></a><div id="StructField.__eq__-def"><a name="L247"></a><tt class="py-lineno"> 247</tt> <a class="py-toggle" href="#" id="StructField.__eq__-toggle" onclick="return toggle('StructField.__eq__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html#__eq__">__eq__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField.__eq__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructField.__eq__-expanded"><a name="L248"></a><tt class="py-lineno"> 248</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L249"></a><tt class="py-lineno"> 249</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-28" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-28', 'name', 'link-25');">name</a></tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt id="link-29" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-29', 'name', 'link-25');">name</a></tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L250"></a><tt class="py-lineno"> 250</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L251"></a><tt class="py-lineno"> 251</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">nullable</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">nullable</tt><tt class="py-op">)</tt> </tt>
</div><a name="L252"></a><tt class="py-lineno"> 252</tt>  <tt class="py-line"> </tt>
<a name="StructField.__ne__"></a><div id="StructField.__ne__-def"><a name="L253"></a><tt class="py-lineno"> 253</tt> <a class="py-toggle" href="#" id="StructField.__ne__-toggle" onclick="return toggle('StructField.__ne__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html#__ne__">__ne__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField.__ne__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructField.__ne__-expanded"><a name="L254"></a><tt class="py-lineno"> 254</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">not</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-30" class="py-name"><a title="pyspark.mllib.linalg.SparseVector.__eq__
pyspark.sql.ArrayType.__eq__
pyspark.sql.MapType.__eq__
pyspark.sql.StructField.__eq__
pyspark.sql.StructType.__eq__" class="py-name" href="#" onclick="return doclink('link-30', '__eq__', 'link-23');">__eq__</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L255"></a><tt class="py-lineno"> 255</tt>  <tt class="py-line"> </tt>
<a name="StructType"></a><div id="StructType-def"><a name="L256"></a><tt class="py-lineno"> 256</tt> <a class="py-toggle" href="#" id="StructType-toggle" onclick="return toggle('StructType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html">StructType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="StructType-expanded"><a name="L257"></a><tt class="py-lineno"> 257</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL StructType</tt> </tt>
<a name="L258"></a><tt class="py-lineno"> 258</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L259"></a><tt class="py-lineno"> 259</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing tuple values.</tt> </tt>
<a name="L260"></a><tt class="py-lineno"> 260</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L261"></a><tt class="py-lineno"> 261</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="StructType.__init__"></a><div id="StructType.__init__-def"><a name="L262"></a><tt class="py-lineno"> 262</tt> <a class="py-toggle" href="#" id="StructType.__init__-toggle" onclick="return toggle('StructType.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">fields</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructType.__init__-expanded"><a name="L263"></a><tt class="py-lineno"> 263</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a StructType</tt> </tt>
<a name="L264"></a><tt class="py-lineno"> 264</tt>  <tt class="py-line"><tt class="py-docstring">        :param fields:</tt> </tt>
<a name="L265"></a><tt class="py-lineno"> 265</tt>  <tt class="py-line"><tt class="py-docstring">        :return:</tt> </tt>
<a name="L266"></a><tt class="py-lineno"> 266</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L267"></a><tt class="py-lineno"> 267</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 = StructType([StructField("f1", StringType, True)])</tt> </tt>
<a name="L268"></a><tt class="py-lineno"> 268</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct2 = StructType([StructField("f1", StringType, True)])</tt> </tt>
<a name="L269"></a><tt class="py-lineno"> 269</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 == struct2</tt> </tt>
<a name="L270"></a><tt class="py-lineno"> 270</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L271"></a><tt class="py-lineno"> 271</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 = StructType([StructField("f1", StringType, True)])</tt> </tt>
<a name="L272"></a><tt class="py-lineno"> 272</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct2 = StructType([StructField("f1", StringType, True),</tt> </tt>
<a name="L273"></a><tt class="py-lineno"> 273</tt>  <tt class="py-line"><tt class="py-docstring">        ...   [StructField("f2", IntegerType, False)]])</tt> </tt>
<a name="L274"></a><tt class="py-lineno"> 274</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 == struct2</tt> </tt>
<a name="L275"></a><tt class="py-lineno"> 275</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L276"></a><tt class="py-lineno"> 276</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L277"></a><tt class="py-lineno"> 277</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt> <tt class="py-op">=</tt> <tt class="py-name">fields</tt> </tt>
</div><a name="L278"></a><tt class="py-lineno"> 278</tt>  <tt class="py-line"> </tt>
<a name="StructType._get_scala_type_string"></a><div id="StructType._get_scala_type_string-def"><a name="L279"></a><tt class="py-lineno"> 279</tt> <a class="py-toggle" href="#" id="StructType._get_scala_type_string-toggle" onclick="return toggle('StructType._get_scala_type_string');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html#_get_scala_type_string">_get_scala_type_string</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType._get_scala_type_string-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructType._get_scala_type_string-expanded"><a name="L280"></a><tt class="py-lineno"> 280</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"StructType(List("</tt> <tt class="py-op">+</tt> \ </tt>
<a name="L281"></a><tt class="py-lineno"> 281</tt>  <tt class="py-line">               <tt class="py-string">","</tt><tt class="py-op">.</tt><tt id="link-31" class="py-name" targets="Method pyspark.rdd.RDD.join()=pyspark.rdd.RDD-class.html#join"><a title="pyspark.rdd.RDD.join" class="py-name" href="#" onclick="return doclink('link-31', 'join', 'link-31');">join</a></tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-name">field</tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">field</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">"))"</tt> </tt>
</div><a name="L282"></a><tt class="py-lineno"> 282</tt>  <tt class="py-line"> </tt>
<a name="StructType.__eq__"></a><div id="StructType.__eq__-def"><a name="L283"></a><tt class="py-lineno"> 283</tt> <a class="py-toggle" href="#" id="StructType.__eq__-toggle" onclick="return toggle('StructType.__eq__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html#__eq__">__eq__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType.__eq__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructType.__eq__-expanded"><a name="L284"></a><tt class="py-lineno"> 284</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> \ </tt>
<a name="L285"></a><tt class="py-lineno"> 285</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt> </tt>
</div><a name="L286"></a><tt class="py-lineno"> 286</tt>  <tt class="py-line"> </tt>
<a name="StructType.__ne__"></a><div id="StructType.__ne__-def"><a name="L287"></a><tt class="py-lineno"> 287</tt> <a class="py-toggle" href="#" id="StructType.__ne__-toggle" onclick="return toggle('StructType.__ne__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html#__ne__">__ne__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType.__ne__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructType.__ne__-expanded"><a name="L288"></a><tt class="py-lineno"> 288</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">not</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-32" class="py-name"><a title="pyspark.mllib.linalg.SparseVector.__eq__
pyspark.sql.ArrayType.__eq__
pyspark.sql.MapType.__eq__
pyspark.sql.StructField.__eq__
pyspark.sql.StructType.__eq__" class="py-name" href="#" onclick="return doclink('link-32', '__eq__', 'link-23');">__eq__</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L289"></a><tt class="py-lineno"> 289</tt>  <tt class="py-line"> </tt>
<a name="_parse_datatype_list"></a><div id="_parse_datatype_list-def"><a name="L290"></a><tt class="py-lineno"> 290</tt> <a class="py-toggle" href="#" id="_parse_datatype_list-toggle" onclick="return toggle('_parse_datatype_list');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_parse_datatype_list">_parse_datatype_list</a><tt class="py-op">(</tt><tt class="py-param">datatype_list_string</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_parse_datatype_list-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_parse_datatype_list-expanded"><a name="L291"></a><tt class="py-lineno"> 291</tt>  <tt class="py-line">    <tt class="py-name">index</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L292"></a><tt class="py-lineno"> 292</tt>  <tt class="py-line">    <tt class="py-name">datatype_list</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt> </tt>
<a name="L293"></a><tt class="py-lineno"> 293</tt>  <tt class="py-line">    <tt class="py-name">start</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L294"></a><tt class="py-lineno"> 294</tt>  <tt class="py-line">    <tt class="py-name">depth</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L295"></a><tt class="py-lineno"> 295</tt>  <tt class="py-line">    <tt class="py-keyword">while</tt> <tt class="py-name">index</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">datatype_list_string</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L296"></a><tt class="py-lineno"> 296</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">depth</tt> <tt class="py-op">==</tt> <tt class="py-number">0</tt> <tt class="py-keyword">and</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">index</tt><tt class="py-op">]</tt> <tt class="py-op">==</tt> <tt class="py-string">","</tt><tt class="py-op">:</tt> </tt>
<a name="L297"></a><tt class="py-lineno"> 297</tt>  <tt class="py-line">            <tt class="py-name">datatype_string</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">start</tt><tt class="py-op">:</tt><tt class="py-name">index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L298"></a><tt class="py-lineno"> 298</tt>  <tt class="py-line">            <tt class="py-name">datatype_list</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L299"></a><tt class="py-lineno"> 299</tt>  <tt class="py-line">            <tt class="py-name">start</tt> <tt class="py-op">=</tt> <tt class="py-name">index</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt> </tt>
<a name="L300"></a><tt class="py-lineno"> 300</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">index</tt><tt class="py-op">]</tt> <tt class="py-op">==</tt> <tt class="py-string">"("</tt><tt class="py-op">:</tt> </tt>
<a name="L301"></a><tt class="py-lineno"> 301</tt>  <tt class="py-line">            <tt class="py-name">depth</tt> <tt class="py-op">+=</tt> <tt class="py-number">1</tt> </tt>
<a name="L302"></a><tt class="py-lineno"> 302</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">index</tt><tt class="py-op">]</tt> <tt class="py-op">==</tt> <tt class="py-string">")"</tt><tt class="py-op">:</tt> </tt>
<a name="L303"></a><tt class="py-lineno"> 303</tt>  <tt class="py-line">            <tt class="py-name">depth</tt> <tt class="py-op">-=</tt> <tt class="py-number">1</tt> </tt>
<a name="L304"></a><tt class="py-lineno"> 304</tt>  <tt class="py-line"> </tt>
<a name="L305"></a><tt class="py-lineno"> 305</tt>  <tt class="py-line">        <tt class="py-name">index</tt> <tt class="py-op">+=</tt> <tt class="py-number">1</tt> </tt>
<a name="L306"></a><tt class="py-lineno"> 306</tt>  <tt class="py-line"> </tt>
<a name="L307"></a><tt class="py-lineno"> 307</tt>  <tt class="py-line">    <tt class="py-comment"># Handle the last data type</tt> </tt>
<a name="L308"></a><tt class="py-lineno"> 308</tt>  <tt class="py-line">    <tt class="py-name">datatype_string</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">start</tt><tt class="py-op">:</tt><tt class="py-name">index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L309"></a><tt class="py-lineno"> 309</tt>  <tt class="py-line">    <tt class="py-name">datatype_list</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L310"></a><tt class="py-lineno"> 310</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">datatype_list</tt> </tt>
</div><a name="L311"></a><tt class="py-lineno"> 311</tt>  <tt class="py-line"> </tt>
<a name="_parse_datatype_string"></a><div id="_parse_datatype_string-def"><a name="L312"></a><tt class="py-lineno"> 312</tt> <a class="py-toggle" href="#" id="_parse_datatype_string-toggle" onclick="return toggle('_parse_datatype_string');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_parse_datatype_string">_parse_datatype_string</a><tt class="py-op">(</tt><tt class="py-param">datatype_string</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_parse_datatype_string-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_parse_datatype_string-expanded"><a name="L313"></a><tt class="py-lineno"> 313</tt>  <tt class="py-line">    <tt class="py-docstring">"""Parses the given data type string.</tt> </tt>
<a name="L314"></a><tt class="py-lineno"> 314</tt>  <tt class="py-line"><tt class="py-docstring">    :param datatype_string:</tt> </tt>
<a name="L315"></a><tt class="py-lineno"> 315</tt>  <tt class="py-line"><tt class="py-docstring">    :return:</tt> </tt>
<a name="L316"></a><tt class="py-lineno"> 316</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L317"></a><tt class="py-lineno"> 317</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; def check_datatype(datatype):</tt> </tt>
<a name="L318"></a><tt class="py-lineno"> 318</tt>  <tt class="py-line"><tt class="py-docstring">    ...     scala_datatype = sqlCtx._ssql_ctx.parseDataType(datatype._get_scala_type_string())</tt> </tt>
<a name="L319"></a><tt class="py-lineno"> 319</tt>  <tt class="py-line"><tt class="py-docstring">    ...     python_datatype = _parse_datatype_string(scala_datatype.toString())</tt> </tt>
<a name="L320"></a><tt class="py-lineno"> 320</tt>  <tt class="py-line"><tt class="py-docstring">    ...     return datatype == python_datatype</tt> </tt>
<a name="L321"></a><tt class="py-lineno"> 321</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(StringType())</tt> </tt>
<a name="L322"></a><tt class="py-lineno"> 322</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L323"></a><tt class="py-lineno"> 323</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(BinaryType())</tt> </tt>
<a name="L324"></a><tt class="py-lineno"> 324</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L325"></a><tt class="py-lineno"> 325</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(BooleanType())</tt> </tt>
<a name="L326"></a><tt class="py-lineno"> 326</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L327"></a><tt class="py-lineno"> 327</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(TimestampType())</tt> </tt>
<a name="L328"></a><tt class="py-lineno"> 328</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L329"></a><tt class="py-lineno"> 329</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(DecimalType())</tt> </tt>
<a name="L330"></a><tt class="py-lineno"> 330</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L331"></a><tt class="py-lineno"> 331</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(DoubleType())</tt> </tt>
<a name="L332"></a><tt class="py-lineno"> 332</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L333"></a><tt class="py-lineno"> 333</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(FloatType())</tt> </tt>
<a name="L334"></a><tt class="py-lineno"> 334</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L335"></a><tt class="py-lineno"> 335</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(ByteType())</tt> </tt>
<a name="L336"></a><tt class="py-lineno"> 336</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L337"></a><tt class="py-lineno"> 337</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(IntegerType())</tt> </tt>
<a name="L338"></a><tt class="py-lineno"> 338</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L339"></a><tt class="py-lineno"> 339</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(LongType())</tt> </tt>
<a name="L340"></a><tt class="py-lineno"> 340</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L341"></a><tt class="py-lineno"> 341</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(ShortType())</tt> </tt>
<a name="L342"></a><tt class="py-lineno"> 342</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L343"></a><tt class="py-lineno"> 343</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Simple ArrayType.</tt> </tt>
<a name="L344"></a><tt class="py-lineno"> 344</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; simple_arraytype = ArrayType(StringType(), True)</tt> </tt>
<a name="L345"></a><tt class="py-lineno"> 345</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(simple_arraytype)</tt> </tt>
<a name="L346"></a><tt class="py-lineno"> 346</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L347"></a><tt class="py-lineno"> 347</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Simple MapType.</tt> </tt>
<a name="L348"></a><tt class="py-lineno"> 348</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; simple_maptype = MapType(StringType(), LongType())</tt> </tt>
<a name="L349"></a><tt class="py-lineno"> 349</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(simple_maptype)</tt> </tt>
<a name="L350"></a><tt class="py-lineno"> 350</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L351"></a><tt class="py-lineno"> 351</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Simple StructType.</tt> </tt>
<a name="L352"></a><tt class="py-lineno"> 352</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; simple_structtype = StructType([</tt> </tt>
<a name="L353"></a><tt class="py-lineno"> 353</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("a", DecimalType(), False),</tt> </tt>
<a name="L354"></a><tt class="py-lineno"> 354</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("b", BooleanType(), True),</tt> </tt>
<a name="L355"></a><tt class="py-lineno"> 355</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("c", LongType(), True),</tt> </tt>
<a name="L356"></a><tt class="py-lineno"> 356</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("d", BinaryType(), False)])</tt> </tt>
<a name="L357"></a><tt class="py-lineno"> 357</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(simple_structtype)</tt> </tt>
<a name="L358"></a><tt class="py-lineno"> 358</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L359"></a><tt class="py-lineno"> 359</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Complex StructType.</tt> </tt>
<a name="L360"></a><tt class="py-lineno"> 360</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; complex_structtype = StructType([</tt> </tt>
<a name="L361"></a><tt class="py-lineno"> 361</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("simpleArray", simple_arraytype, True),</tt> </tt>
<a name="L362"></a><tt class="py-lineno"> 362</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("simpleMap", simple_maptype, True),</tt> </tt>
<a name="L363"></a><tt class="py-lineno"> 363</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("simpleStruct", simple_structtype, True),</tt> </tt>
<a name="L364"></a><tt class="py-lineno"> 364</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("boolean", BooleanType(), False)])</tt> </tt>
<a name="L365"></a><tt class="py-lineno"> 365</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(complex_structtype)</tt> </tt>
<a name="L366"></a><tt class="py-lineno"> 366</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L367"></a><tt class="py-lineno"> 367</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Complex ArrayType.</tt> </tt>
<a name="L368"></a><tt class="py-lineno"> 368</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; complex_arraytype = ArrayType(complex_structtype, True)</tt> </tt>
<a name="L369"></a><tt class="py-lineno"> 369</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(complex_arraytype)</tt> </tt>
<a name="L370"></a><tt class="py-lineno"> 370</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L371"></a><tt class="py-lineno"> 371</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Complex MapType.</tt> </tt>
<a name="L372"></a><tt class="py-lineno"> 372</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; complex_maptype = MapType(complex_structtype, complex_arraytype)</tt> </tt>
<a name="L373"></a><tt class="py-lineno"> 373</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(complex_maptype)</tt> </tt>
<a name="L374"></a><tt class="py-lineno"> 374</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L375"></a><tt class="py-lineno"> 375</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L376"></a><tt class="py-lineno"> 376</tt>  <tt class="py-line">    <tt class="py-name">left_bracket_index</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_string</tt><tt class="py-op">.</tt><tt class="py-name">find</tt><tt class="py-op">(</tt><tt class="py-string">"("</tt><tt class="py-op">)</tt> </tt>
<a name="L377"></a><tt class="py-lineno"> 377</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">left_bracket_index</tt> <tt class="py-op">==</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L378"></a><tt class="py-lineno"> 378</tt>  <tt class="py-line">        <tt class="py-comment"># It is a primitive type.</tt> </tt>
<a name="L379"></a><tt class="py-lineno"> 379</tt>  <tt class="py-line">        <tt class="py-name">left_bracket_index</tt> <tt class="py-op">=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt> </tt>
<a name="L380"></a><tt class="py-lineno"> 380</tt>  <tt class="py-line">    <tt class="py-name">type_or_field</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_string</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">left_bracket_index</tt><tt class="py-op">]</tt> </tt>
<a name="L381"></a><tt class="py-lineno"> 381</tt>  <tt class="py-line">    <tt class="py-name">rest_part</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_string</tt><tt class="py-op">[</tt><tt class="py-name">left_bracket_index</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L382"></a><tt class="py-lineno"> 382</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"StringType"</tt><tt class="py-op">:</tt> </tt>
<a name="L383"></a><tt class="py-lineno"> 383</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-33" class="py-name" targets="Class pyspark.sql.StringType=pyspark.sql.StringType-class.html"><a title="pyspark.sql.StringType" class="py-name" href="#" onclick="return doclink('link-33', 'StringType', 'link-33');">StringType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L384"></a><tt class="py-lineno"> 384</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"BinaryType"</tt><tt class="py-op">:</tt> </tt>
<a name="L385"></a><tt class="py-lineno"> 385</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-34" class="py-name" targets="Class pyspark.sql.BinaryType=pyspark.sql.BinaryType-class.html"><a title="pyspark.sql.BinaryType" class="py-name" href="#" onclick="return doclink('link-34', 'BinaryType', 'link-34');">BinaryType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L386"></a><tt class="py-lineno"> 386</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"BooleanType"</tt><tt class="py-op">:</tt> </tt>
<a name="L387"></a><tt class="py-lineno"> 387</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-35" class="py-name" targets="Class pyspark.sql.BooleanType=pyspark.sql.BooleanType-class.html"><a title="pyspark.sql.BooleanType" class="py-name" href="#" onclick="return doclink('link-35', 'BooleanType', 'link-35');">BooleanType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L388"></a><tt class="py-lineno"> 388</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"TimestampType"</tt><tt class="py-op">:</tt> </tt>
<a name="L389"></a><tt class="py-lineno"> 389</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">TimestampType</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L390"></a><tt class="py-lineno"> 390</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"DecimalType"</tt><tt class="py-op">:</tt> </tt>
<a name="L391"></a><tt class="py-lineno"> 391</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-36" class="py-name" targets="Class pyspark.sql.DecimalType=pyspark.sql.DecimalType-class.html"><a title="pyspark.sql.DecimalType" class="py-name" href="#" onclick="return doclink('link-36', 'DecimalType', 'link-36');">DecimalType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L392"></a><tt class="py-lineno"> 392</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"DoubleType"</tt><tt class="py-op">:</tt> </tt>
<a name="L393"></a><tt class="py-lineno"> 393</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-37" class="py-name" targets="Class pyspark.sql.DoubleType=pyspark.sql.DoubleType-class.html"><a title="pyspark.sql.DoubleType" class="py-name" href="#" onclick="return doclink('link-37', 'DoubleType', 'link-37');">DoubleType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L394"></a><tt class="py-lineno"> 394</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"FloatType"</tt><tt class="py-op">:</tt> </tt>
<a name="L395"></a><tt class="py-lineno"> 395</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-38" class="py-name" targets="Class pyspark.sql.FloatType=pyspark.sql.FloatType-class.html"><a title="pyspark.sql.FloatType" class="py-name" href="#" onclick="return doclink('link-38', 'FloatType', 'link-38');">FloatType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L396"></a><tt class="py-lineno"> 396</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"ByteType"</tt><tt class="py-op">:</tt> </tt>
<a name="L397"></a><tt class="py-lineno"> 397</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-39" class="py-name" targets="Class pyspark.sql.ByteType=pyspark.sql.ByteType-class.html"><a title="pyspark.sql.ByteType" class="py-name" href="#" onclick="return doclink('link-39', 'ByteType', 'link-39');">ByteType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L398"></a><tt class="py-lineno"> 398</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"IntegerType"</tt><tt class="py-op">:</tt> </tt>
<a name="L399"></a><tt class="py-lineno"> 399</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-40" class="py-name" targets="Class pyspark.sql.IntegerType=pyspark.sql.IntegerType-class.html"><a title="pyspark.sql.IntegerType" class="py-name" href="#" onclick="return doclink('link-40', 'IntegerType', 'link-40');">IntegerType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L400"></a><tt class="py-lineno"> 400</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"LongType"</tt><tt class="py-op">:</tt> </tt>
<a name="L401"></a><tt class="py-lineno"> 401</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-41" class="py-name" targets="Class pyspark.sql.LongType=pyspark.sql.LongType-class.html"><a title="pyspark.sql.LongType" class="py-name" href="#" onclick="return doclink('link-41', 'LongType', 'link-41');">LongType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L402"></a><tt class="py-lineno"> 402</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"ShortType"</tt><tt class="py-op">:</tt> </tt>
<a name="L403"></a><tt class="py-lineno"> 403</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-42" class="py-name" targets="Class pyspark.sql.ShortType=pyspark.sql.ShortType-class.html"><a title="pyspark.sql.ShortType" class="py-name" href="#" onclick="return doclink('link-42', 'ShortType', 'link-42');">ShortType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L404"></a><tt class="py-lineno"> 404</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"ArrayType"</tt><tt class="py-op">:</tt> </tt>
<a name="L405"></a><tt class="py-lineno"> 405</tt>  <tt class="py-line">        <tt class="py-name">last_comma_index</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">rfind</tt><tt class="py-op">(</tt><tt class="py-string">","</tt><tt class="py-op">)</tt> </tt>
<a name="L406"></a><tt class="py-lineno"> 406</tt>  <tt class="py-line">        <tt class="py-name">containsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L407"></a><tt class="py-lineno"> 407</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">last_comma_index</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">"false"</tt><tt class="py-op">:</tt> </tt>
<a name="L408"></a><tt class="py-lineno"> 408</tt>  <tt class="py-line">            <tt class="py-name">containsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L409"></a><tt class="py-lineno"> 409</tt>  <tt class="py-line">        <tt class="py-name">elementType</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt><tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">last_comma_index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L410"></a><tt class="py-lineno"> 410</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-43" class="py-name" targets="Class pyspark.sql.ArrayType=pyspark.sql.ArrayType-class.html"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-43', 'ArrayType', 'link-43');">ArrayType</a></tt><tt class="py-op">(</tt><tt class="py-name">elementType</tt><tt class="py-op">,</tt> <tt class="py-name">containsNull</tt><tt class="py-op">)</tt> </tt>
<a name="L411"></a><tt class="py-lineno"> 411</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"MapType"</tt><tt class="py-op">:</tt> </tt>
<a name="L412"></a><tt class="py-lineno"> 412</tt>  <tt class="py-line">        <tt class="py-name">keyType</tt><tt class="py-op">,</tt> <tt class="py-name">valueType</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_list</tt><tt class="py-op">(</tt><tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L413"></a><tt class="py-lineno"> 413</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-44" class="py-name" targets="Class pyspark.sql.MapType=pyspark.sql.MapType-class.html"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-44', 'MapType', 'link-44');">MapType</a></tt><tt class="py-op">(</tt><tt class="py-name">keyType</tt><tt class="py-op">,</tt> <tt class="py-name">valueType</tt><tt class="py-op">)</tt> </tt>
<a name="L414"></a><tt class="py-lineno"> 414</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"StructField"</tt><tt class="py-op">:</tt> </tt>
<a name="L415"></a><tt class="py-lineno"> 415</tt>  <tt class="py-line">        <tt class="py-name">first_comma_index</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">find</tt><tt class="py-op">(</tt><tt class="py-string">","</tt><tt class="py-op">)</tt> </tt>
<a name="L416"></a><tt class="py-lineno"> 416</tt>  <tt class="py-line">        <tt id="link-45" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-45', 'name', 'link-25');">name</a></tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">first_comma_index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L417"></a><tt class="py-lineno"> 417</tt>  <tt class="py-line">        <tt class="py-name">last_comma_index</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">rfind</tt><tt class="py-op">(</tt><tt class="py-string">","</tt><tt class="py-op">)</tt> </tt>
<a name="L418"></a><tt class="py-lineno"> 418</tt>  <tt class="py-line">        <tt class="py-name">nullable</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L419"></a><tt class="py-lineno"> 419</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">last_comma_index</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">"false"</tt><tt class="py-op">:</tt> </tt>
<a name="L420"></a><tt class="py-lineno"> 420</tt>  <tt class="py-line">            <tt class="py-name">nullable</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L421"></a><tt class="py-lineno"> 421</tt>  <tt class="py-line">        <tt class="py-name">dataType</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt> </tt>
<a name="L422"></a><tt class="py-lineno"> 422</tt>  <tt class="py-line">            <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">first_comma_index</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-name">last_comma_index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L423"></a><tt class="py-lineno"> 423</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-46" class="py-name" targets="Class pyspark.sql.StructField=pyspark.sql.StructField-class.html"><a title="pyspark.sql.StructField" class="py-name" href="#" onclick="return doclink('link-46', 'StructField', 'link-46');">StructField</a></tt><tt class="py-op">(</tt><tt id="link-47" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-47', 'name', 'link-25');">name</a></tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt class="py-name">nullable</tt><tt class="py-op">)</tt> </tt>
<a name="L424"></a><tt class="py-lineno"> 424</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"StructType"</tt><tt class="py-op">:</tt> </tt>
<a name="L425"></a><tt class="py-lineno"> 425</tt>  <tt class="py-line">        <tt class="py-comment"># rest_part should be in the format like</tt> </tt>
<a name="L426"></a><tt class="py-lineno"> 426</tt>  <tt class="py-line">        <tt class="py-comment"># List(StructField(field1,IntegerType,false)).</tt> </tt>
<a name="L427"></a><tt class="py-lineno"> 427</tt>  <tt class="py-line">        <tt class="py-name">field_list_string</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">find</tt><tt class="py-op">(</tt><tt class="py-string">"("</tt><tt class="py-op">)</tt><tt class="py-op">+</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> </tt>
<a name="L428"></a><tt class="py-lineno"> 428</tt>  <tt class="py-line">        <tt class="py-name">fields</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_list</tt><tt class="py-op">(</tt><tt class="py-name">field_list_string</tt><tt class="py-op">)</tt> </tt>
<a name="L429"></a><tt class="py-lineno"> 429</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-48" class="py-name" targets="Class pyspark.sql.StructType=pyspark.sql.StructType-class.html"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-48', 'StructType', 'link-48');">StructType</a></tt><tt class="py-op">(</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt> </tt>
</div><a name="L430"></a><tt class="py-lineno"> 430</tt>  <tt class="py-line"> </tt>
<a name="SQLContext"></a><div id="SQLContext-def"><a name="L431"></a><tt class="py-lineno"> 431</tt> <a class="py-toggle" href="#" id="SQLContext-toggle" onclick="return toggle('SQLContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html">SQLContext</a><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="SQLContext-expanded"><a name="L432"></a><tt class="py-lineno"> 432</tt>  <tt class="py-line">    <tt class="py-docstring">"""Main entry point for SparkSQL functionality.</tt> </tt>
<a name="L433"></a><tt class="py-lineno"> 433</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L434"></a><tt class="py-lineno"> 434</tt>  <tt class="py-line"><tt class="py-docstring">    A SQLContext can be used create L{SchemaRDD}s, register L{SchemaRDD}s as</tt> </tt>
<a name="L435"></a><tt class="py-lineno"> 435</tt>  <tt class="py-line"><tt class="py-docstring">    tables, execute SQL over tables, cache tables, and read parquet files.</tt> </tt>
<a name="L436"></a><tt class="py-lineno"> 436</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L437"></a><tt class="py-lineno"> 437</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.__init__"></a><div id="SQLContext.__init__-def"><a name="L438"></a><tt class="py-lineno"> 438</tt> <a class="py-toggle" href="#" id="SQLContext.__init__-toggle" onclick="return toggle('SQLContext.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sparkContext</tt><tt class="py-op">,</tt> <tt class="py-param">sqlContext</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.__init__-expanded"><a name="L439"></a><tt class="py-lineno"> 439</tt>  <tt class="py-line">        <tt class="py-docstring">"""Create a new SQLContext.</tt> </tt>
<a name="L440"></a><tt class="py-lineno"> 440</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L441"></a><tt class="py-lineno"> 441</tt>  <tt class="py-line"><tt class="py-docstring">        @param sparkContext: The SparkContext to wrap.</tt> </tt>
<a name="L442"></a><tt class="py-lineno"> 442</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L443"></a><tt class="py-lineno"> 443</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L444"></a><tt class="py-lineno"> 444</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.inferSchema(srdd) # doctest: +IGNORE_EXCEPTION_DETAIL</tt> </tt>
<a name="L445"></a><tt class="py-lineno"> 445</tt>  <tt class="py-line"><tt class="py-docstring">        Traceback (most recent call last):</tt> </tt>
<a name="L446"></a><tt class="py-lineno"> 446</tt>  <tt class="py-line"><tt class="py-docstring">            ...</tt> </tt>
<a name="L447"></a><tt class="py-lineno"> 447</tt>  <tt class="py-line"><tt class="py-docstring">        ValueError:...</tt> </tt>
<a name="L448"></a><tt class="py-lineno"> 448</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L449"></a><tt class="py-lineno"> 449</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; bad_rdd = sc.parallelize([1,2,3])</tt> </tt>
<a name="L450"></a><tt class="py-lineno"> 450</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.inferSchema(bad_rdd) # doctest: +IGNORE_EXCEPTION_DETAIL</tt> </tt>
<a name="L451"></a><tt class="py-lineno"> 451</tt>  <tt class="py-line"><tt class="py-docstring">        Traceback (most recent call last):</tt> </tt>
<a name="L452"></a><tt class="py-lineno"> 452</tt>  <tt class="py-line"><tt class="py-docstring">            ...</tt> </tt>
<a name="L453"></a><tt class="py-lineno"> 453</tt>  <tt class="py-line"><tt class="py-docstring">        ValueError:...</tt> </tt>
<a name="L454"></a><tt class="py-lineno"> 454</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L455"></a><tt class="py-lineno"> 455</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; allTypes = sc.parallelize([{"int" : 1, "string" : "string", "double" : 1.0, "long": 1L,</tt> </tt>
<a name="L456"></a><tt class="py-lineno"> 456</tt>  <tt class="py-line"><tt class="py-docstring">        ... "boolean" : True}])</tt> </tt>
<a name="L457"></a><tt class="py-lineno"> 457</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(allTypes).map(lambda x: (x.int, x.string, x.double, x.long,</tt> </tt>
<a name="L458"></a><tt class="py-lineno"> 458</tt>  <tt class="py-line"><tt class="py-docstring">        ... x.boolean))</tt> </tt>
<a name="L459"></a><tt class="py-lineno"> 459</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect()[0]</tt> </tt>
<a name="L460"></a><tt class="py-lineno"> 460</tt>  <tt class="py-line"><tt class="py-docstring">        (1, u'string', 1.0, 1, True)</tt> </tt>
<a name="L461"></a><tt class="py-lineno"> 461</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L462"></a><tt class="py-lineno"> 462</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-49" class="py-name" targets="Variable pyspark.files.SparkFiles._sc=pyspark.files.SparkFiles-class.html#_sc"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-49', '_sc', 'link-49');">_sc</a></tt> <tt class="py-op">=</tt> <tt class="py-name">sparkContext</tt> </tt>
<a name="L463"></a><tt class="py-lineno"> 463</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-50" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-50', '_sc', 'link-49');">_sc</a></tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt> </tt>
<a name="L464"></a><tt class="py-lineno"> 464</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-51" class="py-name" targets="Variable pyspark.context.SparkContext._jvm=pyspark.context.SparkContext-class.html#_jvm"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-51', '_jvm', 'link-51');">_jvm</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-52" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-52', '_sc', 'link-49');">_sc</a></tt><tt class="py-op">.</tt><tt id="link-53" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-53', '_jvm', 'link-51');">_jvm</a></tt> </tt>
<a name="L465"></a><tt class="py-lineno"> 465</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_pythonToJavaMap</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-54" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-54', '_jvm', 'link-51');">_jvm</a></tt><tt class="py-op">.</tt><tt class="py-name">PythonRDD</tt><tt class="py-op">.</tt><tt class="py-name">pythonToJavaMap</tt> </tt>
<a name="L466"></a><tt class="py-lineno"> 466</tt>  <tt class="py-line"> </tt>
<a name="L467"></a><tt class="py-lineno"> 467</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">sqlContext</tt><tt class="py-op">:</tt> </tt>
<a name="L468"></a><tt class="py-lineno"> 468</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_SQLContext</tt> <tt class="py-op">=</tt> <tt class="py-name">sqlContext</tt> </tt>
</div><a name="L469"></a><tt class="py-lineno"> 469</tt>  <tt class="py-line"> </tt>
<a name="L470"></a><tt class="py-lineno"> 470</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="SQLContext._ssql_ctx"></a><div id="SQLContext._ssql_ctx-def"><a name="L471"></a><tt class="py-lineno"> 471</tt> <a class="py-toggle" href="#" id="SQLContext._ssql_ctx-toggle" onclick="return toggle('SQLContext._ssql_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#_ssql_ctx">_ssql_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext._ssql_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext._ssql_ctx-expanded"><a name="L472"></a><tt class="py-lineno"> 472</tt>  <tt class="py-line">        <tt class="py-docstring">"""Accessor for the JVM SparkSQL context.</tt> </tt>
<a name="L473"></a><tt class="py-lineno"> 473</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L474"></a><tt class="py-lineno"> 474</tt>  <tt class="py-line"><tt class="py-docstring">        Subclasses can override this property to provide their own</tt> </tt>
<a name="L475"></a><tt class="py-lineno"> 475</tt>  <tt class="py-line"><tt class="py-docstring">        JVM Contexts.</tt> </tt>
<a name="L476"></a><tt class="py-lineno"> 476</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L477"></a><tt class="py-lineno"> 477</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">'_scala_SQLContext'</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L478"></a><tt class="py-lineno"> 478</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_SQLContext</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-55" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-55', '_jvm', 'link-51');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-56" class="py-name" targets="Class pyspark.sql.SQLContext=pyspark.sql.SQLContext-class.html"><a title="pyspark.sql.SQLContext" class="py-name" href="#" onclick="return doclink('link-56', 'SQLContext', 'link-56');">SQLContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L479"></a><tt class="py-lineno"> 479</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_SQLContext</tt> </tt>
</div><a name="L480"></a><tt class="py-lineno"> 480</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.inferSchema"></a><div id="SQLContext.inferSchema-def"><a name="L481"></a><tt class="py-lineno"> 481</tt> <a class="py-toggle" href="#" id="SQLContext.inferSchema-toggle" onclick="return toggle('SQLContext.inferSchema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#inferSchema">inferSchema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.inferSchema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.inferSchema-expanded"><a name="L482"></a><tt class="py-lineno"> 482</tt>  <tt class="py-line">        <tt class="py-docstring">"""Infer and apply a schema to an RDD of L{dict}s.</tt> </tt>
<a name="L483"></a><tt class="py-lineno"> 483</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L484"></a><tt class="py-lineno"> 484</tt>  <tt class="py-line"><tt class="py-docstring">        We peek at the first row of the RDD to determine the fields names</tt> </tt>
<a name="L485"></a><tt class="py-lineno"> 485</tt>  <tt class="py-line"><tt class="py-docstring">        and types, and then use that to extract all the dictionaries. Nested</tt> </tt>
<a name="L486"></a><tt class="py-lineno"> 486</tt>  <tt class="py-line"><tt class="py-docstring">        collections are supported, which include array, dict, list, set, and</tt> </tt>
<a name="L487"></a><tt class="py-lineno"> 487</tt>  <tt class="py-line"><tt class="py-docstring">        tuple.</tt> </tt>
<a name="L488"></a><tt class="py-lineno"> 488</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L489"></a><tt class="py-lineno"> 489</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L490"></a><tt class="py-lineno"> 490</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect() == [{"field1" : 1, "field2" : "row1"}, {"field1" : 2, "field2": "row2"},</tt> </tt>
<a name="L491"></a><tt class="py-lineno"> 491</tt>  <tt class="py-line"><tt class="py-docstring">        ...                    {"field1" : 3, "field2": "row3"}]</tt> </tt>
<a name="L492"></a><tt class="py-lineno"> 492</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L493"></a><tt class="py-lineno"> 493</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L494"></a><tt class="py-lineno"> 494</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from array import array</tt> </tt>
<a name="L495"></a><tt class="py-lineno"> 495</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(nestedRdd1)</tt> </tt>
<a name="L496"></a><tt class="py-lineno"> 496</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect() == [{"f1" : array('i', [1, 2]), "f2" : {"row1" : 1.0}},</tt> </tt>
<a name="L497"></a><tt class="py-lineno"> 497</tt>  <tt class="py-line"><tt class="py-docstring">        ...                    {"f1" : array('i', [2, 3]), "f2" : {"row2" : 2.0}}]</tt> </tt>
<a name="L498"></a><tt class="py-lineno"> 498</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L499"></a><tt class="py-lineno"> 499</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L500"></a><tt class="py-lineno"> 500</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(nestedRdd2)</tt> </tt>
<a name="L501"></a><tt class="py-lineno"> 501</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect() == [{"f1" : [[1, 2], [2, 3]], "f2" : set([1, 2]), "f3" : (1, 2)},</tt> </tt>
<a name="L502"></a><tt class="py-lineno"> 502</tt>  <tt class="py-line"><tt class="py-docstring">        ...                    {"f1" : [[2, 3], [3, 4]], "f2" : set([2, 3]), "f3" : (2, 3)}]</tt> </tt>
<a name="L503"></a><tt class="py-lineno"> 503</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L504"></a><tt class="py-lineno"> 504</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L505"></a><tt class="py-lineno"> 505</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt id="link-57" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-57', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt> <tt class="py-keyword">is</tt> <tt id="link-58" class="py-name" targets="Class pyspark.sql.SchemaRDD=pyspark.sql.SchemaRDD-class.html"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-58', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L506"></a><tt class="py-lineno"> 506</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Cannot apply schema to %s"</tt> <tt class="py-op">%</tt> <tt id="link-59" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-59', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">.</tt><tt class="py-name">__name__</tt><tt class="py-op">)</tt> </tt>
<a name="L507"></a><tt class="py-lineno"> 507</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-keyword">not</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt id="link-60" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-60', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt id="link-61" class="py-name" targets="Method pyspark.rdd.RDD.first()=pyspark.rdd.RDD-class.html#first"><a title="pyspark.rdd.RDD.first" class="py-name" href="#" onclick="return doclink('link-61', 'first', 'link-61');">first</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">dict</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L508"></a><tt class="py-lineno"> 508</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Only RDDs with dictionaries can be converted to %s: %s"</tt> <tt class="py-op">%</tt> </tt>
<a name="L509"></a><tt class="py-lineno"> 509</tt>  <tt class="py-line">                             <tt class="py-op">(</tt><tt id="link-62" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-62', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">.</tt><tt class="py-name">__name__</tt><tt class="py-op">,</tt> <tt id="link-63" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-63', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt id="link-64" class="py-name"><a title="pyspark.rdd.RDD.first" class="py-name" href="#" onclick="return doclink('link-64', 'first', 'link-61');">first</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L510"></a><tt class="py-lineno"> 510</tt>  <tt class="py-line"> </tt>
<a name="L511"></a><tt class="py-lineno"> 511</tt>  <tt class="py-line">        <tt class="py-name">jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_pythonToJavaMap</tt><tt class="py-op">(</tt><tt id="link-65" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-65', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">)</tt> </tt>
<a name="L512"></a><tt class="py-lineno"> 512</tt>  <tt class="py-line">        <tt class="py-name">srdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-66" class="py-name" targets="Method pyspark.sql.SQLContext.inferSchema()=pyspark.sql.SQLContext-class.html#inferSchema"><a title="pyspark.sql.SQLContext.inferSchema" class="py-name" href="#" onclick="return doclink('link-66', 'inferSchema', 'link-66');">inferSchema</a></tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">.</tt><tt id="link-67" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-67', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L513"></a><tt class="py-lineno"> 513</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-68" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-68', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">srdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L514"></a><tt class="py-lineno"> 514</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.applySchema"></a><div id="SQLContext.applySchema-def"><a name="L515"></a><tt class="py-lineno"> 515</tt> <a class="py-toggle" href="#" id="SQLContext.applySchema-toggle" onclick="return toggle('SQLContext.applySchema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#applySchema">applySchema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">,</tt> <tt class="py-param">schema</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.applySchema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.applySchema-expanded"><a name="L516"></a><tt class="py-lineno"> 516</tt>  <tt class="py-line">        <tt class="py-docstring">"""Applies the given schema to the given RDD of L{dict}s.</tt> </tt>
<a name="L517"></a><tt class="py-lineno"> 517</tt>  <tt class="py-line"><tt class="py-docstring">        :param rdd:</tt> </tt>
<a name="L518"></a><tt class="py-lineno"> 518</tt>  <tt class="py-line"><tt class="py-docstring">        :param schema:</tt> </tt>
<a name="L519"></a><tt class="py-lineno"> 519</tt>  <tt class="py-line"><tt class="py-docstring">        :return:</tt> </tt>
<a name="L520"></a><tt class="py-lineno"> 520</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L521"></a><tt class="py-lineno"> 521</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = StructType([StructField("field1", IntegerType(), False),</tt> </tt>
<a name="L522"></a><tt class="py-lineno"> 522</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field2", StringType(), False)])</tt> </tt>
<a name="L523"></a><tt class="py-lineno"> 523</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.applySchema(rdd, schema)</tt> </tt>
<a name="L524"></a><tt class="py-lineno"> 524</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L525"></a><tt class="py-lineno"> 525</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql("SELECT * from table1")</tt> </tt>
<a name="L526"></a><tt class="py-lineno"> 526</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2.collect() == [{"field1" : 1, "field2" : "row1"}, {"field1" : 2, "field2": "row2"},</tt> </tt>
<a name="L527"></a><tt class="py-lineno"> 527</tt>  <tt class="py-line"><tt class="py-docstring">        ...                    {"field1" : 3, "field2": "row3"}]</tt> </tt>
<a name="L528"></a><tt class="py-lineno"> 528</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L529"></a><tt class="py-lineno"> 529</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L530"></a><tt class="py-lineno"> 530</tt>  <tt class="py-line">        <tt class="py-name">jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_pythonToJavaMap</tt><tt class="py-op">(</tt><tt id="link-69" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-69', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">)</tt> </tt>
<a name="L531"></a><tt class="py-lineno"> 531</tt>  <tt class="py-line">        <tt class="py-name">srdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-70" class="py-name" targets="Method pyspark.sql.SQLContext.applySchema()=pyspark.sql.SQLContext-class.html#applySchema"><a title="pyspark.sql.SQLContext.applySchema" class="py-name" href="#" onclick="return doclink('link-70', 'applySchema', 'link-70');">applySchema</a></tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">.</tt><tt id="link-71" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-71', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt id="link-72" class="py-name" targets="Method pyspark.sql.SchemaRDD.schema()=pyspark.sql.SchemaRDD-class.html#schema"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-72', 'schema', 'link-72');">schema</a></tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L532"></a><tt class="py-lineno"> 532</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-73" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-73', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">srdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L533"></a><tt class="py-lineno"> 533</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.registerRDDAsTable"></a><div id="SQLContext.registerRDDAsTable-def"><a name="L534"></a><tt class="py-lineno"> 534</tt> <a class="py-toggle" href="#" id="SQLContext.registerRDDAsTable-toggle" onclick="return toggle('SQLContext.registerRDDAsTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#registerRDDAsTable">registerRDDAsTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.registerRDDAsTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.registerRDDAsTable-expanded"><a name="L535"></a><tt class="py-lineno"> 535</tt>  <tt class="py-line">        <tt class="py-docstring">"""Registers the given RDD as a temporary table in the catalog.</tt> </tt>
<a name="L536"></a><tt class="py-lineno"> 536</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L537"></a><tt class="py-lineno"> 537</tt>  <tt class="py-line"><tt class="py-docstring">        Temporary tables exist only during the lifetime of this instance of</tt> </tt>
<a name="L538"></a><tt class="py-lineno"> 538</tt>  <tt class="py-line"><tt class="py-docstring">        SQLContext.</tt> </tt>
<a name="L539"></a><tt class="py-lineno"> 539</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L540"></a><tt class="py-lineno"> 540</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L541"></a><tt class="py-lineno"> 541</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L542"></a><tt class="py-lineno"> 542</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L543"></a><tt class="py-lineno"> 543</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt id="link-74" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-74', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt> <tt class="py-keyword">is</tt> <tt id="link-75" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-75', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L544"></a><tt class="py-lineno"> 544</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt id="link-76" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-76', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt> </tt>
<a name="L545"></a><tt class="py-lineno"> 545</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-77" class="py-name" targets="Method pyspark.sql.SQLContext.registerRDDAsTable()=pyspark.sql.SQLContext-class.html#registerRDDAsTable"><a title="pyspark.sql.SQLContext.registerRDDAsTable" class="py-name" href="#" onclick="return doclink('link-77', 'registerRDDAsTable', 'link-77');">registerRDDAsTable</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
<a name="L546"></a><tt class="py-lineno"> 546</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L547"></a><tt class="py-lineno"> 547</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can only register SchemaRDD as table"</tt><tt class="py-op">)</tt> </tt>
</div><a name="L548"></a><tt class="py-lineno"> 548</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.parquetFile"></a><div id="SQLContext.parquetFile-def"><a name="L549"></a><tt class="py-lineno"> 549</tt> <a class="py-toggle" href="#" id="SQLContext.parquetFile-toggle" onclick="return toggle('SQLContext.parquetFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#parquetFile">parquetFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">path</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.parquetFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.parquetFile-expanded"><a name="L550"></a><tt class="py-lineno"> 550</tt>  <tt class="py-line">        <tt class="py-docstring">"""Loads a Parquet file, returning the result as a L{SchemaRDD}.</tt> </tt>
<a name="L551"></a><tt class="py-lineno"> 551</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L552"></a><tt class="py-lineno"> 552</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import tempfile, shutil</tt> </tt>
<a name="L553"></a><tt class="py-lineno"> 553</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; parquetFile = tempfile.mkdtemp()</tt> </tt>
<a name="L554"></a><tt class="py-lineno"> 554</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; shutil.rmtree(parquetFile)</tt> </tt>
<a name="L555"></a><tt class="py-lineno"> 555</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L556"></a><tt class="py-lineno"> 556</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.saveAsParquetFile(parquetFile)</tt> </tt>
<a name="L557"></a><tt class="py-lineno"> 557</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.parquetFile(parquetFile)</tt> </tt>
<a name="L558"></a><tt class="py-lineno"> 558</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd.collect()) == sorted(srdd2.collect())</tt> </tt>
<a name="L559"></a><tt class="py-lineno"> 559</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L560"></a><tt class="py-lineno"> 560</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L561"></a><tt class="py-lineno"> 561</tt>  <tt class="py-line">        <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-78" class="py-name" targets="Method pyspark.sql.SQLContext.parquetFile()=pyspark.sql.SQLContext-class.html#parquetFile"><a title="pyspark.sql.SQLContext.parquetFile" class="py-name" href="#" onclick="return doclink('link-78', 'parquetFile', 'link-78');">parquetFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">)</tt> </tt>
<a name="L562"></a><tt class="py-lineno"> 562</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-79" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-79', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L563"></a><tt class="py-lineno"> 563</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.jsonFile"></a><div id="SQLContext.jsonFile-def"><a name="L564"></a><tt class="py-lineno"> 564</tt> <a class="py-toggle" href="#" id="SQLContext.jsonFile-toggle" onclick="return toggle('SQLContext.jsonFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#jsonFile">jsonFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">path</tt><tt class="py-op">,</tt> <tt class="py-param">schema</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.jsonFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.jsonFile-expanded"><a name="L565"></a><tt class="py-lineno"> 565</tt>  <tt class="py-line">        <tt class="py-docstring">"""Loads a text file storing one JSON object per line as a L{SchemaRDD}.</tt> </tt>
<a name="L566"></a><tt class="py-lineno"> 566</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L567"></a><tt class="py-lineno"> 567</tt>  <tt class="py-line"><tt class="py-docstring">        If the schema is provided, applies the given schema to this JSON dataset.</tt> </tt>
<a name="L568"></a><tt class="py-lineno"> 568</tt>  <tt class="py-line"><tt class="py-docstring">        Otherwise, it goes through the entire dataset once to determine the schema.</tt> </tt>
<a name="L569"></a><tt class="py-lineno"> 569</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L570"></a><tt class="py-lineno"> 570</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import tempfile, shutil</tt> </tt>
<a name="L571"></a><tt class="py-lineno"> 571</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; jsonFile = tempfile.mkdtemp()</tt> </tt>
<a name="L572"></a><tt class="py-lineno"> 572</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; shutil.rmtree(jsonFile)</tt> </tt>
<a name="L573"></a><tt class="py-lineno"> 573</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ofn = open(jsonFile, 'w')</tt> </tt>
<a name="L574"></a><tt class="py-lineno"> 574</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; for json in jsonStrings:</tt> </tt>
<a name="L575"></a><tt class="py-lineno"> 575</tt>  <tt class="py-line"><tt class="py-docstring">        ...   print&gt;&gt;ofn, json</tt> </tt>
<a name="L576"></a><tt class="py-lineno"> 576</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ofn.close()</tt> </tt>
<a name="L577"></a><tt class="py-lineno"> 577</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd1 = sqlCtx.jsonFile(jsonFile)</tt> </tt>
<a name="L578"></a><tt class="py-lineno"> 578</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd1, "table1")</tt> </tt>
<a name="L579"></a><tt class="py-lineno"> 579</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql(</tt> </tt>
<a name="L580"></a><tt class="py-lineno"> 580</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, field6 as f4 from table1")</tt> </tt>
<a name="L581"></a><tt class="py-lineno"> 581</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2.collect() == [</tt> </tt>
<a name="L582"></a><tt class="py-lineno"> 582</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":1, "f2":"row1", "f3":{"field4":11, "field5": None}, "f4":None},</tt> </tt>
<a name="L583"></a><tt class="py-lineno"> 583</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":2, "f2":None, "f3":{"field4":22,  "field5": [10, 11]}, "f4":[{"field7": "row2"}]},</tt> </tt>
<a name="L584"></a><tt class="py-lineno"> 584</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":None, "f2":"row3", "f3":{"field4":33, "field5": []}, "f4":None}]</tt> </tt>
<a name="L585"></a><tt class="py-lineno"> 585</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L586"></a><tt class="py-lineno"> 586</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd3 = sqlCtx.jsonFile(jsonFile, srdd1.schema())</tt> </tt>
<a name="L587"></a><tt class="py-lineno"> 587</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd3, "table2")</tt> </tt>
<a name="L588"></a><tt class="py-lineno"> 588</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd4 = sqlCtx.sql(</tt> </tt>
<a name="L589"></a><tt class="py-lineno"> 589</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, field6 as f4 from table2")</tt> </tt>
<a name="L590"></a><tt class="py-lineno"> 590</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd4.collect() == [</tt> </tt>
<a name="L591"></a><tt class="py-lineno"> 591</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":1, "f2":"row1", "f3":{"field4":11, "field5": None}, "f4":None},</tt> </tt>
<a name="L592"></a><tt class="py-lineno"> 592</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":2, "f2":None, "f3":{"field4":22,  "field5": [10, 11]}, "f4":[{"field7": "row2"}]},</tt> </tt>
<a name="L593"></a><tt class="py-lineno"> 593</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":None, "f2":"row3", "f3":{"field4":33, "field5": []}, "f4":None}]</tt> </tt>
<a name="L594"></a><tt class="py-lineno"> 594</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L595"></a><tt class="py-lineno"> 595</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = StructType([</tt> </tt>
<a name="L596"></a><tt class="py-lineno"> 596</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field2", StringType(), True),</tt> </tt>
<a name="L597"></a><tt class="py-lineno"> 597</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field3",</tt> </tt>
<a name="L598"></a><tt class="py-lineno"> 598</tt>  <tt class="py-line"><tt class="py-docstring">        ...         StructType([</tt> </tt>
<a name="L599"></a><tt class="py-lineno"> 599</tt>  <tt class="py-line"><tt class="py-docstring">        ...             StructField("field5", ArrayType(IntegerType(), False), True)]), False)])</tt> </tt>
<a name="L600"></a><tt class="py-lineno"> 600</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd5 = sqlCtx.jsonFile(jsonFile, schema)</tt> </tt>
<a name="L601"></a><tt class="py-lineno"> 601</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd5, "table3")</tt> </tt>
<a name="L602"></a><tt class="py-lineno"> 602</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6 = sqlCtx.sql(</tt> </tt>
<a name="L603"></a><tt class="py-lineno"> 603</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field2 AS f1, field3.field5 as f2, field3.field5[0] as f3 from table3")</tt> </tt>
<a name="L604"></a><tt class="py-lineno"> 604</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6.collect() == [</tt> </tt>
<a name="L605"></a><tt class="py-lineno"> 605</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1": "row1", "f2": None, "f3": None},</tt> </tt>
<a name="L606"></a><tt class="py-lineno"> 606</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1": None, "f2": [10, 11], "f3": 10},</tt> </tt>
<a name="L607"></a><tt class="py-lineno"> 607</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1": "row3", "f2": [], "f3": None}]</tt> </tt>
<a name="L608"></a><tt class="py-lineno"> 608</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L609"></a><tt class="py-lineno"> 609</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L610"></a><tt class="py-lineno"> 610</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-80" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-80', 'schema', 'link-72');">schema</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L611"></a><tt class="py-lineno"> 611</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-81" class="py-name" targets="Method pyspark.sql.SQLContext.jsonFile()=pyspark.sql.SQLContext-class.html#jsonFile"><a title="pyspark.sql.SQLContext.jsonFile" class="py-name" href="#" onclick="return doclink('link-81', 'jsonFile', 'link-81');">jsonFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">)</tt> </tt>
<a name="L612"></a><tt class="py-lineno"> 612</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L613"></a><tt class="py-lineno"> 613</tt>  <tt class="py-line">            <tt class="py-name">scala_datatype</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt class="py-name">parseDataType</tt><tt class="py-op">(</tt><tt id="link-82" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-82', 'schema', 'link-72');">schema</a></tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L614"></a><tt class="py-lineno"> 614</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-83" class="py-name"><a title="pyspark.sql.SQLContext.jsonFile" class="py-name" href="#" onclick="return doclink('link-83', 'jsonFile', 'link-81');">jsonFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">,</tt> <tt class="py-name">scala_datatype</tt><tt class="py-op">)</tt> </tt>
<a name="L615"></a><tt class="py-lineno"> 615</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-84" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-84', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L616"></a><tt class="py-lineno"> 616</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.jsonRDD"></a><div id="SQLContext.jsonRDD-def"><a name="L617"></a><tt class="py-lineno"> 617</tt> <a class="py-toggle" href="#" id="SQLContext.jsonRDD-toggle" onclick="return toggle('SQLContext.jsonRDD');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#jsonRDD">jsonRDD</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">,</tt> <tt class="py-param">schema</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.jsonRDD-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.jsonRDD-expanded"><a name="L618"></a><tt class="py-lineno"> 618</tt>  <tt class="py-line">        <tt class="py-docstring">"""Loads an RDD storing one JSON object per string as a L{SchemaRDD}.</tt> </tt>
<a name="L619"></a><tt class="py-lineno"> 619</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L620"></a><tt class="py-lineno"> 620</tt>  <tt class="py-line"><tt class="py-docstring">        If the schema is provided, applies the given schema to this JSON dataset.</tt> </tt>
<a name="L621"></a><tt class="py-lineno"> 621</tt>  <tt class="py-line"><tt class="py-docstring">        Otherwise, it goes through the entire dataset once to determine the schema.</tt> </tt>
<a name="L622"></a><tt class="py-lineno"> 622</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L623"></a><tt class="py-lineno"> 623</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd1 = sqlCtx.jsonRDD(json)</tt> </tt>
<a name="L624"></a><tt class="py-lineno"> 624</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd1, "table1")</tt> </tt>
<a name="L625"></a><tt class="py-lineno"> 625</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql(</tt> </tt>
<a name="L626"></a><tt class="py-lineno"> 626</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, field6 as f4 from table1")</tt> </tt>
<a name="L627"></a><tt class="py-lineno"> 627</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2.collect() == [</tt> </tt>
<a name="L628"></a><tt class="py-lineno"> 628</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":1, "f2":"row1", "f3":{"field4":11, "field5": None}, "f4":None},</tt> </tt>
<a name="L629"></a><tt class="py-lineno"> 629</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":2, "f2":None, "f3":{"field4":22,  "field5": [10, 11]}, "f4":[{"field7": "row2"}]},</tt> </tt>
<a name="L630"></a><tt class="py-lineno"> 630</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":None, "f2":"row3", "f3":{"field4":33, "field5": []}, "f4":None}]</tt> </tt>
<a name="L631"></a><tt class="py-lineno"> 631</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L632"></a><tt class="py-lineno"> 632</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd3 = sqlCtx.jsonRDD(json, srdd1.schema())</tt> </tt>
<a name="L633"></a><tt class="py-lineno"> 633</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd3, "table2")</tt> </tt>
<a name="L634"></a><tt class="py-lineno"> 634</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd4 = sqlCtx.sql(</tt> </tt>
<a name="L635"></a><tt class="py-lineno"> 635</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, field6 as f4 from table2")</tt> </tt>
<a name="L636"></a><tt class="py-lineno"> 636</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd4.collect() == [</tt> </tt>
<a name="L637"></a><tt class="py-lineno"> 637</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":1, "f2":"row1", "f3":{"field4":11, "field5": None}, "f4":None},</tt> </tt>
<a name="L638"></a><tt class="py-lineno"> 638</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":2, "f2":None, "f3":{"field4":22,  "field5": [10, 11]}, "f4":[{"field7": "row2"}]},</tt> </tt>
<a name="L639"></a><tt class="py-lineno"> 639</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1":None, "f2":"row3", "f3":{"field4":33, "field5": []}, "f4":None}]</tt> </tt>
<a name="L640"></a><tt class="py-lineno"> 640</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L641"></a><tt class="py-lineno"> 641</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = StructType([</tt> </tt>
<a name="L642"></a><tt class="py-lineno"> 642</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field2", StringType(), True),</tt> </tt>
<a name="L643"></a><tt class="py-lineno"> 643</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field3",</tt> </tt>
<a name="L644"></a><tt class="py-lineno"> 644</tt>  <tt class="py-line"><tt class="py-docstring">        ...         StructType([</tt> </tt>
<a name="L645"></a><tt class="py-lineno"> 645</tt>  <tt class="py-line"><tt class="py-docstring">        ...             StructField("field5", ArrayType(IntegerType(), False), True)]), False)])</tt> </tt>
<a name="L646"></a><tt class="py-lineno"> 646</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd5 = sqlCtx.jsonRDD(json, schema)</tt> </tt>
<a name="L647"></a><tt class="py-lineno"> 647</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd5, "table3")</tt> </tt>
<a name="L648"></a><tt class="py-lineno"> 648</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6 = sqlCtx.sql(</tt> </tt>
<a name="L649"></a><tt class="py-lineno"> 649</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field2 AS f1, field3.field5 as f2, field3.field5[0] as f3 from table3")</tt> </tt>
<a name="L650"></a><tt class="py-lineno"> 650</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6.collect() == [</tt> </tt>
<a name="L651"></a><tt class="py-lineno"> 651</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1": "row1", "f2": None, "f3": None},</tt> </tt>
<a name="L652"></a><tt class="py-lineno"> 652</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1": None, "f2": [10, 11], "f3": 10},</tt> </tt>
<a name="L653"></a><tt class="py-lineno"> 653</tt>  <tt class="py-line"><tt class="py-docstring">        ... {"f1": "row3", "f2": [], "f3": None}]</tt> </tt>
<a name="L654"></a><tt class="py-lineno"> 654</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L655"></a><tt class="py-lineno"> 655</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L656"></a><tt class="py-lineno"> 656</tt>  <tt class="py-line">        <tt class="py-keyword">def</tt> <tt class="py-def-name">func</tt><tt class="py-op">(</tt><tt class="py-param">split</tt><tt class="py-op">,</tt> <tt class="py-param">iterator</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L657"></a><tt class="py-lineno"> 657</tt>  <tt class="py-line">            <tt class="py-keyword">for</tt> <tt class="py-name">x</tt> <tt class="py-keyword">in</tt> <tt class="py-name">iterator</tt><tt class="py-op">:</tt> </tt>
<a name="L658"></a><tt class="py-lineno"> 658</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-name">basestring</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L659"></a><tt class="py-lineno"> 659</tt>  <tt class="py-line">                    <tt class="py-name">x</tt> <tt class="py-op">=</tt> <tt class="py-name">unicode</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">)</tt> </tt>
<a name="L660"></a><tt class="py-lineno"> 660</tt>  <tt class="py-line">                <tt class="py-keyword">yield</tt> <tt class="py-name">x</tt><tt class="py-op">.</tt><tt class="py-name">encode</tt><tt class="py-op">(</tt><tt class="py-string">"utf-8"</tt><tt class="py-op">)</tt> </tt>
</div><a name="L661"></a><tt class="py-lineno"> 661</tt>  <tt class="py-line">        <tt class="py-name">keyed</tt> <tt class="py-op">=</tt> <tt class="py-name">PipelinedRDD</tt><tt class="py-op">(</tt><tt id="link-85" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-85', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">func</tt><tt class="py-op">)</tt> </tt>
<a name="L662"></a><tt class="py-lineno"> 662</tt>  <tt class="py-line">        <tt class="py-name">keyed</tt><tt class="py-op">.</tt><tt class="py-name">_bypass_serializer</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L663"></a><tt class="py-lineno"> 663</tt>  <tt class="py-line">        <tt class="py-name">jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">keyed</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">.</tt><tt id="link-86" class="py-name" targets="Method pyspark.rdd.RDD.map()=pyspark.rdd.RDD-class.html#map"><a title="pyspark.rdd.RDD.map" class="py-name" href="#" onclick="return doclink('link-86', 'map', 'link-86');">map</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-87" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-87', '_jvm', 'link-51');">_jvm</a></tt><tt class="py-op">.</tt><tt class="py-name">BytesToString</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L664"></a><tt class="py-lineno"> 664</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-88" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-88', 'schema', 'link-72');">schema</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L665"></a><tt class="py-lineno"> 665</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-89" class="py-name" targets="Method pyspark.sql.SQLContext.jsonRDD()=pyspark.sql.SQLContext-class.html#jsonRDD"><a title="pyspark.sql.SQLContext.jsonRDD" class="py-name" href="#" onclick="return doclink('link-89', 'jsonRDD', 'link-89');">jsonRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">.</tt><tt id="link-90" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-90', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L666"></a><tt class="py-lineno"> 666</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L667"></a><tt class="py-lineno"> 667</tt>  <tt class="py-line">            <tt class="py-name">scala_datatype</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt class="py-name">parseDataType</tt><tt class="py-op">(</tt><tt id="link-91" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-91', 'schema', 'link-72');">schema</a></tt><tt class="py-op">.</tt><tt class="py-name">_get_scala_type_string</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L668"></a><tt class="py-lineno"> 668</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-92" class="py-name"><a title="pyspark.sql.SQLContext.jsonRDD" class="py-name" href="#" onclick="return doclink('link-92', 'jsonRDD', 'link-89');">jsonRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">.</tt><tt id="link-93" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-93', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">scala_datatype</tt><tt class="py-op">)</tt> </tt>
<a name="L669"></a><tt class="py-lineno"> 669</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-94" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-94', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L670"></a><tt class="py-lineno"> 670</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.sql"></a><div id="SQLContext.sql-def"><a name="L671"></a><tt class="py-lineno"> 671</tt> <a class="py-toggle" href="#" id="SQLContext.sql-toggle" onclick="return toggle('SQLContext.sql');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#sql">sql</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.sql-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.sql-expanded"><a name="L672"></a><tt class="py-lineno"> 672</tt>  <tt class="py-line">        <tt class="py-docstring">"""Return a L{SchemaRDD} representing the result of the given query.</tt> </tt>
<a name="L673"></a><tt class="py-lineno"> 673</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L674"></a><tt class="py-lineno"> 674</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L675"></a><tt class="py-lineno"> 675</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L676"></a><tt class="py-lineno"> 676</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql("SELECT field1 AS f1, field2 as f2 from table1")</tt> </tt>
<a name="L677"></a><tt class="py-lineno"> 677</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2.collect() == [{"f1" : 1, "f2" : "row1"}, {"f1" : 2, "f2": "row2"},</tt> </tt>
<a name="L678"></a><tt class="py-lineno"> 678</tt>  <tt class="py-line"><tt class="py-docstring">        ...                     {"f1" : 3, "f2": "row3"}]</tt> </tt>
<a name="L679"></a><tt class="py-lineno"> 679</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L680"></a><tt class="py-lineno"> 680</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L681"></a><tt class="py-lineno"> 681</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-95" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-95', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-96" class="py-name" targets="Module pyspark.sql=pyspark.sql-module.html,Method pyspark.sql.SQLContext.sql()=pyspark.sql.SQLContext-class.html#sql"><a title="pyspark.sql
pyspark.sql.SQLContext.sql" class="py-name" href="#" onclick="return doclink('link-96', 'sql', 'link-96');">sql</a></tt><tt class="py-op">(</tt><tt class="py-name">sqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L682"></a><tt class="py-lineno"> 682</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.table"></a><div id="SQLContext.table-def"><a name="L683"></a><tt class="py-lineno"> 683</tt> <a class="py-toggle" href="#" id="SQLContext.table-toggle" onclick="return toggle('SQLContext.table');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#table">table</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.table-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.table-expanded"><a name="L684"></a><tt class="py-lineno"> 684</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the specified table as a L{SchemaRDD}.</tt> </tt>
<a name="L685"></a><tt class="py-lineno"> 685</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L686"></a><tt class="py-lineno"> 686</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L687"></a><tt class="py-lineno"> 687</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L688"></a><tt class="py-lineno"> 688</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.table("table1")</tt> </tt>
<a name="L689"></a><tt class="py-lineno"> 689</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd.collect()) == sorted(srdd2.collect())</tt> </tt>
<a name="L690"></a><tt class="py-lineno"> 690</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L691"></a><tt class="py-lineno"> 691</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L692"></a><tt class="py-lineno"> 692</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-97" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-97', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-98" class="py-name" targets="Method pyspark.sql.SQLContext.table()=pyspark.sql.SQLContext-class.html#table"><a title="pyspark.sql.SQLContext.table" class="py-name" href="#" onclick="return doclink('link-98', 'table', 'link-98');">table</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L693"></a><tt class="py-lineno"> 693</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.cacheTable"></a><div id="SQLContext.cacheTable-def"><a name="L694"></a><tt class="py-lineno"> 694</tt> <a class="py-toggle" href="#" id="SQLContext.cacheTable-toggle" onclick="return toggle('SQLContext.cacheTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#cacheTable">cacheTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.cacheTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.cacheTable-expanded"><a name="L695"></a><tt class="py-lineno"> 695</tt>  <tt class="py-line">        <tt class="py-docstring">"""Caches the specified table in-memory."""</tt> </tt>
<a name="L696"></a><tt class="py-lineno"> 696</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-99" class="py-name" targets="Method pyspark.sql.SQLContext.cacheTable()=pyspark.sql.SQLContext-class.html#cacheTable"><a title="pyspark.sql.SQLContext.cacheTable" class="py-name" href="#" onclick="return doclink('link-99', 'cacheTable', 'link-99');">cacheTable</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
</div><a name="L697"></a><tt class="py-lineno"> 697</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.uncacheTable"></a><div id="SQLContext.uncacheTable-def"><a name="L698"></a><tt class="py-lineno"> 698</tt> <a class="py-toggle" href="#" id="SQLContext.uncacheTable-toggle" onclick="return toggle('SQLContext.uncacheTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#uncacheTable">uncacheTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.uncacheTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.uncacheTable-expanded"><a name="L699"></a><tt class="py-lineno"> 699</tt>  <tt class="py-line">        <tt class="py-docstring">"""Removes the specified table from the in-memory cache."""</tt> </tt>
<a name="L700"></a><tt class="py-lineno"> 700</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-100" class="py-name" targets="Method pyspark.sql.SQLContext.uncacheTable()=pyspark.sql.SQLContext-class.html#uncacheTable"><a title="pyspark.sql.SQLContext.uncacheTable" class="py-name" href="#" onclick="return doclink('link-100', 'uncacheTable', 'link-100');">uncacheTable</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L701"></a><tt class="py-lineno"> 701</tt>  <tt class="py-line"> </tt>
<a name="HiveContext"></a><div id="HiveContext-def"><a name="L702"></a><tt class="py-lineno"> 702</tt>  <tt class="py-line"> </tt>
<a name="L703"></a><tt class="py-lineno"> 703</tt> <a class="py-toggle" href="#" id="HiveContext-toggle" onclick="return toggle('HiveContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html">HiveContext</a><tt class="py-op">(</tt><tt class="py-base-class">SQLContext</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="HiveContext-expanded"><a name="L704"></a><tt class="py-lineno"> 704</tt>  <tt class="py-line">    <tt class="py-docstring">"""A variant of Spark SQL that integrates with data stored in Hive.</tt> </tt>
<a name="L705"></a><tt class="py-lineno"> 705</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L706"></a><tt class="py-lineno"> 706</tt>  <tt class="py-line"><tt class="py-docstring">    Configuration for Hive is read from hive-site.xml on the classpath.</tt> </tt>
<a name="L707"></a><tt class="py-lineno"> 707</tt>  <tt class="py-line"><tt class="py-docstring">    It supports running both SQL and HiveQL commands.</tt> </tt>
<a name="L708"></a><tt class="py-lineno"> 708</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L709"></a><tt class="py-lineno"> 709</tt>  <tt class="py-line"> </tt>
<a name="L710"></a><tt class="py-lineno"> 710</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="HiveContext._ssql_ctx"></a><div id="HiveContext._ssql_ctx-def"><a name="L711"></a><tt class="py-lineno"> 711</tt> <a class="py-toggle" href="#" id="HiveContext._ssql_ctx-toggle" onclick="return toggle('HiveContext._ssql_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#_ssql_ctx">_ssql_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext._ssql_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext._ssql_ctx-expanded"><a name="L712"></a><tt class="py-lineno"> 712</tt>  <tt class="py-line">        <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L713"></a><tt class="py-lineno"> 713</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">'_scala_HiveContext'</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L714"></a><tt class="py-lineno"> 714</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_HiveContext</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_get_hive_ctx</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L715"></a><tt class="py-lineno"> 715</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_HiveContext</tt> </tt>
<a name="L716"></a><tt class="py-lineno"> 716</tt>  <tt class="py-line">        <tt class="py-keyword">except</tt> <tt class="py-name">Py4JError</tt> <tt class="py-keyword">as</tt> <tt class="py-name">e</tt><tt class="py-op">:</tt> </tt>
<a name="L717"></a><tt class="py-lineno"> 717</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">Exception</tt><tt class="py-op">(</tt><tt class="py-string">"You must build Spark with Hive. Export 'SPARK_HIVE=true' and run "</tt> </tt>
<a name="L718"></a><tt class="py-lineno"> 718</tt>  <tt class="py-line">                            <tt class="py-string">"sbt/sbt assembly"</tt><tt class="py-op">,</tt> <tt class="py-name">e</tt><tt class="py-op">)</tt> </tt>
</div><a name="L719"></a><tt class="py-lineno"> 719</tt>  <tt class="py-line"> </tt>
<a name="HiveContext._get_hive_ctx"></a><div id="HiveContext._get_hive_ctx-def"><a name="L720"></a><tt class="py-lineno"> 720</tt> <a class="py-toggle" href="#" id="HiveContext._get_hive_ctx-toggle" onclick="return toggle('HiveContext._get_hive_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#_get_hive_ctx">_get_hive_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext._get_hive_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext._get_hive_ctx-expanded"><a name="L721"></a><tt class="py-lineno"> 721</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-101" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-101', '_jvm', 'link-51');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-102" class="py-name" targets="Class pyspark.sql.HiveContext=pyspark.sql.HiveContext-class.html"><a title="pyspark.sql.HiveContext" class="py-name" href="#" onclick="return doclink('link-102', 'HiveContext', 'link-102');">HiveContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L722"></a><tt class="py-lineno"> 722</tt>  <tt class="py-line"> </tt>
<a name="HiveContext.hiveql"></a><div id="HiveContext.hiveql-def"><a name="L723"></a><tt class="py-lineno"> 723</tt> <a class="py-toggle" href="#" id="HiveContext.hiveql-toggle" onclick="return toggle('HiveContext.hiveql');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#hiveql">hiveql</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">hqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext.hiveql-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext.hiveql-expanded"><a name="L724"></a><tt class="py-lineno"> 724</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L725"></a><tt class="py-lineno"> 725</tt>  <tt class="py-line"><tt class="py-docstring">        Runs a query expressed in HiveQL, returning the result as a L{SchemaRDD}.</tt> </tt>
<a name="L726"></a><tt class="py-lineno"> 726</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L727"></a><tt class="py-lineno"> 727</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-103" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-103', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-104" class="py-name" targets="Method pyspark.sql.HiveContext.hiveql()=pyspark.sql.HiveContext-class.html#hiveql"><a title="pyspark.sql.HiveContext.hiveql" class="py-name" href="#" onclick="return doclink('link-104', 'hiveql', 'link-104');">hiveql</a></tt><tt class="py-op">(</tt><tt class="py-name">hqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L728"></a><tt class="py-lineno"> 728</tt>  <tt class="py-line"> </tt>
<a name="HiveContext.hql"></a><div id="HiveContext.hql-def"><a name="L729"></a><tt class="py-lineno"> 729</tt> <a class="py-toggle" href="#" id="HiveContext.hql-toggle" onclick="return toggle('HiveContext.hql');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#hql">hql</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">hqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext.hql-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext.hql-expanded"><a name="L730"></a><tt class="py-lineno"> 730</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L731"></a><tt class="py-lineno"> 731</tt>  <tt class="py-line"><tt class="py-docstring">        Runs a query expressed in HiveQL, returning the result as a L{SchemaRDD}.</tt> </tt>
<a name="L732"></a><tt class="py-lineno"> 732</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L733"></a><tt class="py-lineno"> 733</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-105" class="py-name"><a title="pyspark.sql.HiveContext.hiveql" class="py-name" href="#" onclick="return doclink('link-105', 'hiveql', 'link-104');">hiveql</a></tt><tt class="py-op">(</tt><tt class="py-name">hqlQuery</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L734"></a><tt class="py-lineno"> 734</tt>  <tt class="py-line"> </tt>
<a name="LocalHiveContext"></a><div id="LocalHiveContext-def"><a name="L735"></a><tt class="py-lineno"> 735</tt>  <tt class="py-line"> </tt>
<a name="L736"></a><tt class="py-lineno"> 736</tt> <a class="py-toggle" href="#" id="LocalHiveContext-toggle" onclick="return toggle('LocalHiveContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.LocalHiveContext-class.html">LocalHiveContext</a><tt class="py-op">(</tt><tt class="py-base-class">HiveContext</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LocalHiveContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="LocalHiveContext-expanded"><a name="L737"></a><tt class="py-lineno"> 737</tt>  <tt class="py-line">    <tt class="py-docstring">"""Starts up an instance of hive where metadata is stored locally.</tt> </tt>
<a name="L738"></a><tt class="py-lineno"> 738</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L739"></a><tt class="py-lineno"> 739</tt>  <tt class="py-line"><tt class="py-docstring">    An in-process metadata data is created with data stored in ./metadata.</tt> </tt>
<a name="L740"></a><tt class="py-lineno"> 740</tt>  <tt class="py-line"><tt class="py-docstring">    Warehouse data is stored in in ./warehouse.</tt> </tt>
<a name="L741"></a><tt class="py-lineno"> 741</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L742"></a><tt class="py-lineno"> 742</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; import os</tt> </tt>
<a name="L743"></a><tt class="py-lineno"> 743</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; hiveCtx = LocalHiveContext(sc)</tt> </tt>
<a name="L744"></a><tt class="py-lineno"> 744</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; try:</tt> </tt>
<a name="L745"></a><tt class="py-lineno"> 745</tt>  <tt class="py-line"><tt class="py-docstring">    ...     supress = hiveCtx.hql("DROP TABLE src")</tt> </tt>
<a name="L746"></a><tt class="py-lineno"> 746</tt>  <tt class="py-line"><tt class="py-docstring">    ... except Exception:</tt> </tt>
<a name="L747"></a><tt class="py-lineno"> 747</tt>  <tt class="py-line"><tt class="py-docstring">    ...     pass</tt> </tt>
<a name="L748"></a><tt class="py-lineno"> 748</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; kv1 = os.path.join(os.environ["SPARK_HOME"], 'examples/src/main/resources/kv1.txt')</tt> </tt>
<a name="L749"></a><tt class="py-lineno"> 749</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; supress = hiveCtx.hql("CREATE TABLE IF NOT EXISTS src (key INT, value STRING)")</tt> </tt>
<a name="L750"></a><tt class="py-lineno"> 750</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; supress = hiveCtx.hql("LOAD DATA LOCAL INPATH '%s' INTO TABLE src" % kv1)</tt> </tt>
<a name="L751"></a><tt class="py-lineno"> 751</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; results = hiveCtx.hql("FROM src SELECT value").map(lambda r: int(r.value.split('_')[1]))</tt> </tt>
<a name="L752"></a><tt class="py-lineno"> 752</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; num = results.count()</tt> </tt>
<a name="L753"></a><tt class="py-lineno"> 753</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; reduce_sum = results.reduce(lambda x, y: x + y)</tt> </tt>
<a name="L754"></a><tt class="py-lineno"> 754</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; num</tt> </tt>
<a name="L755"></a><tt class="py-lineno"> 755</tt>  <tt class="py-line"><tt class="py-docstring">    500</tt> </tt>
<a name="L756"></a><tt class="py-lineno"> 756</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; reduce_sum</tt> </tt>
<a name="L757"></a><tt class="py-lineno"> 757</tt>  <tt class="py-line"><tt class="py-docstring">    130091</tt> </tt>
<a name="L758"></a><tt class="py-lineno"> 758</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L759"></a><tt class="py-lineno"> 759</tt>  <tt class="py-line"> </tt>
<a name="LocalHiveContext._get_hive_ctx"></a><div id="LocalHiveContext._get_hive_ctx-def"><a name="L760"></a><tt class="py-lineno"> 760</tt> <a class="py-toggle" href="#" id="LocalHiveContext._get_hive_ctx-toggle" onclick="return toggle('LocalHiveContext._get_hive_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.LocalHiveContext-class.html#_get_hive_ctx">_get_hive_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LocalHiveContext._get_hive_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="LocalHiveContext._get_hive_ctx-expanded"><a name="L761"></a><tt class="py-lineno"> 761</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-106" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-106', '_jvm', 'link-51');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-107" class="py-name" targets="Class pyspark.sql.LocalHiveContext=pyspark.sql.LocalHiveContext-class.html"><a title="pyspark.sql.LocalHiveContext" class="py-name" href="#" onclick="return doclink('link-107', 'LocalHiveContext', 'link-107');">LocalHiveContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L762"></a><tt class="py-lineno"> 762</tt>  <tt class="py-line"> </tt>
<a name="TestHiveContext"></a><div id="TestHiveContext-def"><a name="L763"></a><tt class="py-lineno"> 763</tt>  <tt class="py-line"> </tt>
<a name="L764"></a><tt class="py-lineno"> 764</tt> <a class="py-toggle" href="#" id="TestHiveContext-toggle" onclick="return toggle('TestHiveContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.TestHiveContext-class.html">TestHiveContext</a><tt class="py-op">(</tt><tt class="py-base-class">HiveContext</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="TestHiveContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="TestHiveContext-expanded"><a name="L765"></a><tt class="py-lineno"> 765</tt>  <tt class="py-line"> </tt>
<a name="TestHiveContext._get_hive_ctx"></a><div id="TestHiveContext._get_hive_ctx-def"><a name="L766"></a><tt class="py-lineno"> 766</tt> <a class="py-toggle" href="#" id="TestHiveContext._get_hive_ctx-toggle" onclick="return toggle('TestHiveContext._get_hive_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.TestHiveContext-class.html#_get_hive_ctx">_get_hive_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="TestHiveContext._get_hive_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="TestHiveContext._get_hive_ctx-expanded"><a name="L767"></a><tt class="py-lineno"> 767</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-108" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-108', '_jvm', 'link-51');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-109" class="py-name" targets="Class pyspark.sql.TestHiveContext=pyspark.sql.TestHiveContext-class.html"><a title="pyspark.sql.TestHiveContext" class="py-name" href="#" onclick="return doclink('link-109', 'TestHiveContext', 'link-109');">TestHiveContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L768"></a><tt class="py-lineno"> 768</tt>  <tt class="py-line"> </tt>
<a name="Row"></a><div id="Row-def"><a name="L769"></a><tt class="py-lineno"> 769</tt>  <tt class="py-line"> </tt>
<a name="L770"></a><tt class="py-lineno"> 770</tt>  <tt class="py-line"><tt class="py-comment"># TODO: Investigate if it is more efficient to use a namedtuple. One problem is that named tuples</tt> </tt>
<a name="L771"></a><tt class="py-lineno"> 771</tt>  <tt class="py-line"><tt class="py-comment"># are custom classes that must be generated per Schema.</tt> </tt>
<a name="L772"></a><tt class="py-lineno"> 772</tt> <a class="py-toggle" href="#" id="Row-toggle" onclick="return toggle('Row');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html">Row</a><tt class="py-op">(</tt><tt class="py-base-class">dict</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="Row-expanded"><a name="L773"></a><tt class="py-lineno"> 773</tt>  <tt class="py-line">    <tt class="py-docstring">"""A row in L{SchemaRDD}.</tt> </tt>
<a name="L774"></a><tt class="py-lineno"> 774</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L775"></a><tt class="py-lineno"> 775</tt>  <tt class="py-line"><tt class="py-docstring">    An extended L{dict} that takes a L{dict} in its constructor, and</tt> </tt>
<a name="L776"></a><tt class="py-lineno"> 776</tt>  <tt class="py-line"><tt class="py-docstring">    exposes those items as fields.</tt> </tt>
<a name="L777"></a><tt class="py-lineno"> 777</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L778"></a><tt class="py-lineno"> 778</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; r = Row({"hello" : "world", "foo" : "bar"})</tt> </tt>
<a name="L779"></a><tt class="py-lineno"> 779</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; r.hello</tt> </tt>
<a name="L780"></a><tt class="py-lineno"> 780</tt>  <tt class="py-line"><tt class="py-docstring">    'world'</tt> </tt>
<a name="L781"></a><tt class="py-lineno"> 781</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; r.foo</tt> </tt>
<a name="L782"></a><tt class="py-lineno"> 782</tt>  <tt class="py-line"><tt class="py-docstring">    'bar'</tt> </tt>
<a name="L783"></a><tt class="py-lineno"> 783</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L784"></a><tt class="py-lineno"> 784</tt>  <tt class="py-line"> </tt>
<a name="Row.__init__"></a><div id="Row.__init__-def"><a name="L785"></a><tt class="py-lineno"> 785</tt> <a class="py-toggle" href="#" id="Row.__init__-toggle" onclick="return toggle('Row.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">d</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="Row.__init__-expanded"><a name="L786"></a><tt class="py-lineno"> 786</tt>  <tt class="py-line">        <tt class="py-name">d</tt><tt class="py-op">.</tt><tt class="py-name">update</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__dict__</tt><tt class="py-op">)</tt> </tt>
<a name="L787"></a><tt class="py-lineno"> 787</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__dict__</tt> <tt class="py-op">=</tt> <tt class="py-name">d</tt> </tt>
<a name="L788"></a><tt class="py-lineno"> 788</tt>  <tt class="py-line">        <tt class="py-name">dict</tt><tt class="py-op">.</tt><tt id="link-110" class="py-name" targets="Method pyspark.accumulators.Accumulator.__init__()=pyspark.accumulators.Accumulator-class.html#__init__,Method pyspark.accumulators.AddingAccumulatorParam.__init__()=pyspark.accumulators.AddingAccumulatorParam-class.html#__init__,Method pyspark.broadcast.Broadcast.__init__()=pyspark.broadcast.Broadcast-class.html#__init__,Method pyspark.conf.SparkConf.__init__()=pyspark.conf.SparkConf-class.html#__init__,Method pyspark.context.SparkContext.__init__()=pyspark.context.SparkContext-class.html#__init__,Method pyspark.files.SparkFiles.__init__()=pyspark.files.SparkFiles-class.html#__init__,Method pyspark.mllib.classification.NaiveBayesModel.__init__()=pyspark.mllib.classification.NaiveBayesModel-class.html#__init__,Method pyspark.mllib.clustering.KMeansModel.__init__()=pyspark.mllib.clustering.KMeansModel-class.html#__init__,Method pyspark.mllib.linalg.SparseVector.__init__()=pyspark.mllib.linalg.SparseVector-class.html#__init__,Method pyspark.mllib.recommendation.MatrixFactorizationModel.__init__()=pyspark.mllib.recommendation.MatrixFactorizationModel-class.html#__init__,Method pyspark.mllib.regression.LabeledPoint.__init__()=pyspark.mllib.regression.LabeledPoint-class.html#__init__,Method pyspark.mllib.regression.LinearModel.__init__()=pyspark.mllib.regression.LinearModel-class.html#__init__,Method pyspark.rdd.RDD.__init__()=pyspark.rdd.RDD-class.html#__init__,Method pyspark.resultiterable.ResultIterable.__init__()=pyspark.resultiterable.ResultIterable-class.html#__init__,Method pyspark.sql.ArrayType.__init__()=pyspark.sql.ArrayType-class.html#__init__,Method pyspark.sql.MapType.__init__()=pyspark.sql.MapType-class.html#__init__,Method pyspark.sql.Row.__init__()=pyspark.sql.Row-class.html#__init__,Method pyspark.sql.SQLContext.__init__()=pyspark.sql.SQLContext-class.html#__init__,Method pyspark.sql.SchemaRDD.__init__()=pyspark.sql.SchemaRDD-class.html#__init__,Method pyspark.sql.StructField.__init__()=pyspark.sql.StructField-class.html#__init__,Method pyspark.sql.StructType.__init__()=pyspark.sql.StructType-class.html#__init__,Method pyspark.statcounter.StatCounter.__init__()=pyspark.statcounter.StatCounter-class.html#__init__,Method pyspark.storagelevel.StorageLevel.__init__()=pyspark.storagelevel.StorageLevel-class.html#__init__"><a title="pyspark.accumulators.Accumulator.__init__
pyspark.accumulators.AddingAccumulatorParam.__init__
pyspark.broadcast.Broadcast.__init__
pyspark.conf.SparkConf.__init__
pyspark.context.SparkContext.__init__
pyspark.files.SparkFiles.__init__
pyspark.mllib.classification.NaiveBayesModel.__init__
pyspark.mllib.clustering.KMeansModel.__init__
pyspark.mllib.linalg.SparseVector.__init__
pyspark.mllib.recommendation.MatrixFactorizationModel.__init__
pyspark.mllib.regression.LabeledPoint.__init__
pyspark.mllib.regression.LinearModel.__init__
pyspark.rdd.RDD.__init__
pyspark.resultiterable.ResultIterable.__init__
pyspark.sql.ArrayType.__init__
pyspark.sql.MapType.__init__
pyspark.sql.Row.__init__
pyspark.sql.SQLContext.__init__
pyspark.sql.SchemaRDD.__init__
pyspark.sql.StructField.__init__
pyspark.sql.StructType.__init__
pyspark.statcounter.StatCounter.__init__
pyspark.storagelevel.StorageLevel.__init__" class="py-name" href="#" onclick="return doclink('link-110', '__init__', 'link-110');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">d</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L789"></a><tt class="py-lineno"> 789</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD"></a><div id="SchemaRDD-def"><a name="L790"></a><tt class="py-lineno"> 790</tt>  <tt class="py-line"> </tt>
<a name="L791"></a><tt class="py-lineno"> 791</tt> <a class="py-toggle" href="#" id="SchemaRDD-toggle" onclick="return toggle('SchemaRDD');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html">SchemaRDD</a><tt class="py-op">(</tt><tt class="py-base-class">RDD</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="SchemaRDD-expanded"><a name="L792"></a><tt class="py-lineno"> 792</tt>  <tt class="py-line">    <tt class="py-docstring">"""An RDD of L{Row} objects that has an associated schema.</tt> </tt>
<a name="L793"></a><tt class="py-lineno"> 793</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L794"></a><tt class="py-lineno"> 794</tt>  <tt class="py-line"><tt class="py-docstring">    The underlying JVM object is a SchemaRDD, not a PythonRDD, so we can</tt> </tt>
<a name="L795"></a><tt class="py-lineno"> 795</tt>  <tt class="py-line"><tt class="py-docstring">    utilize the relational query api exposed by SparkSQL.</tt> </tt>
<a name="L796"></a><tt class="py-lineno"> 796</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L797"></a><tt class="py-lineno"> 797</tt>  <tt class="py-line"><tt class="py-docstring">    For normal L{pyspark.rdd.RDD} operations (map, count, etc.) the</tt> </tt>
<a name="L798"></a><tt class="py-lineno"> 798</tt>  <tt class="py-line"><tt class="py-docstring">    L{SchemaRDD} is not operated on directly, as it's underlying</tt> </tt>
<a name="L799"></a><tt class="py-lineno"> 799</tt>  <tt class="py-line"><tt class="py-docstring">    implementation is an RDD composed of Java objects. Instead it is</tt> </tt>
<a name="L800"></a><tt class="py-lineno"> 800</tt>  <tt class="py-line"><tt class="py-docstring">    converted to a PythonRDD in the JVM, on which Python operations can</tt> </tt>
<a name="L801"></a><tt class="py-lineno"> 801</tt>  <tt class="py-line"><tt class="py-docstring">    be done.</tt> </tt>
<a name="L802"></a><tt class="py-lineno"> 802</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L803"></a><tt class="py-lineno"> 803</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.__init__"></a><div id="SchemaRDD.__init__-def"><a name="L804"></a><tt class="py-lineno"> 804</tt> <a class="py-toggle" href="#" id="SchemaRDD.__init__-toggle" onclick="return toggle('SchemaRDD.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-param">sql_ctx</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.__init__-expanded"><a name="L805"></a><tt class="py-lineno"> 805</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt> <tt class="py-op">=</tt> <tt class="py-name">sql_ctx</tt> </tt>
<a name="L806"></a><tt class="py-lineno"> 806</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-111" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-111', '_sc', 'link-49');">_sc</a></tt> <tt class="py-op">=</tt> <tt class="py-name">sql_ctx</tt><tt class="py-op">.</tt><tt id="link-112" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-112', '_sc', 'link-49');">_sc</a></tt> </tt>
<a name="L807"></a><tt class="py-lineno"> 807</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">jschema_rdd</tt> </tt>
<a name="L808"></a><tt class="py-lineno"> 808</tt>  <tt class="py-line"> </tt>
<a name="L809"></a><tt class="py-lineno"> 809</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L810"></a><tt class="py-lineno"> 810</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_checkpointed</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L811"></a><tt class="py-lineno"> 811</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">ctx</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">.</tt><tt id="link-113" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-113', '_sc', 'link-49');">_sc</a></tt> </tt>
<a name="L812"></a><tt class="py-lineno"> 812</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd_deserializer</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">ctx</tt><tt class="py-op">.</tt><tt class="py-name">serializer</tt> </tt>
</div><a name="L813"></a><tt class="py-lineno"> 813</tt>  <tt class="py-line"> </tt>
<a name="L814"></a><tt class="py-lineno"> 814</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="SchemaRDD._jrdd"></a><div id="SchemaRDD._jrdd-def"><a name="L815"></a><tt class="py-lineno"> 815</tt> <a class="py-toggle" href="#" id="SchemaRDD._jrdd-toggle" onclick="return toggle('SchemaRDD._jrdd');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#_jrdd">_jrdd</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD._jrdd-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD._jrdd-expanded"><a name="L816"></a><tt class="py-lineno"> 816</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lazy evaluation of PythonRDD object.</tt> </tt>
<a name="L817"></a><tt class="py-lineno"> 817</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L818"></a><tt class="py-lineno"> 818</tt>  <tt class="py-line"><tt class="py-docstring">        Only done when a user calls methods defined by the</tt> </tt>
<a name="L819"></a><tt class="py-lineno"> 819</tt>  <tt class="py-line"><tt class="py-docstring">        L{pyspark.rdd.RDD} super class (map, filter, etc.).</tt> </tt>
<a name="L820"></a><tt class="py-lineno"> 820</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L821"></a><tt class="py-lineno"> 821</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">'_lazy_jrdd'</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L822"></a><tt class="py-lineno"> 822</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lazy_jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_toPython</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt> </tt>
<a name="L823"></a><tt class="py-lineno"> 823</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lazy_jrdd</tt> </tt>
</div><a name="L824"></a><tt class="py-lineno"> 824</tt>  <tt class="py-line"> </tt>
<a name="L825"></a><tt class="py-lineno"> 825</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="SchemaRDD._id"></a><div id="SchemaRDD._id-def"><a name="L826"></a><tt class="py-lineno"> 826</tt> <a class="py-toggle" href="#" id="SchemaRDD._id-toggle" onclick="return toggle('SchemaRDD._id');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#_id">_id</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD._id-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD._id-expanded"><a name="L827"></a><tt class="py-lineno"> 827</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">.</tt><tt id="link-114" class="py-name" targets="Method pyspark.rdd.RDD.id()=pyspark.rdd.RDD-class.html#id"><a title="pyspark.rdd.RDD.id" class="py-name" href="#" onclick="return doclink('link-114', 'id', 'link-114');">id</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L828"></a><tt class="py-lineno"> 828</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.saveAsParquetFile"></a><div id="SchemaRDD.saveAsParquetFile-def"><a name="L829"></a><tt class="py-lineno"> 829</tt> <a class="py-toggle" href="#" id="SchemaRDD.saveAsParquetFile-toggle" onclick="return toggle('SchemaRDD.saveAsParquetFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#saveAsParquetFile">saveAsParquetFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">path</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.saveAsParquetFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.saveAsParquetFile-expanded"><a name="L830"></a><tt class="py-lineno"> 830</tt>  <tt class="py-line">        <tt class="py-docstring">"""Save the contents as a Parquet file, preserving the schema.</tt> </tt>
<a name="L831"></a><tt class="py-lineno"> 831</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L832"></a><tt class="py-lineno"> 832</tt>  <tt class="py-line"><tt class="py-docstring">        Files that are written out using this method can be read back in as</tt> </tt>
<a name="L833"></a><tt class="py-lineno"> 833</tt>  <tt class="py-line"><tt class="py-docstring">        a SchemaRDD using the L{SQLContext.parquetFile} method.</tt> </tt>
<a name="L834"></a><tt class="py-lineno"> 834</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L835"></a><tt class="py-lineno"> 835</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import tempfile, shutil</tt> </tt>
<a name="L836"></a><tt class="py-lineno"> 836</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; parquetFile = tempfile.mkdtemp()</tt> </tt>
<a name="L837"></a><tt class="py-lineno"> 837</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; shutil.rmtree(parquetFile)</tt> </tt>
<a name="L838"></a><tt class="py-lineno"> 838</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L839"></a><tt class="py-lineno"> 839</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.saveAsParquetFile(parquetFile)</tt> </tt>
<a name="L840"></a><tt class="py-lineno"> 840</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.parquetFile(parquetFile)</tt> </tt>
<a name="L841"></a><tt class="py-lineno"> 841</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd2.collect()) == sorted(srdd.collect())</tt> </tt>
<a name="L842"></a><tt class="py-lineno"> 842</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L843"></a><tt class="py-lineno"> 843</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L844"></a><tt class="py-lineno"> 844</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-115" class="py-name" targets="Method pyspark.sql.SchemaRDD.saveAsParquetFile()=pyspark.sql.SchemaRDD-class.html#saveAsParquetFile"><a title="pyspark.sql.SchemaRDD.saveAsParquetFile" class="py-name" href="#" onclick="return doclink('link-115', 'saveAsParquetFile', 'link-115');">saveAsParquetFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">)</tt> </tt>
</div><a name="L845"></a><tt class="py-lineno"> 845</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.registerAsTable"></a><div id="SchemaRDD.registerAsTable-def"><a name="L846"></a><tt class="py-lineno"> 846</tt> <a class="py-toggle" href="#" id="SchemaRDD.registerAsTable-toggle" onclick="return toggle('SchemaRDD.registerAsTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#registerAsTable">registerAsTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">name</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.registerAsTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.registerAsTable-expanded"><a name="L847"></a><tt class="py-lineno"> 847</tt>  <tt class="py-line">        <tt class="py-docstring">"""Registers this RDD as a temporary table using the given name.</tt> </tt>
<a name="L848"></a><tt class="py-lineno"> 848</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L849"></a><tt class="py-lineno"> 849</tt>  <tt class="py-line"><tt class="py-docstring">        The lifetime of this temporary table is tied to the L{SQLContext}</tt> </tt>
<a name="L850"></a><tt class="py-lineno"> 850</tt>  <tt class="py-line"><tt class="py-docstring">        that was used to create this SchemaRDD.</tt> </tt>
<a name="L851"></a><tt class="py-lineno"> 851</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L852"></a><tt class="py-lineno"> 852</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L853"></a><tt class="py-lineno"> 853</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.registerAsTable("test")</tt> </tt>
<a name="L854"></a><tt class="py-lineno"> 854</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql("select * from test")</tt> </tt>
<a name="L855"></a><tt class="py-lineno"> 855</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd.collect()) == sorted(srdd2.collect())</tt> </tt>
<a name="L856"></a><tt class="py-lineno"> 856</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L857"></a><tt class="py-lineno"> 857</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L858"></a><tt class="py-lineno"> 858</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-116" class="py-name" targets="Method pyspark.sql.SchemaRDD.registerAsTable()=pyspark.sql.SchemaRDD-class.html#registerAsTable"><a title="pyspark.sql.SchemaRDD.registerAsTable" class="py-name" href="#" onclick="return doclink('link-116', 'registerAsTable', 'link-116');">registerAsTable</a></tt><tt class="py-op">(</tt><tt id="link-117" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-117', 'name', 'link-25');">name</a></tt><tt class="py-op">)</tt> </tt>
</div><a name="L859"></a><tt class="py-lineno"> 859</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.insertInto"></a><div id="SchemaRDD.insertInto-def"><a name="L860"></a><tt class="py-lineno"> 860</tt> <a class="py-toggle" href="#" id="SchemaRDD.insertInto-toggle" onclick="return toggle('SchemaRDD.insertInto');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#insertInto">insertInto</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">,</tt> <tt class="py-param">overwrite</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.insertInto-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.insertInto-expanded"><a name="L861"></a><tt class="py-lineno"> 861</tt>  <tt class="py-line">        <tt class="py-docstring">"""Inserts the contents of this SchemaRDD into the specified table.</tt> </tt>
<a name="L862"></a><tt class="py-lineno"> 862</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L863"></a><tt class="py-lineno"> 863</tt>  <tt class="py-line"><tt class="py-docstring">        Optionally overwriting any existing data.</tt> </tt>
<a name="L864"></a><tt class="py-lineno"> 864</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L865"></a><tt class="py-lineno"> 865</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-118" class="py-name" targets="Method pyspark.sql.SchemaRDD.insertInto()=pyspark.sql.SchemaRDD-class.html#insertInto"><a title="pyspark.sql.SchemaRDD.insertInto" class="py-name" href="#" onclick="return doclink('link-118', 'insertInto', 'link-118');">insertInto</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">,</tt> <tt class="py-name">overwrite</tt><tt class="py-op">)</tt> </tt>
</div><a name="L866"></a><tt class="py-lineno"> 866</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.saveAsTable"></a><div id="SchemaRDD.saveAsTable-def"><a name="L867"></a><tt class="py-lineno"> 867</tt> <a class="py-toggle" href="#" id="SchemaRDD.saveAsTable-toggle" onclick="return toggle('SchemaRDD.saveAsTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#saveAsTable">saveAsTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.saveAsTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.saveAsTable-expanded"><a name="L868"></a><tt class="py-lineno"> 868</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a new table with the contents of this SchemaRDD."""</tt> </tt>
<a name="L869"></a><tt class="py-lineno"> 869</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-119" class="py-name" targets="Method pyspark.sql.SchemaRDD.saveAsTable()=pyspark.sql.SchemaRDD-class.html#saveAsTable"><a title="pyspark.sql.SchemaRDD.saveAsTable" class="py-name" href="#" onclick="return doclink('link-119', 'saveAsTable', 'link-119');">saveAsTable</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
</div><a name="L870"></a><tt class="py-lineno"> 870</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.schema"></a><div id="SchemaRDD.schema-def"><a name="L871"></a><tt class="py-lineno"> 871</tt> <a class="py-toggle" href="#" id="SchemaRDD.schema-toggle" onclick="return toggle('SchemaRDD.schema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#schema">schema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.schema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.schema-expanded"><a name="L872"></a><tt class="py-lineno"> 872</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the schema of this SchemaRDD (represented by a L{StructType})."""</tt> </tt>
<a name="L873"></a><tt class="py-lineno"> 873</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-120" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-120', 'schema', 'link-72');">schema</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">toString</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L874"></a><tt class="py-lineno"> 874</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.schemaString"></a><div id="SchemaRDD.schemaString-def"><a name="L875"></a><tt class="py-lineno"> 875</tt> <a class="py-toggle" href="#" id="SchemaRDD.schemaString-toggle" onclick="return toggle('SchemaRDD.schemaString');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#schemaString">schemaString</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.schemaString-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.schemaString-expanded"><a name="L876"></a><tt class="py-lineno"> 876</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the output schema in the tree format."""</tt> </tt>
<a name="L877"></a><tt class="py-lineno"> 877</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-121" class="py-name" targets="Method pyspark.sql.SchemaRDD.schemaString()=pyspark.sql.SchemaRDD-class.html#schemaString"><a title="pyspark.sql.SchemaRDD.schemaString" class="py-name" href="#" onclick="return doclink('link-121', 'schemaString', 'link-121');">schemaString</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L878"></a><tt class="py-lineno"> 878</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.printSchema"></a><div id="SchemaRDD.printSchema-def"><a name="L879"></a><tt class="py-lineno"> 879</tt> <a class="py-toggle" href="#" id="SchemaRDD.printSchema-toggle" onclick="return toggle('SchemaRDD.printSchema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#printSchema">printSchema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.printSchema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.printSchema-expanded"><a name="L880"></a><tt class="py-lineno"> 880</tt>  <tt class="py-line">        <tt class="py-docstring">"""Prints out the schema in the tree format."""</tt> </tt>
<a name="L881"></a><tt class="py-lineno"> 881</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-122" class="py-name"><a title="pyspark.sql.SchemaRDD.schemaString" class="py-name" href="#" onclick="return doclink('link-122', 'schemaString', 'link-121');">schemaString</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L882"></a><tt class="py-lineno"> 882</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.count"></a><div id="SchemaRDD.count-def"><a name="L883"></a><tt class="py-lineno"> 883</tt> <a class="py-toggle" href="#" id="SchemaRDD.count-toggle" onclick="return toggle('SchemaRDD.count');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#count">count</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.count-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.count-expanded"><a name="L884"></a><tt class="py-lineno"> 884</tt>  <tt class="py-line">        <tt class="py-docstring">"""Return the number of elements in this RDD.</tt> </tt>
<a name="L885"></a><tt class="py-lineno"> 885</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L886"></a><tt class="py-lineno"> 886</tt>  <tt class="py-line"><tt class="py-docstring">        Unlike the base RDD implementation of count, this implementation</tt> </tt>
<a name="L887"></a><tt class="py-lineno"> 887</tt>  <tt class="py-line"><tt class="py-docstring">        leverages the query optimizer to compute the count on the SchemaRDD,</tt> </tt>
<a name="L888"></a><tt class="py-lineno"> 888</tt>  <tt class="py-line"><tt class="py-docstring">        which supports features such as filter pushdown.</tt> </tt>
<a name="L889"></a><tt class="py-lineno"> 889</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L890"></a><tt class="py-lineno"> 890</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L891"></a><tt class="py-lineno"> 891</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.count()</tt> </tt>
<a name="L892"></a><tt class="py-lineno"> 892</tt>  <tt class="py-line"><tt class="py-docstring">        3L</tt> </tt>
<a name="L893"></a><tt class="py-lineno"> 893</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.count() == srdd.map(lambda x: x).count()</tt> </tt>
<a name="L894"></a><tt class="py-lineno"> 894</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L895"></a><tt class="py-lineno"> 895</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L896"></a><tt class="py-lineno"> 896</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-123" class="py-name" targets="Method pyspark.rdd.RDD.count()=pyspark.rdd.RDD-class.html#count,Method pyspark.sql.SchemaRDD.count()=pyspark.sql.SchemaRDD-class.html#count,Method pyspark.statcounter.StatCounter.count()=pyspark.statcounter.StatCounter-class.html#count"><a title="pyspark.rdd.RDD.count
pyspark.sql.SchemaRDD.count
pyspark.statcounter.StatCounter.count" class="py-name" href="#" onclick="return doclink('link-123', 'count', 'link-123');">count</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L897"></a><tt class="py-lineno"> 897</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD._toPython"></a><div id="SchemaRDD._toPython-def"><a name="L898"></a><tt class="py-lineno"> 898</tt> <a class="py-toggle" href="#" id="SchemaRDD._toPython-toggle" onclick="return toggle('SchemaRDD._toPython');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#_toPython">_toPython</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD._toPython-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD._toPython-expanded"><a name="L899"></a><tt class="py-lineno"> 899</tt>  <tt class="py-line">        <tt class="py-comment"># We have to import the Row class explicitly, so that the reference Pickler has is</tt> </tt>
<a name="L900"></a><tt class="py-lineno"> 900</tt>  <tt class="py-line">        <tt class="py-comment"># pyspark.sql.Row instead of __main__.Row</tt> </tt>
<a name="L901"></a><tt class="py-lineno"> 901</tt>  <tt class="py-line">        <tt class="py-keyword">from</tt> <tt id="link-124" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-124', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-125" class="py-name"><a title="pyspark.sql
pyspark.sql.SQLContext.sql" class="py-name" href="#" onclick="return doclink('link-125', 'sql', 'link-96');">sql</a></tt> <tt class="py-keyword">import</tt> <tt id="link-126" class="py-name" targets="Class pyspark.sql.Row=pyspark.sql.Row-class.html"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-126', 'Row', 'link-126');">Row</a></tt> </tt>
<a name="L902"></a><tt class="py-lineno"> 902</tt>  <tt class="py-line">        <tt class="py-name">jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt class="py-name">javaToPython</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L903"></a><tt class="py-lineno"> 903</tt>  <tt class="py-line">        <tt class="py-comment"># TODO: This is inefficient, we should construct the Python Row object</tt> </tt>
<a name="L904"></a><tt class="py-lineno"> 904</tt>  <tt class="py-line">        <tt class="py-comment"># in Java land in the javaToPython function. May require a custom</tt> </tt>
<a name="L905"></a><tt class="py-lineno"> 905</tt>  <tt class="py-line">        <tt class="py-comment"># pickle serializer in Pyrolite</tt> </tt>
<a name="L906"></a><tt class="py-lineno"> 906</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-127" class="py-name"><a title="pyspark.rdd.RDD" class="py-name" href="#" onclick="return doclink('link-127', 'RDD', 'link-2');">RDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-128" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-128', '_sc', 'link-49');">_sc</a></tt><tt class="py-op">,</tt> <tt class="py-name">BatchedSerializer</tt><tt class="py-op">(</tt> </tt>
<a name="L907"></a><tt class="py-lineno"> 907</tt>  <tt class="py-line">            <tt id="link-129" class="py-name"><a title="pyspark.serializers.PickleSerializer" class="py-name" href="#" onclick="return doclink('link-129', 'PickleSerializer', 'link-5');">PickleSerializer</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-130" class="py-name"><a title="pyspark.rdd.RDD.map" class="py-name" href="#" onclick="return doclink('link-130', 'map', 'link-86');">map</a></tt><tt class="py-op">(</tt><tt class="py-keyword">lambda</tt> <tt class="py-name">d</tt><tt class="py-op">:</tt> <tt id="link-131" class="py-name"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-131', 'Row', 'link-126');">Row</a></tt><tt class="py-op">(</tt><tt class="py-name">d</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L908"></a><tt class="py-lineno"> 908</tt>  <tt class="py-line"> </tt>
<a name="L909"></a><tt class="py-lineno"> 909</tt>  <tt class="py-line">    <tt class="py-comment"># We override the default cache/persist/checkpoint behavior as we want to cache the underlying</tt> </tt>
<a name="L910"></a><tt class="py-lineno"> 910</tt>  <tt class="py-line">    <tt class="py-comment"># SchemaRDD object in the JVM, not the PythonRDD checkpointed by the super class</tt> </tt>
<a name="SchemaRDD.cache"></a><div id="SchemaRDD.cache-def"><a name="L911"></a><tt class="py-lineno"> 911</tt> <a class="py-toggle" href="#" id="SchemaRDD.cache-toggle" onclick="return toggle('SchemaRDD.cache');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#cache">cache</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.cache-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.cache-expanded"><a name="L912"></a><tt class="py-lineno"> 912</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L913"></a><tt class="py-lineno"> 913</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-132" class="py-name" targets="Method pyspark.rdd.RDD.cache()=pyspark.rdd.RDD-class.html#cache,Method pyspark.sql.SchemaRDD.cache()=pyspark.sql.SchemaRDD-class.html#cache"><a title="pyspark.rdd.RDD.cache
pyspark.sql.SchemaRDD.cache" class="py-name" href="#" onclick="return doclink('link-132', 'cache', 'link-132');">cache</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L914"></a><tt class="py-lineno"> 914</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt> </tt>
</div><a name="L915"></a><tt class="py-lineno"> 915</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.persist"></a><div id="SchemaRDD.persist-def"><a name="L916"></a><tt class="py-lineno"> 916</tt> <a class="py-toggle" href="#" id="SchemaRDD.persist-toggle" onclick="return toggle('SchemaRDD.persist');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#persist">persist</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">storageLevel</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.persist-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.persist-expanded"><a name="L917"></a><tt class="py-lineno"> 917</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L918"></a><tt class="py-lineno"> 918</tt>  <tt class="py-line">        <tt class="py-name">javaStorageLevel</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">ctx</tt><tt class="py-op">.</tt><tt class="py-name">_getJavaStorageLevel</tt><tt class="py-op">(</tt><tt class="py-name">storageLevel</tt><tt class="py-op">)</tt> </tt>
<a name="L919"></a><tt class="py-lineno"> 919</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-133" class="py-name" targets="Method pyspark.rdd.RDD.persist()=pyspark.rdd.RDD-class.html#persist,Method pyspark.sql.SchemaRDD.persist()=pyspark.sql.SchemaRDD-class.html#persist"><a title="pyspark.rdd.RDD.persist
pyspark.sql.SchemaRDD.persist" class="py-name" href="#" onclick="return doclink('link-133', 'persist', 'link-133');">persist</a></tt><tt class="py-op">(</tt><tt class="py-name">javaStorageLevel</tt><tt class="py-op">)</tt> </tt>
<a name="L920"></a><tt class="py-lineno"> 920</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt> </tt>
</div><a name="L921"></a><tt class="py-lineno"> 921</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.unpersist"></a><div id="SchemaRDD.unpersist-def"><a name="L922"></a><tt class="py-lineno"> 922</tt> <a class="py-toggle" href="#" id="SchemaRDD.unpersist-toggle" onclick="return toggle('SchemaRDD.unpersist');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#unpersist">unpersist</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.unpersist-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.unpersist-expanded"><a name="L923"></a><tt class="py-lineno"> 923</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L924"></a><tt class="py-lineno"> 924</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-134" class="py-name" targets="Method pyspark.rdd.RDD.unpersist()=pyspark.rdd.RDD-class.html#unpersist,Method pyspark.sql.SchemaRDD.unpersist()=pyspark.sql.SchemaRDD-class.html#unpersist"><a title="pyspark.rdd.RDD.unpersist
pyspark.sql.SchemaRDD.unpersist" class="py-name" href="#" onclick="return doclink('link-134', 'unpersist', 'link-134');">unpersist</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L925"></a><tt class="py-lineno"> 925</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt> </tt>
</div><a name="L926"></a><tt class="py-lineno"> 926</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.checkpoint"></a><div id="SchemaRDD.checkpoint-def"><a name="L927"></a><tt class="py-lineno"> 927</tt> <a class="py-toggle" href="#" id="SchemaRDD.checkpoint-toggle" onclick="return toggle('SchemaRDD.checkpoint');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#checkpoint">checkpoint</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.checkpoint-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.checkpoint-expanded"><a name="L928"></a><tt class="py-lineno"> 928</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_checkpointed</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L929"></a><tt class="py-lineno"> 929</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-135" class="py-name" targets="Method pyspark.rdd.RDD.checkpoint()=pyspark.rdd.RDD-class.html#checkpoint,Method pyspark.sql.SchemaRDD.checkpoint()=pyspark.sql.SchemaRDD-class.html#checkpoint"><a title="pyspark.rdd.RDD.checkpoint
pyspark.sql.SchemaRDD.checkpoint" class="py-name" href="#" onclick="return doclink('link-135', 'checkpoint', 'link-135');">checkpoint</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L930"></a><tt class="py-lineno"> 930</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.isCheckpointed"></a><div id="SchemaRDD.isCheckpointed-def"><a name="L931"></a><tt class="py-lineno"> 931</tt> <a class="py-toggle" href="#" id="SchemaRDD.isCheckpointed-toggle" onclick="return toggle('SchemaRDD.isCheckpointed');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#isCheckpointed">isCheckpointed</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.isCheckpointed-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.isCheckpointed-expanded"><a name="L932"></a><tt class="py-lineno"> 932</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-136" class="py-name" targets="Method pyspark.rdd.RDD.isCheckpointed()=pyspark.rdd.RDD-class.html#isCheckpointed,Method pyspark.sql.SchemaRDD.isCheckpointed()=pyspark.sql.SchemaRDD-class.html#isCheckpointed"><a title="pyspark.rdd.RDD.isCheckpointed
pyspark.sql.SchemaRDD.isCheckpointed" class="py-name" href="#" onclick="return doclink('link-136', 'isCheckpointed', 'link-136');">isCheckpointed</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L933"></a><tt class="py-lineno"> 933</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.getCheckpointFile"></a><div id="SchemaRDD.getCheckpointFile-def"><a name="L934"></a><tt class="py-lineno"> 934</tt> <a class="py-toggle" href="#" id="SchemaRDD.getCheckpointFile-toggle" onclick="return toggle('SchemaRDD.getCheckpointFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#getCheckpointFile">getCheckpointFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.getCheckpointFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.getCheckpointFile-expanded"><a name="L935"></a><tt class="py-lineno"> 935</tt>  <tt class="py-line">        <tt class="py-name">checkpointFile</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-137" class="py-name" targets="Method pyspark.rdd.RDD.getCheckpointFile()=pyspark.rdd.RDD-class.html#getCheckpointFile,Method pyspark.sql.SchemaRDD.getCheckpointFile()=pyspark.sql.SchemaRDD-class.html#getCheckpointFile"><a title="pyspark.rdd.RDD.getCheckpointFile
pyspark.sql.SchemaRDD.getCheckpointFile" class="py-name" href="#" onclick="return doclink('link-137', 'getCheckpointFile', 'link-137');">getCheckpointFile</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L936"></a><tt class="py-lineno"> 936</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">checkpointFile</tt><tt class="py-op">.</tt><tt class="py-name">isDefined</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L937"></a><tt class="py-lineno"> 937</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">checkpointFile</tt><tt class="py-op">.</tt><tt id="link-138" class="py-name" targets="Method pyspark.conf.SparkConf.get()=pyspark.conf.SparkConf-class.html#get,Class Method pyspark.files.SparkFiles.get()=pyspark.files.SparkFiles-class.html#get"><a title="pyspark.conf.SparkConf.get
pyspark.files.SparkFiles.get" class="py-name" href="#" onclick="return doclink('link-138', 'get', 'link-138');">get</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L938"></a><tt class="py-lineno"> 938</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L939"></a><tt class="py-lineno"> 939</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L940"></a><tt class="py-lineno"> 940</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.coalesce"></a><div id="SchemaRDD.coalesce-def"><a name="L941"></a><tt class="py-lineno"> 941</tt> <a class="py-toggle" href="#" id="SchemaRDD.coalesce-toggle" onclick="return toggle('SchemaRDD.coalesce');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#coalesce">coalesce</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">numPartitions</tt><tt class="py-op">,</tt> <tt class="py-param">shuffle</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.coalesce-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.coalesce-expanded"><a name="L942"></a><tt class="py-lineno"> 942</tt>  <tt class="py-line">        <tt id="link-139" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-139', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-140" class="py-name" targets="Method pyspark.rdd.RDD.coalesce()=pyspark.rdd.RDD-class.html#coalesce,Method pyspark.sql.SchemaRDD.coalesce()=pyspark.sql.SchemaRDD-class.html#coalesce"><a title="pyspark.rdd.RDD.coalesce
pyspark.sql.SchemaRDD.coalesce" class="py-name" href="#" onclick="return doclink('link-140', 'coalesce', 'link-140');">coalesce</a></tt><tt class="py-op">(</tt><tt class="py-name">numPartitions</tt><tt class="py-op">,</tt> <tt class="py-name">shuffle</tt><tt class="py-op">)</tt> </tt>
<a name="L943"></a><tt class="py-lineno"> 943</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-141" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-141', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-142" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-142', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
</div><a name="L944"></a><tt class="py-lineno"> 944</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.distinct"></a><div id="SchemaRDD.distinct-def"><a name="L945"></a><tt class="py-lineno"> 945</tt> <a class="py-toggle" href="#" id="SchemaRDD.distinct-toggle" onclick="return toggle('SchemaRDD.distinct');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#distinct">distinct</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.distinct-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.distinct-expanded"><a name="L946"></a><tt class="py-lineno"> 946</tt>  <tt class="py-line">        <tt id="link-143" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-143', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-144" class="py-name" targets="Method pyspark.rdd.RDD.distinct()=pyspark.rdd.RDD-class.html#distinct,Method pyspark.sql.SchemaRDD.distinct()=pyspark.sql.SchemaRDD-class.html#distinct"><a title="pyspark.rdd.RDD.distinct
pyspark.sql.SchemaRDD.distinct" class="py-name" href="#" onclick="return doclink('link-144', 'distinct', 'link-144');">distinct</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L947"></a><tt class="py-lineno"> 947</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-145" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-145', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-146" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-146', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
</div><a name="L948"></a><tt class="py-lineno"> 948</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.intersection"></a><div id="SchemaRDD.intersection-def"><a name="L949"></a><tt class="py-lineno"> 949</tt> <a class="py-toggle" href="#" id="SchemaRDD.intersection-toggle" onclick="return toggle('SchemaRDD.intersection');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#intersection">intersection</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.intersection-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.intersection-expanded"><a name="L950"></a><tt class="py-lineno"> 950</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt> <tt class="py-keyword">is</tt> <tt id="link-147" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-147', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L951"></a><tt class="py-lineno"> 951</tt>  <tt class="py-line">            <tt id="link-148" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-148', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-149" class="py-name" targets="Method pyspark.rdd.RDD.intersection()=pyspark.rdd.RDD-class.html#intersection,Method pyspark.sql.SchemaRDD.intersection()=pyspark.sql.SchemaRDD-class.html#intersection"><a title="pyspark.rdd.RDD.intersection
pyspark.sql.SchemaRDD.intersection" class="py-name" href="#" onclick="return doclink('link-149', 'intersection', 'link-149');">intersection</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">)</tt> </tt>
<a name="L952"></a><tt class="py-lineno"> 952</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt id="link-150" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-150', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-151" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-151', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
<a name="L953"></a><tt class="py-lineno"> 953</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L954"></a><tt class="py-lineno"> 954</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can only intersect with another SchemaRDD"</tt><tt class="py-op">)</tt> </tt>
</div><a name="L955"></a><tt class="py-lineno"> 955</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.repartition"></a><div id="SchemaRDD.repartition-def"><a name="L956"></a><tt class="py-lineno"> 956</tt> <a class="py-toggle" href="#" id="SchemaRDD.repartition-toggle" onclick="return toggle('SchemaRDD.repartition');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#repartition">repartition</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">numPartitions</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.repartition-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.repartition-expanded"><a name="L957"></a><tt class="py-lineno"> 957</tt>  <tt class="py-line">        <tt id="link-152" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-152', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-153" class="py-name" targets="Method pyspark.rdd.RDD.repartition()=pyspark.rdd.RDD-class.html#repartition,Method pyspark.sql.SchemaRDD.repartition()=pyspark.sql.SchemaRDD-class.html#repartition"><a title="pyspark.rdd.RDD.repartition
pyspark.sql.SchemaRDD.repartition" class="py-name" href="#" onclick="return doclink('link-153', 'repartition', 'link-153');">repartition</a></tt><tt class="py-op">(</tt><tt class="py-name">numPartitions</tt><tt class="py-op">)</tt> </tt>
<a name="L958"></a><tt class="py-lineno"> 958</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-154" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-154', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-155" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-155', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
</div><a name="L959"></a><tt class="py-lineno"> 959</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.subtract"></a><div id="SchemaRDD.subtract-def"><a name="L960"></a><tt class="py-lineno"> 960</tt> <a class="py-toggle" href="#" id="SchemaRDD.subtract-toggle" onclick="return toggle('SchemaRDD.subtract');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#subtract">subtract</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">,</tt> <tt class="py-param">numPartitions</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.subtract-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.subtract-expanded"><a name="L961"></a><tt class="py-lineno"> 961</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt> <tt class="py-keyword">is</tt> <tt id="link-156" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-156', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L962"></a><tt class="py-lineno"> 962</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">numPartitions</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L963"></a><tt class="py-lineno"> 963</tt>  <tt class="py-line">                <tt id="link-157" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-157', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-158" class="py-name" targets="Method pyspark.rdd.RDD.subtract()=pyspark.rdd.RDD-class.html#subtract,Method pyspark.sql.SchemaRDD.subtract()=pyspark.sql.SchemaRDD-class.html#subtract"><a title="pyspark.rdd.RDD.subtract
pyspark.sql.SchemaRDD.subtract" class="py-name" href="#" onclick="return doclink('link-158', 'subtract', 'link-158');">subtract</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">)</tt> </tt>
<a name="L964"></a><tt class="py-lineno"> 964</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L965"></a><tt class="py-lineno"> 965</tt>  <tt class="py-line">                <tt id="link-159" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-159', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-160" class="py-name"><a title="pyspark.rdd.RDD.subtract
pyspark.sql.SchemaRDD.subtract" class="py-name" href="#" onclick="return doclink('link-160', 'subtract', 'link-158');">subtract</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">numPartitions</tt><tt class="py-op">)</tt> </tt>
<a name="L966"></a><tt class="py-lineno"> 966</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt id="link-161" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-161', 'SchemaRDD', 'link-58');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-162" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-162', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
<a name="L967"></a><tt class="py-lineno"> 967</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L968"></a><tt class="py-lineno"> 968</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can only subtract another SchemaRDD"</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L969"></a><tt class="py-lineno"> 969</tt>  <tt class="py-line"> </tt>
<a name="_test"></a><div id="_test-def"><a name="L970"></a><tt class="py-lineno"> 970</tt>  <tt class="py-line"> </tt>
<a name="L971"></a><tt class="py-lineno"> 971</tt> <a class="py-toggle" href="#" id="_test-toggle" onclick="return toggle('_test');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_test">_test</a><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_test-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_test-expanded"><a name="L972"></a><tt class="py-lineno"> 972</tt>  <tt class="py-line">    <tt class="py-keyword">import</tt> <tt class="py-name">doctest</tt> </tt>
<a name="L973"></a><tt class="py-lineno"> 973</tt>  <tt class="py-line">    <tt class="py-keyword">from</tt> <tt class="py-name">array</tt> <tt class="py-keyword">import</tt> <tt class="py-name">array</tt> </tt>
<a name="L974"></a><tt class="py-lineno"> 974</tt>  <tt class="py-line">    <tt class="py-keyword">from</tt> <tt id="link-163" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-163', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-164" class="py-name" targets="Module pyspark.context=pyspark.context-module.html,Method pyspark.rdd.RDD.context()=pyspark.rdd.RDD-class.html#context"><a title="pyspark.context
pyspark.rdd.RDD.context" class="py-name" href="#" onclick="return doclink('link-164', 'context', 'link-164');">context</a></tt> <tt class="py-keyword">import</tt> <tt id="link-165" class="py-name" targets="Class pyspark.context.SparkContext=pyspark.context.SparkContext-class.html"><a title="pyspark.context.SparkContext" class="py-name" href="#" onclick="return doclink('link-165', 'SparkContext', 'link-165');">SparkContext</a></tt> </tt>
<a name="L975"></a><tt class="py-lineno"> 975</tt>  <tt class="py-line">    <tt class="py-name">globs</tt> <tt class="py-op">=</tt> <tt class="py-name">globals</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-166" class="py-name" targets="Method pyspark.statcounter.StatCounter.copy()=pyspark.statcounter.StatCounter-class.html#copy"><a title="pyspark.statcounter.StatCounter.copy" class="py-name" href="#" onclick="return doclink('link-166', 'copy', 'link-166');">copy</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L976"></a><tt class="py-lineno"> 976</tt>  <tt class="py-line">    <tt class="py-comment"># The small batch size here ensures that we see multiple batches,</tt> </tt>
<a name="L977"></a><tt class="py-lineno"> 977</tt>  <tt class="py-line">    <tt class="py-comment"># even in these small test examples:</tt> </tt>
<a name="L978"></a><tt class="py-lineno"> 978</tt>  <tt class="py-line">    <tt class="py-name">sc</tt> <tt class="py-op">=</tt> <tt id="link-167" class="py-name"><a title="pyspark.context.SparkContext" class="py-name" href="#" onclick="return doclink('link-167', 'SparkContext', 'link-165');">SparkContext</a></tt><tt class="py-op">(</tt><tt class="py-string">'local[4]'</tt><tt class="py-op">,</tt> <tt class="py-string">'PythonTest'</tt><tt class="py-op">,</tt> <tt class="py-name">batchSize</tt><tt class="py-op">=</tt><tt class="py-number">2</tt><tt class="py-op">)</tt> </tt>
<a name="L979"></a><tt class="py-lineno"> 979</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'sc'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt> </tt>
<a name="L980"></a><tt class="py-lineno"> 980</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'sqlCtx'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt id="link-168" class="py-name"><a title="pyspark.sql.SQLContext" class="py-name" href="#" onclick="return doclink('link-168', 'SQLContext', 'link-56');">SQLContext</a></tt><tt class="py-op">(</tt><tt class="py-name">sc</tt><tt class="py-op">)</tt> </tt>
<a name="L981"></a><tt class="py-lineno"> 981</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'rdd'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt><tt class="py-op">.</tt><tt id="link-169" class="py-name" targets="Method pyspark.context.SparkContext.parallelize()=pyspark.context.SparkContext-class.html#parallelize"><a title="pyspark.context.SparkContext.parallelize" class="py-name" href="#" onclick="return doclink('link-169', 'parallelize', 'link-169');">parallelize</a></tt><tt class="py-op">(</tt> </tt>
<a name="L982"></a><tt class="py-lineno"> 982</tt>  <tt class="py-line">        <tt class="py-op">[</tt><tt class="py-op">{</tt><tt class="py-string">"field1"</tt><tt class="py-op">:</tt> <tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-string">"field2"</tt><tt class="py-op">:</tt> <tt class="py-string">"row1"</tt><tt class="py-op">}</tt><tt class="py-op">,</tt> </tt>
<a name="L983"></a><tt class="py-lineno"> 983</tt>  <tt class="py-line">         <tt class="py-op">{</tt><tt class="py-string">"field1"</tt><tt class="py-op">:</tt> <tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-string">"field2"</tt><tt class="py-op">:</tt> <tt class="py-string">"row2"</tt><tt class="py-op">}</tt><tt class="py-op">,</tt> </tt>
<a name="L984"></a><tt class="py-lineno"> 984</tt>  <tt class="py-line">         <tt class="py-op">{</tt><tt class="py-string">"field1"</tt><tt class="py-op">:</tt> <tt class="py-number">3</tt><tt class="py-op">,</tt> <tt class="py-string">"field2"</tt><tt class="py-op">:</tt> <tt class="py-string">"row3"</tt><tt class="py-op">}</tt><tt class="py-op">]</tt> </tt>
<a name="L985"></a><tt class="py-lineno"> 985</tt>  <tt class="py-line">    <tt class="py-op">)</tt> </tt>
<a name="L986"></a><tt class="py-lineno"> 986</tt>  <tt class="py-line">    <tt class="py-name">jsonStrings</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt> </tt>
<a name="L987"></a><tt class="py-lineno"> 987</tt>  <tt class="py-line">        <tt class="py-string">'{"field1": 1, "field2": "row1", "field3":{"field4":11}}'</tt><tt class="py-op">,</tt> </tt>
<a name="L988"></a><tt class="py-lineno"> 988</tt>  <tt class="py-line">        <tt class="py-string">'{"field1" : 2, "field3":{"field4":22, "field5": [10, 11]}, "field6":[{"field7": "row2"}]}'</tt><tt class="py-op">,</tt> </tt>
<a name="L989"></a><tt class="py-lineno"> 989</tt>  <tt class="py-line">        <tt class="py-string">'{"field1" : null, "field2": "row3", "field3":{"field4":33, "field5": []}}'</tt> </tt>
<a name="L990"></a><tt class="py-lineno"> 990</tt>  <tt class="py-line">    <tt class="py-op">]</tt> </tt>
<a name="L991"></a><tt class="py-lineno"> 991</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'jsonStrings'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">jsonStrings</tt> </tt>
<a name="L992"></a><tt class="py-lineno"> 992</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'json'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt><tt class="py-op">.</tt><tt id="link-170" class="py-name"><a title="pyspark.context.SparkContext.parallelize" class="py-name" href="#" onclick="return doclink('link-170', 'parallelize', 'link-169');">parallelize</a></tt><tt class="py-op">(</tt><tt class="py-name">jsonStrings</tt><tt class="py-op">)</tt> </tt>
<a name="L993"></a><tt class="py-lineno"> 993</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'nestedRdd1'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt><tt class="py-op">.</tt><tt id="link-171" class="py-name"><a title="pyspark.context.SparkContext.parallelize" class="py-name" href="#" onclick="return doclink('link-171', 'parallelize', 'link-169');">parallelize</a></tt><tt class="py-op">(</tt><tt class="py-op">[</tt> </tt>
<a name="L994"></a><tt class="py-lineno"> 994</tt>  <tt class="py-line">        <tt class="py-op">{</tt><tt class="py-string">"f1"</tt><tt class="py-op">:</tt> <tt class="py-name">array</tt><tt class="py-op">(</tt><tt class="py-string">'i'</tt><tt class="py-op">,</tt> <tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-string">"f2"</tt><tt class="py-op">:</tt> <tt class="py-op">{</tt><tt class="py-string">"row1"</tt><tt class="py-op">:</tt> <tt class="py-number">1.0</tt><tt class="py-op">}</tt><tt class="py-op">}</tt><tt class="py-op">,</tt> </tt>
<a name="L995"></a><tt class="py-lineno"> 995</tt>  <tt class="py-line">        <tt class="py-op">{</tt><tt class="py-string">"f1"</tt><tt class="py-op">:</tt> <tt class="py-name">array</tt><tt class="py-op">(</tt><tt class="py-string">'i'</tt><tt class="py-op">,</tt> <tt class="py-op">[</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-number">3</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-string">"f2"</tt><tt class="py-op">:</tt> <tt class="py-op">{</tt><tt class="py-string">"row2"</tt><tt class="py-op">:</tt> <tt class="py-number">2.0</tt><tt class="py-op">}</tt><tt class="py-op">}</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L996"></a><tt class="py-lineno"> 996</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'nestedRdd2'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt><tt class="py-op">.</tt><tt id="link-172" class="py-name"><a title="pyspark.context.SparkContext.parallelize" class="py-name" href="#" onclick="return doclink('link-172', 'parallelize', 'link-169');">parallelize</a></tt><tt class="py-op">(</tt><tt class="py-op">[</tt> </tt>
<a name="L997"></a><tt class="py-lineno"> 997</tt>  <tt class="py-line">        <tt class="py-op">{</tt><tt class="py-string">"f1"</tt><tt class="py-op">:</tt> <tt class="py-op">[</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">[</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-number">3</tt><tt class="py-op">]</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-string">"f2"</tt><tt class="py-op">:</tt> <tt id="link-173" class="py-name" targets="Method pyspark.conf.SparkConf.set()=pyspark.conf.SparkConf-class.html#set"><a title="pyspark.conf.SparkConf.set" class="py-name" href="#" onclick="return doclink('link-173', 'set', 'link-173');">set</a></tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-string">"f3"</tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-number">2</tt><tt class="py-op">)</tt><tt class="py-op">}</tt><tt class="py-op">,</tt> </tt>
<a name="L998"></a><tt class="py-lineno"> 998</tt>  <tt class="py-line">        <tt class="py-op">{</tt><tt class="py-string">"f1"</tt><tt class="py-op">:</tt> <tt class="py-op">[</tt><tt class="py-op">[</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-number">3</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-op">[</tt><tt class="py-number">3</tt><tt class="py-op">,</tt> <tt class="py-number">4</tt><tt class="py-op">]</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-string">"f2"</tt><tt class="py-op">:</tt> <tt id="link-174" class="py-name"><a title="pyspark.conf.SparkConf.set" class="py-name" href="#" onclick="return doclink('link-174', 'set', 'link-173');">set</a></tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-number">3</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-string">"f3"</tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-number">3</tt><tt class="py-op">)</tt><tt class="py-op">}</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L999"></a><tt class="py-lineno"> 999</tt>  <tt class="py-line">    <tt class="py-op">(</tt><tt class="py-name">failure_count</tt><tt class="py-op">,</tt> <tt class="py-name">test_count</tt><tt class="py-op">)</tt> <tt class="py-op">=</tt> <tt class="py-name">doctest</tt><tt class="py-op">.</tt><tt class="py-name">testmod</tt><tt class="py-op">(</tt><tt class="py-name">globs</tt><tt class="py-op">=</tt><tt class="py-name">globs</tt><tt class="py-op">,</tt> <tt class="py-name">optionflags</tt><tt class="py-op">=</tt><tt class="py-name">doctest</tt><tt class="py-op">.</tt><tt class="py-name">ELLIPSIS</tt><tt class="py-op">)</tt> </tt>
<a name="L1000"></a><tt class="py-lineno">1000</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'sc'</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt id="link-175" class="py-name" targets="Method pyspark.context.SparkContext.stop()=pyspark.context.SparkContext-class.html#stop"><a title="pyspark.context.SparkContext.stop" class="py-name" href="#" onclick="return doclink('link-175', 'stop', 'link-175');">stop</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1001"></a><tt class="py-lineno">1001</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">failure_count</tt><tt class="py-op">:</tt> </tt>
<a name="L1002"></a><tt class="py-lineno">1002</tt>  <tt class="py-line">        <tt class="py-name">exit</tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1003"></a><tt class="py-lineno">1003</tt>  <tt class="py-line"> </tt>
<a name="L1004"></a><tt class="py-lineno">1004</tt>  <tt class="py-line"> </tt>
<a name="L1005"></a><tt class="py-lineno">1005</tt>  <tt class="py-line"><tt class="py-keyword">if</tt> <tt class="py-name">__name__</tt> <tt class="py-op">==</tt> <tt class="py-string">"__main__"</tt><tt class="py-op">:</tt> </tt>
<a name="L1006"></a><tt class="py-lineno">1006</tt>  <tt class="py-line">    <tt class="py-name">_test</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1007"></a><tt class="py-lineno">1007</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.0.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Sun Jul 27 17:21:23 2014
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
