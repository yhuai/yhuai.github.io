<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>pyspark.sql.LocalHiveContext</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.0.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="pyspark-module.html">Package&nbsp;pyspark</a> ::
        <a href="pyspark.sql-module.html">Module&nbsp;sql</a> ::
        Class&nbsp;LocalHiveContext
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="pyspark.sql.LocalHiveContext-class.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<!-- ==================== CLASS DESCRIPTION ==================== -->
<h1 class="epydoc">Class LocalHiveContext</h1><p class="nomargin-top"><span class="codelink"><a href="pyspark.sql-pysrc.html#LocalHiveContext">source&nbsp;code</a></span></p>
<pre class="base-tree">
<a href="pyspark.sql.SQLContext-class.html">SQLContext</a> --+    
             |    
   <a href="pyspark.sql.HiveContext-class.html">HiveContext</a> --+
                 |
                <strong class="uidshort">LocalHiveContext</strong>
</pre>

<hr />
<p>Starts up an instance of hive where metadata is stored locally.</p>
  <p>An in-process metadata data is created with data stored in ./metadata.
  Warehouse data is stored in in ./warehouse.</p>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">import</span> os
<span class="py-prompt">&gt;&gt;&gt; </span>hiveCtx = LocalHiveContext(sc)
<span class="py-prompt">&gt;&gt;&gt; </span>try:
<span class="py-more">... </span>    supress = hiveCtx.sql(<span class="py-string">&quot;DROP TABLE src&quot;</span>)
<span class="py-more">... </span><span class="py-keyword">except</span> Exception:
<span class="py-more">... </span>    <span class="py-keyword">pass</span>
<span class="py-prompt">&gt;&gt;&gt; </span>kv1 = os.path.join(os.environ[<span class="py-string">&quot;SPARK_HOME&quot;</span>],
<span class="py-more">... </span>       <span class="py-string">'examples/src/main/resources/kv1.txt'</span>)
<span class="py-prompt">&gt;&gt;&gt; </span>supress = hiveCtx.sql(
<span class="py-more">... </span>    <span class="py-string">&quot;CREATE TABLE IF NOT EXISTS src (key INT, value STRING)&quot;</span>)
<span class="py-prompt">&gt;&gt;&gt; </span>supress = hiveCtx.sql(<span class="py-string">&quot;LOAD DATA LOCAL INPATH '%s' INTO TABLE src&quot;</span>
<span class="py-more">... </span>       % kv1)
<span class="py-prompt">&gt;&gt;&gt; </span>results = hiveCtx.sql(<span class="py-string">&quot;FROM src SELECT value&quot;</span>
<span class="py-more">... </span>     ).map(<span class="py-keyword">lambda</span> r: int(r.value.split(<span class="py-string">'_'</span>)[1]))
<span class="py-prompt">&gt;&gt;&gt; </span>num = results.count()
<span class="py-prompt">&gt;&gt;&gt; </span>reduce_sum = results.reduce(<span class="py-keyword">lambda</span> x, y: x + y)
<span class="py-prompt">&gt;&gt;&gt; </span>num
<span class="py-output">500</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span>reduce_sum
<span class="py-output">130091</span></pre>

<!-- ==================== INSTANCE METHODS ==================== -->
<a name="section-InstanceMethods"></a>
<table class="summary" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr bgcolor="#70b0f0" class="table-header">
  <td align="left" colspan="2" class="table-header">
    <span class="table-header">Instance Methods</span></td>
</tr>
<tr>
    <td width="15%" align="right" valign="top" class="summary">
      <span class="summary-type">&nbsp;</span>
    </td><td class="summary">
      <table width="100%" cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td><span class="summary-sig"><a href="pyspark.sql.LocalHiveContext-class.html#__init__" class="summary-sig-name">__init__</a>(<span class="summary-sig-arg">self</span>,
        <span class="summary-sig-arg">sparkContext</span>,
        <span class="summary-sig-arg">sqlContext</span>=<span class="summary-sig-default">None</span>)</span><br />
      Create a new SQLContext.</td>
          <td align="right" valign="top">
            <span class="codelink"><a href="pyspark.sql-pysrc.html#LocalHiveContext.__init__">source&nbsp;code</a></span>
            
          </td>
        </tr>
      </table>
      
    </td>
  </tr>
  <tr>
    <td colspan="2" class="summary">
    <p class="indent-wrapped-lines"><b>Inherited from <code><a href="pyspark.sql.HiveContext-class.html">HiveContext</a></code></b>:
      <code><a href="pyspark.sql.HiveContext-class.html#hiveql">hiveql</a></code>,
      <code><a href="pyspark.sql.HiveContext-class.html#hql">hql</a></code>
      </p>
    <p class="indent-wrapped-lines"><b>Inherited from <code><a href="pyspark.sql.SQLContext-class.html">SQLContext</a></code></b>:
      <code><a href="pyspark.sql.SQLContext-class.html#applySchema">applySchema</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#cacheTable">cacheTable</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#inferSchema">inferSchema</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#jsonFile">jsonFile</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#jsonRDD">jsonRDD</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#parquetFile">parquetFile</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#registerFunction">registerFunction</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#registerRDDAsTable">registerRDDAsTable</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#sql">sql</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#table">table</a></code>,
      <code><a href="pyspark.sql.SQLContext-class.html#uncacheTable">uncacheTable</a></code>
      </p>
    </td>
  </tr>
</table>
<!-- ==================== METHOD DETAILS ==================== -->
<a name="section-MethodDetails"></a>
<table class="details" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr bgcolor="#70b0f0" class="table-header">
  <td align="left" colspan="2" class="table-header">
    <span class="table-header">Method Details</span></td>
</tr>
</table>
<a name="__init__"></a>
<div>
<table class="details" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr><td>
  <table width="100%" cellpadding="0" cellspacing="0" border="0">
  <tr valign="top"><td>
  <h3 class="epydoc"><span class="sig"><span class="sig-name">__init__</span>(<span class="sig-arg">self</span>,
        <span class="sig-arg">sparkContext</span>,
        <span class="sig-arg">sqlContext</span>=<span class="sig-default">None</span>)</span>
    <br /><em class="fname">(Constructor)</em>
  </h3>
  </td><td align="right" valign="top"
    ><span class="codelink"><a href="pyspark.sql-pysrc.html#LocalHiveContext.__init__">source&nbsp;code</a></span>&nbsp;
    </td>
  </tr></table>
  
  <p>Create a new SQLContext.</p>
  <dl class="fields">
    <dt>Parameters:</dt>
    <dd><ul class="nomargin-top">
        <li><strong class="pname"><code>sparkContext</code></strong> - The SparkContext to wrap.
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span>srdd = sqlCtx.inferSchema(rdd)
<span class="py-prompt">&gt;&gt;&gt; </span>sqlCtx.inferSchema(srdd) <span class="py-comment"># doctest: +IGNORE_EXCEPTION_DETAIL</span>
<span class="py-except">Traceback (most recent call last):</span>
<span class="py-except">    ...</span>
<span class="py-except">TypeError:...</span></pre>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span>bad_rdd = sc.parallelize([1,2,3])
<span class="py-prompt">&gt;&gt;&gt; </span>sqlCtx.inferSchema(bad_rdd) <span class="py-comment"># doctest: +IGNORE_EXCEPTION_DETAIL</span>
<span class="py-except">Traceback (most recent call last):</span>
<span class="py-except">    ...</span>
<span class="py-except">ValueError:...</span></pre>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> datetime <span class="py-keyword">import</span> datetime
<span class="py-prompt">&gt;&gt;&gt; </span>allTypes = sc.parallelize([Row(i=1, s=<span class="py-string">&quot;string&quot;</span>, d=1.0, l=1L,
<span class="py-more">... </span>    b=True, list=[1, 2, 3], dict={<span class="py-string">&quot;s&quot;</span>: 0}, row=Row(a=1),
<span class="py-more">... </span>    time=datetime(2014, 8, 1, 14, 1, 5))])
<span class="py-prompt">&gt;&gt;&gt; </span>srdd = sqlCtx.inferSchema(allTypes)
<span class="py-prompt">&gt;&gt;&gt; </span>srdd.registerTempTable(<span class="py-string">&quot;allTypes&quot;</span>)
<span class="py-prompt">&gt;&gt;&gt; </span>sqlCtx.sql(<span class="py-string">'select i+1, d+1, not b, list[1], dict[&quot;s&quot;], time, row.a '</span>
<span class="py-more">... </span>           <span class="py-string">'from allTypes where b and i &gt; 0'</span>).collect()
<span class="py-output">[Row(c0=2, c1=2.0, c2=False, c3=2, c4=0...8, 1, 14, 1, 5), a=1)]</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span>srdd.map(<span class="py-keyword">lambda</span> x: (x.i, x.s, x.d, x.l, x.b, x.time,
<span class="py-more">... </span>                    x.row.a, x.list)).collect()
<span class="py-output">[(1, u'string', 1.0, 1, True, ...(2014, 8, 1, 14, 1, 5), 1, [1, 2, 3])]</span></pre></li>
    </ul></dd>
    <dt>Overrides:
        <a href="pyspark.sql.SQLContext-class.html#__init__">SQLContext.__init__</a>
        <dd><em class="note">(inherited documentation)</em></dd>
    </dt>
  </dl>
</td></tr></table>
</div>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.0.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Tue Aug  5 16:54:38 2014
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
