<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>pyspark.mllib.util.MLUtils</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.0.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="pyspark-module.html">Package&nbsp;pyspark</a> ::
        <a href="pyspark.mllib-module.html">Package&nbsp;mllib</a> ::
        <a href="pyspark.mllib.util-module.html">Module&nbsp;util</a> ::
        Class&nbsp;MLUtils
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="pyspark.mllib.util.MLUtils-class.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<!-- ==================== CLASS DESCRIPTION ==================== -->
<h1 class="epydoc">Class MLUtils</h1><p class="nomargin-top"><span class="codelink"><a href="pyspark.mllib.util-pysrc.html#MLUtils">source&nbsp;code</a></span></p>
<p>Helper methods to load, save and pre-process data used in MLlib.</p>

<!-- ==================== STATIC METHODS ==================== -->
<a name="section-StaticMethods"></a>
<table class="summary" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr bgcolor="#70b0f0" class="table-header">
  <td align="left" colspan="2" class="table-header">
    <span class="table-header">Static Methods</span></td>
</tr>
<tr>
    <td width="15%" align="right" valign="top" class="summary">
      <span class="summary-type">&nbsp;</span>
    </td><td class="summary">
      <table width="100%" cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td><span class="summary-sig"><a href="pyspark.mllib.util.MLUtils-class.html#loadLibSVMFile" class="summary-sig-name">loadLibSVMFile</a>(<span class="summary-sig-arg">sc</span>,
        <span class="summary-sig-arg">path</span>,
        <span class="summary-sig-arg">multiclass</span>=<span class="summary-sig-default">False</span>,
        <span class="summary-sig-arg">numFeatures</span>=<span class="summary-sig-default">-1</span>,
        <span class="summary-sig-arg">minPartitions</span>=<span class="summary-sig-default">None</span>)</span><br />
      Loads labeled data in the LIBSVM format into an RDD of LabeledPoint.</td>
          <td align="right" valign="top">
            <span class="codelink"><a href="pyspark.mllib.util-pysrc.html#MLUtils.loadLibSVMFile">source&nbsp;code</a></span>
            
          </td>
        </tr>
      </table>
      
    </td>
  </tr>
<tr>
    <td width="15%" align="right" valign="top" class="summary">
      <span class="summary-type">&nbsp;</span>
    </td><td class="summary">
      <table width="100%" cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td><span class="summary-sig"><a href="pyspark.mllib.util.MLUtils-class.html#saveAsLibSVMFile" class="summary-sig-name">saveAsLibSVMFile</a>(<span class="summary-sig-arg">data</span>,
        <span class="summary-sig-arg">dir</span>)</span><br />
      Save labeled data in LIBSVM format.</td>
          <td align="right" valign="top">
            <span class="codelink"><a href="pyspark.mllib.util-pysrc.html#MLUtils.saveAsLibSVMFile">source&nbsp;code</a></span>
            
          </td>
        </tr>
      </table>
      
    </td>
  </tr>
<tr>
    <td width="15%" align="right" valign="top" class="summary">
      <span class="summary-type">&nbsp;</span>
    </td><td class="summary">
      <table width="100%" cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td><span class="summary-sig"><a href="pyspark.mllib.util.MLUtils-class.html#loadLabeledPoints" class="summary-sig-name">loadLabeledPoints</a>(<span class="summary-sig-arg">sc</span>,
        <span class="summary-sig-arg">path</span>,
        <span class="summary-sig-arg">minPartitions</span>=<span class="summary-sig-default">None</span>)</span><br />
      Load labeled points saved using RDD.saveAsTextFile.</td>
          <td align="right" valign="top">
            <span class="codelink"><a href="pyspark.mllib.util-pysrc.html#MLUtils.loadLabeledPoints">source&nbsp;code</a></span>
            
          </td>
        </tr>
      </table>
      
    </td>
  </tr>
</table>
<!-- ==================== METHOD DETAILS ==================== -->
<a name="section-MethodDetails"></a>
<table class="details" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr bgcolor="#70b0f0" class="table-header">
  <td align="left" colspan="2" class="table-header">
    <span class="table-header">Method Details</span></td>
</tr>
</table>
<a name="loadLibSVMFile"></a>
<div>
<table class="details" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr><td>
  <table width="100%" cellpadding="0" cellspacing="0" border="0">
  <tr valign="top"><td>
  <h3 class="epydoc"><span class="sig"><span class="sig-name">loadLibSVMFile</span>(<span class="sig-arg">sc</span>,
        <span class="sig-arg">path</span>,
        <span class="sig-arg">multiclass</span>=<span class="sig-default">False</span>,
        <span class="sig-arg">numFeatures</span>=<span class="sig-default">-1</span>,
        <span class="sig-arg">minPartitions</span>=<span class="sig-default">None</span>)</span>
    <br /><em class="fname">Static Method</em>
  </h3>
  </td><td align="right" valign="top"
    ><span class="codelink"><a href="pyspark.mllib.util-pysrc.html#MLUtils.loadLibSVMFile">source&nbsp;code</a></span>&nbsp;
    </td>
  </tr></table>
  
  <p>Loads labeled data in the LIBSVM format into an RDD of LabeledPoint. 
  The LIBSVM format is a text-based format used by LIBSVM and LIBLINEAR. 
  Each line represents a labeled sparse feature vector using the following 
  format:</p>
  <p>label index1:value1 index2:value2 ...</p>
  <p>where the indices are one-based and in ascending order. This method 
  parses each line into a LabeledPoint, where the feature indices are 
  converted to zero-based.</p>
  <dl class="fields">
    <dt>Parameters:</dt>
    <dd><ul class="nomargin-top">
        <li><strong class="pname"><code>sc</code></strong> - Spark context</li>
        <li><strong class="pname"><code>path</code></strong> - file or directory path in any Hadoop-supported file system URI</li>
        <li><strong class="pname"><code>multiclass</code></strong> - whether the input labels contain more than two classes. If false,
          any label with value greater than 0.5 will be mapped to 1.0, or 
          0.0 otherwise. So it works for both +1/-1 and 1/0 cases. If true,
          the double value parsed directly from the label string will be 
          used as the label value.</li>
        <li><strong class="pname"><code>numFeatures</code></strong> - number of features, which will be determined from the input data 
          if a nonpositive value is given. This is useful when the dataset 
          is already split into multiple files and you want to load them 
          separately, because some features may not present in certain 
          files, which leads to inconsistent feature dimensions.</li>
        <li><strong class="pname"><code>minPartitions</code></strong> - min number of partitions</li>
    </ul></dd>
    <dt>Returns:</dt>
        <dd>labeled data stored as an RDD of LabeledPoint
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> tempfile <span class="py-keyword">import</span> NamedTemporaryFile
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> pyspark.mllib.util <span class="py-keyword">import</span> MLUtils
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile = NamedTemporaryFile(delete=True)
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile.write(<span class="py-string">&quot;+1 1:1.0 3:2.0 5:3.0\n-1\n-1 2:4.0 4:5.0 6:6.0&quot;</span>)
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile.flush()
<span class="py-prompt">&gt;&gt;&gt; </span>examples = MLUtils.loadLibSVMFile(sc, tempFile.name).collect()
<span class="py-prompt">&gt;&gt;&gt; </span>multiclass_examples = MLUtils.loadLibSVMFile(sc, tempFile.name, True).collect()
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile.close()
<span class="py-prompt">&gt;&gt;&gt; </span>type(examples[0]) == LabeledPoint
<span class="py-output">True</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">print</span> examples[0]
<span class="py-output">(1.0,(6,[0,2,4],[1.0,2.0,3.0]))</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span>type(examples[1]) == LabeledPoint
<span class="py-output">True</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">print</span> examples[1]
<span class="py-output">(0.0,(6,[],[]))</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span>type(examples[2]) == LabeledPoint
<span class="py-output">True</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">print</span> examples[2]
<span class="py-output">(0.0,(6,[1,3,5],[4.0,5.0,6.0]))</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span>multiclass_examples[1].label
<span class="py-output">-1.0</span></pre></dd>
  </dl>
</td></tr></table>
</div>
<a name="saveAsLibSVMFile"></a>
<div>
<table class="details" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr><td>
  <table width="100%" cellpadding="0" cellspacing="0" border="0">
  <tr valign="top"><td>
  <h3 class="epydoc"><span class="sig"><span class="sig-name">saveAsLibSVMFile</span>(<span class="sig-arg">data</span>,
        <span class="sig-arg">dir</span>)</span>
    <br /><em class="fname">Static Method</em>
  </h3>
  </td><td align="right" valign="top"
    ><span class="codelink"><a href="pyspark.mllib.util-pysrc.html#MLUtils.saveAsLibSVMFile">source&nbsp;code</a></span>&nbsp;
    </td>
  </tr></table>
  
  <p>Save labeled data in LIBSVM format.</p>
  <dl class="fields">
    <dt>Parameters:</dt>
    <dd><ul class="nomargin-top">
        <li><strong class="pname"><code>data</code></strong> - an RDD of LabeledPoint to be saved</li>
        <li><strong class="pname"><code>dir</code></strong> - directory to save the data
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> tempfile <span class="py-keyword">import</span> NamedTemporaryFile
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> fileinput <span class="py-keyword">import</span> input
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> glob <span class="py-keyword">import</span> glob
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> pyspark.mllib.util <span class="py-keyword">import</span> MLUtils
<span class="py-prompt">&gt;&gt;&gt; </span>examples = [LabeledPoint(1.1, Vectors.sparse(3, [(0, 1.23), (2, 4.56)])),                         LabeledPoint(0.0, Vectors.dense([1.01, 2.02, 3.03]))]
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile = NamedTemporaryFile(delete=True)
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile.close()
<span class="py-prompt">&gt;&gt;&gt; </span>MLUtils.saveAsLibSVMFile(sc.parallelize(examples), tempFile.name)
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-string">''</span>.join(sorted(input(glob(tempFile.name + <span class="py-string">&quot;/part-0000*&quot;</span>))))
<span class="py-output">'0.0 1:1.01 2:2.02 3:3.03\n1.1 1:1.23 3:4.56\n'</span></pre></li>
    </ul></dd>
  </dl>
</td></tr></table>
</div>
<a name="loadLabeledPoints"></a>
<div>
<table class="details" border="1" cellpadding="3"
       cellspacing="0" width="100%" bgcolor="white">
<tr><td>
  <table width="100%" cellpadding="0" cellspacing="0" border="0">
  <tr valign="top"><td>
  <h3 class="epydoc"><span class="sig"><span class="sig-name">loadLabeledPoints</span>(<span class="sig-arg">sc</span>,
        <span class="sig-arg">path</span>,
        <span class="sig-arg">minPartitions</span>=<span class="sig-default">None</span>)</span>
    <br /><em class="fname">Static Method</em>
  </h3>
  </td><td align="right" valign="top"
    ><span class="codelink"><a href="pyspark.mllib.util-pysrc.html#MLUtils.loadLabeledPoints">source&nbsp;code</a></span>&nbsp;
    </td>
  </tr></table>
  
  <p>Load labeled points saved using RDD.saveAsTextFile.</p>
  <dl class="fields">
    <dt>Parameters:</dt>
    <dd><ul class="nomargin-top">
        <li><strong class="pname"><code>sc</code></strong> - Spark context</li>
        <li><strong class="pname"><code>path</code></strong> - file or directory path in any Hadoop-supported file system URI</li>
        <li><strong class="pname"><code>minPartitions</code></strong> - min number of partitions</li>
    </ul></dd>
    <dt>Returns:</dt>
        <dd>labeled data stored as an RDD of LabeledPoint
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> tempfile <span class="py-keyword">import</span> NamedTemporaryFile
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> pyspark.mllib.util <span class="py-keyword">import</span> MLUtils
<span class="py-prompt">&gt;&gt;&gt; </span>examples = [LabeledPoint(1.1, Vectors.sparse(3, [(0, -1.23), (2, 4.56e-7)])),                         LabeledPoint(0.0, Vectors.dense([1.01, 2.02, 3.03]))]
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile = NamedTemporaryFile(delete=True)
<span class="py-prompt">&gt;&gt;&gt; </span>tempFile.close()
<span class="py-prompt">&gt;&gt;&gt; </span>sc.parallelize(examples, 1).saveAsTextFile(tempFile.name)
<span class="py-prompt">&gt;&gt;&gt; </span>loaded = MLUtils.loadLabeledPoints(sc, tempFile.name).collect()
<span class="py-prompt">&gt;&gt;&gt; </span>type(loaded[0]) == LabeledPoint
<span class="py-output">True</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">print</span> examples[0]
<span class="py-output">(1.1,(3,[0,2],[-1.23,4.56e-07]))</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span>type(examples[1]) == LabeledPoint
<span class="py-output">True</span>
<span class="py-output"></span><span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">print</span> examples[1]
<span class="py-output">(0.0,[1.01,2.02,3.03])</span></pre></dd>
  </dl>
</td></tr></table>
</div>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.0.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Thu Jul 24 22:54:38 2014
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
