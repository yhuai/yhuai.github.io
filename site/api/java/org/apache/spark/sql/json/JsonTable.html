<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_55) on Fri Jun 13 14:14:35 PDT 2014 -->
<title>JsonTable (Spark 1.1.0 JavaDoc)</title>
<meta name="date" content="2014-06-13">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="JsonTable (Spark 1.1.0 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/json/JsonSuite.html" title="class in org.apache.spark.sql.json"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/json/TestJsonData.html" title="class in org.apache.spark.sql.json"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/json/JsonTable.html" target="_top">Frames</a></li>
<li><a href="JsonTable.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.json</div>
<h2 title="Class JsonTable" class="title">Class JsonTable</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">org.apache.spark.rdd.RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">org.apache.spark.sql.SchemaRDD</a></li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.json.JsonTable</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">JsonTable</span>
extends <a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></pre>
<div class="block">:: Experimental ::
 <p>
 A JSON dataset (text files with one JSON object per line or a RDD[String] with one JSON object
 per string) can be directly loaded as a <code>SchemaRDD</code>. The schema of this <code>SchemaRDD</code> is
 automatically inferred from the dataset.
 <p>
 == SQL Queries ==
 <pre><code>
  val sc: SparkContext // An existing spark context.

  import org.apache.spark.sql.SQLContext
  val sqlContext = new SQLContext(sc)

  // Importing the SQL context gives access to all the SQL functions and implicit conversions.
  import sqlContext._

  // Create a SchemaRDD from a JSON file (or a directory having JSON files).
  val jsonTable = jsonFile("examples/src/main/resources/people.json")
  // Or, if you have a JSON dataset as RDD[String]
  // val json = sc.textFile("examples/src/main/resources/people.json")
  // val jsonTable = jsonRDD(json)

  // See the schema of jsonTable.
  jsonTable.printSchema()

  // Register jsonTable as a table.
  jsonTable.registerAsTable("jsonTable")

  // Run some queries.
  sql("SELECT name, age FROM jsonTable").collect().foreach(println)
  sql("SELECT name FROM jsonTable WHERE age &gt;= 10 and age &lt;= 19").collect().foreach(println)

  // Create another RDD[String] storing JSON objects.
  val anotherDataset = sc.parallelize(
  """{"name":"Yin","address":{"city":"Columbus","state":"Ohio"}}""" :: Nil)
  val anotherJsonTable = jsonRDD(anotherDataset)

  // See the schema of anotherJsonTable.
  anotherJsonTable.printSchema()

  // Union jsonTable and anotherJsonTable.
  val unionedJsonTable = jsonTable.unionAll(anotherJsonTable)

  // See the schema of unionedJsonTable.
  unionedJsonTable.printSchema()

  // Register unionedJsonTable as table.
  unionedJsonTable.registerAsTable("unionedJsonTable")

  // Run some queries.
  sql("SELECT name, age FROM unionedJsonTable").collect().foreach(println)
  sql("SELECT name, age, address FROM unionedJsonTable WHERE address.city = 'Columbus'").
    collect().foreach(println)
 </code></pre>
 <p>
 == Language Integrated Queries ==
 <pre><code>
  val sc: SparkContext // An existing spark context.

  import org.apache.spark.sql.SQLContext
  val sqlContext = new SQLContext(sc)

  // Importing the SQL context gives access to all the SQL functions and implicit conversions.
  import sqlContext._

  // Create a SchemaRDD from a JSON file (or a directory having JSON files).
  val jsonTable = jsonFile("examples/src/main/resources/people.json")
  // Or, if you have a JSON dataset as RDD[String]
  // val json = sc.textFile("examples/src/main/resources/people.json")
  // val jsonTable = jsonRDD(json)

  // See the schema of jsonTable.
  jsonTable.printSchema()

  // Run some queries.
  jsonTable.select('name, 'age).collect().foreach(println)
  jsonTable.where('age &lt;=19).select('name).collect().foreach(println)

  // Create another RDD[String] storing JSON objects.
  val anotherDataset = sc.parallelize(
  """{"name":"Yin","address":{"city":"Columbus","state":"Ohio"}}""" :: Nil)
  val anotherJsonTable = jsonRDD(anotherDataset)

  // See the schema of anotherJsonTable.
  anotherJsonTable.printSchema()

  // Union jsonTable and anotherJsonTable.
  val unionedJsonTable = jsonTable.unionAll(anotherJsonTable)

  // See the schema of unionedJsonTable.
  unionedJsonTable.printSchema()

  // Run some queries.
  unionedJsonTable.select('name, 'age).collect().foreach(println)
  unionedJsonTable.where(
    "address.city".attr === "Columbus").select(
      'name, 'age, 'address).collect().foreach(println)
 </code></pre></div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../serialized-form.html#org.apache.spark.sql.json.JsonTable">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#JsonTable(org.apache.spark.sql.SQLContext, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">JsonTable</a></strong>(<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext,
         org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
         <a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;baseRDD,
         org.apache.spark.sql.catalyst.types.StructType&nbsp;baseSchema)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#insertInto(java.lang.String)">insertInto</a></strong>(String&nbsp;tableName)</code>
<div class="block">:: Experimental ::
 Appends the rows from this RDD to the specified table.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#insertInto(java.lang.String, boolean)">insertInto</a></strong>(String&nbsp;tableName,
          boolean&nbsp;overwrite)</code>
<div class="block">:: Experimental ::
 Adds the rows from this RDD to the specified table, optionally overwriting the existing data.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#printSchema()">printSchema</a></strong>()</code>
<div class="block">Print the schema of this SchemaRDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.spark.sql.SQLContext.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#queryExecution()">queryExecution</a></strong>()</code>
<div class="block">:: DeveloperApi ::
 A lazily computed query execution workflow.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#registerAsTable(java.lang.String)">registerAsTable</a></strong>(String&nbsp;tableName)</code>
<div class="block">Registers this RDD as a temporary table using the given name.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#saveAsParquetFile(java.lang.String)">saveAsParquetFile</a></strong>(String&nbsp;path)</code>
<div class="block">Saves the contents of this <code>SchemaRDD</code> as a parquet file, preserving the schema.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#saveAsTable(java.lang.String)">saveAsTable</a></strong>(String&nbsp;tableName)</code>
<div class="block">:: Experimental ::
 Creates a table from the the contents of this SchemaRDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#sqlContext()">sqlContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#toString()">toString</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/json/JsonTable.html" title="class in org.apache.spark.sql.json">JsonTable</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/json/JsonTable.html#unionAll(org.apache.spark.sql.json.JsonTable)">unionAll</a></strong>(<a href="../../../../../org/apache/spark/sql/json/JsonTable.html" title="class in org.apache.spark.sql.json">JsonTable</a>&nbsp;otherPlan)</code>
<div class="block">Combines the tuples of two JsonTables and union their schemas, keeping duplicates.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.SchemaRDD">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></h3>
<code><a href="../../../../../org/apache/spark/sql/SchemaRDD.html#aggregate(scala.collection.Seq)">aggregate</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#as(scala.Symbol)">as</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#baseSchemaRDD()">baseSchemaRDD</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#coalesce(int, boolean, scala.math.Ordering)">coalesce</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#collect()">collect</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#count()">count</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#distinct()">distinct</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#distinct(int, scala.math.Ordering)">distinct</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#filter(scala.Function1)">filter</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#generate(org.apache.spark.sql.catalyst.expressions.Generator, boolean, boolean, scala.Option)">generate</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#getPartitions()">getPartitions</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#groupBy(scala.collection.Seq, scala.collection.Seq)">groupBy</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD)">intersection</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD, int)">intersection</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">intersection</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#join(org.apache.spark.sql.SchemaRDD, org.apache.spark.sql.catalyst.plans.JoinType, scala.Option)">join</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#limit(org.apache.spark.sql.catalyst.expressions.Expression)">limit</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#limit(int)">limit</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#orderBy(scala.collection.Seq)">orderBy</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#repartition(int, scala.math.Ordering)">repartition</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#sample(boolean, double, long)">sample</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#select(scala.collection.Seq)">select</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD)">subtract</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD, int)">subtract</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">subtract</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#take(int)">take</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#toJavaSchemaRDD()">toJavaSchemaRDD</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#toSchemaRDD()">toSchemaRDD</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#unionAll(org.apache.spark.sql.SchemaRDD)">unionAll</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#where(org.apache.spark.sql.catalyst.expressions.Expression)">where</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#where(scala.Function1)">where</a>, <a href="../../../../../org/apache/spark/sql/SchemaRDD.html#where(scala.Symbol, scala.Function1)">where</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.rdd.RDD">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.rdd.<a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></h3>
<code><a href="../../../../../org/apache/spark/rdd/RDD.html#aggregate(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregate</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#cache()">cache</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#cartesian(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">cartesian</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#checkpoint()">checkpoint</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#checkpointData()">checkpointData</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#collect(scala.PartialFunction, scala.reflect.ClassTag)">collect</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#context()">context</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#countApprox(long, double)">countApprox</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(double)">countApproxDistinct</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(int, int)">countApproxDistinct</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#countByValue(scala.math.Ordering)">countByValue</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#countByValueApprox(long, double, scala.math.Ordering)">countByValueApprox</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#creationSiteInfo()">creationSiteInfo</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#dependencies()">dependencies</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#filterWith(scala.Function1, scala.Function2)">filterWith</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#first()">first</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#flatMap(scala.Function1, scala.reflect.ClassTag)">flatMap</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#flatMapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">flatMapWith</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#fold(T, scala.Function2)">fold</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#foreach(scala.Function1)">foreach</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#foreachPartition(scala.Function1)">foreachPartition</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#foreachWith(scala.Function1, scala.Function2)">foreachWith</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#getCheckpointFile()">getCheckpointFile</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#getStorageLevel()">getStorageLevel</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#glom()">glom</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, scala.reflect.ClassTag)">groupBy</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, int, scala.reflect.ClassTag)">groupBy</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, org.apache.spark.Partitioner, scala.reflect.ClassTag, scala.math.Ordering)">groupBy</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#id()">id</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#isCheckpointed()">isCheckpointed</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)">iterator</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#keyBy(scala.Function1)">keyBy</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#map(scala.Function1, scala.reflect.ClassTag)">map</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#mapPartitions(scala.Function1, boolean, scala.reflect.ClassTag)">mapPartitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithContext(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithContext</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithIndex</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithSplit(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithSplit</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#mapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">mapWith</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#max(scala.math.Ordering)">max</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#min(scala.math.Ordering)">min</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#name()">name</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#partitioner()">partitioner</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#partitions()">partitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#persist()">persist</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#persist(org.apache.spark.storage.StorageLevel)">persist</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#pipe(scala.collection.Seq, scala.collection.Map, scala.Function1, scala.Function2, boolean)">pipe</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String)">pipe</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String, scala.collection.Map)">pipe</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#preferredLocations(org.apache.spark.Partition)">preferredLocations</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#randomSplit(double[], long)">randomSplit</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#reduce(scala.Function2)">reduce</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#saveAsObjectFile(java.lang.String)">saveAsObjectFile</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)">saveAsTextFile</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String, java.lang.Class)">saveAsTextFile</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#setName(java.lang.String)">setName</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#sparkContext()">sparkContext</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#takeOrdered(int, scala.math.Ordering)">takeOrdered</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#takeSample(boolean, int, long)">takeSample</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#toArray()">toArray</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#toDebugString()">toDebugString</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#toJavaRDD()">toJavaRDD</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#toLocalIterator()">toLocalIterator</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#top(int, scala.math.Ordering)">top</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#toString()">toString</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#union(org.apache.spark.rdd.RDD)">union</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#unpersist(boolean)">unpersist</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zip(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">zip</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, boolean, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipWithIndex()">zipWithIndex</a>, <a href="../../../../../org/apache/spark/rdd/RDD.html#zipWithUniqueId()">zipWithUniqueId</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/Logging.html#initialized()">initialized</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../../org/apache/spark/Logging.html#initLock()">initLock</a>, <a href="../../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="JsonTable(org.apache.spark.sql.SQLContext, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>JsonTable</h4>
<pre>public&nbsp;JsonTable(<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext,
         org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
         <a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;baseRDD,
         org.apache.spark.sql.catalyst.types.StructType&nbsp;baseSchema)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="sqlContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sqlContext</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SchemaRDD.html#sqlContext()">sqlContext</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></dd>
</dl>
</li>
</ul>
<a name="unionAll(org.apache.spark.sql.json.JsonTable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unionAll</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/json/JsonTable.html" title="class in org.apache.spark.sql.json">JsonTable</a>&nbsp;unionAll(<a href="../../../../../org/apache/spark/sql/json/JsonTable.html" title="class in org.apache.spark.sql.json">JsonTable</a>&nbsp;otherPlan)</pre>
<div class="block">Combines the tuples of two JsonTables and union their schemas, keeping duplicates.
 <p></div>
</li>
</ul>
<a name="queryExecution()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>queryExecution</h4>
<pre>public&nbsp;org.apache.spark.sql.SQLContext.QueryExecution&nbsp;queryExecution()</pre>
<div class="block">:: DeveloperApi ::
 A lazily computed query execution workflow.  All other RDD operations are passed
 through to the RDD that is produced by this workflow. This workflow is produced lazily because
 invoking the whole query optimization pipeline can be expensive.
 <p>
 The query execution is considered a Developer API as phases may be added or removed in future
 releases.  This execution is only exposed to provide an interface for inspecting the various
 phases for debugging purposes.  Applications should not depend on particular phases existing
 or producing any specific output, even for exactly the same query.
 <p>
 Additionally, the RDD exposed by this execution is not designed for consumption by end users.
 In particular, it does not contain any schema information, and it reuses Row objects
 internally.  This object reuse improves performance, but can make programming against the RDD
 more difficult.  Instead end users should perform RDD operations on a SchemaRDD directly.</div>
</li>
</ul>
<a name="toString()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toString</h4>
<pre>public&nbsp;String&nbsp;toString()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code>toString</code>&nbsp;in class&nbsp;<code>Object</code></dd>
</dl>
</li>
</ul>
<a name="saveAsParquetFile(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsParquetFile</h4>
<pre>public&nbsp;void&nbsp;saveAsParquetFile(String&nbsp;path)</pre>
<div class="block">Saves the contents of this <code>SchemaRDD</code> as a parquet file, preserving the schema.  Files that
 are written out using this method can be read back in as a SchemaRDD using the <code>parquetFile</code>
 function.
 <p></div>
</li>
</ul>
<a name="registerAsTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>registerAsTable</h4>
<pre>public&nbsp;void&nbsp;registerAsTable(String&nbsp;tableName)</pre>
<div class="block">Registers this RDD as a temporary table using the given name.  The lifetime of this temporary
 table is tied to the <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a> that was used to create this SchemaRDD.
 <p></div>
</li>
</ul>
<a name="insertInto(java.lang.String, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>insertInto</h4>
<pre>public&nbsp;void&nbsp;insertInto(String&nbsp;tableName,
              boolean&nbsp;overwrite)</pre>
<div class="block">:: Experimental ::
 Adds the rows from this RDD to the specified table, optionally overwriting the existing data.
 <p></div>
</li>
</ul>
<a name="insertInto(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>insertInto</h4>
<pre>public&nbsp;void&nbsp;insertInto(String&nbsp;tableName)</pre>
<div class="block">:: Experimental ::
 Appends the rows from this RDD to the specified table.
 <p></div>
</li>
</ul>
<a name="saveAsTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsTable</h4>
<pre>public&nbsp;void&nbsp;saveAsTable(String&nbsp;tableName)</pre>
<div class="block">:: Experimental ::
 Creates a table from the the contents of this SchemaRDD.  This will fail if the table already
 exists.
 <p>
 Note that this currently only works with SchemaRDDs that are created from a HiveContext as
 there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
 an RDD out to a parquet file, and then register that file as a table.  This "table" can then
 be the target of an <code>insertInto</code>.
 <p></div>
</li>
</ul>
<a name="printSchema()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>printSchema</h4>
<pre>public&nbsp;void&nbsp;printSchema()</pre>
<div class="block">Print the schema of this SchemaRDD.</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/json/JsonSuite.html" title="class in org.apache.spark.sql.json"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/json/TestJsonData.html" title="class in org.apache.spark.sql.json"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/json/JsonTable.html" target="_top">Frames</a></li>
<li><a href="JsonTable.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
