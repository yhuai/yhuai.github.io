<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_55) on Sun Jul 27 17:10:03 PDT 2014 -->
<title>PairRDDFunctions (Spark 1.1.0 JavaDoc)</title>
<meta name="date" content="2014-07-27">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="PairRDDFunctions (Spark 1.1.0 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/PairRDDFunctions.html" target="_top">Frames</a></li>
<li><a href="PairRDDFunctions.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.rdd</div>
<h2 title="Class PairRDDFunctions" class="title">Class PairRDDFunctions&lt;K,V&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.rdd.PairRDDFunctions&lt;K,V&gt;</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">PairRDDFunctions&lt;K,V&gt;</span>
extends Object
implements <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, scala.Serializable</pre>
<div class="block">Extra functions available on RDDs of (key, value) pairs through an implicit conversion.
 Import <code>org.apache.spark.SparkContext._</code> at the top of your program to use these functions.</div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.rdd.PairRDDFunctions">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#PairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">PairRDDFunctions</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;self,
                scala.reflect.ClassTag&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&gt;&nbsp;kt,
                scala.reflect.ClassTag&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;vt,
                scala.math.Ordering&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregateByKey</a></strong>(U&nbsp;zeroValue,
              scala.Function2&lt;U,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;seqOp,
              scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
              scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$3)</code>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, int, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregateByKey</a></strong>(U&nbsp;zeroValue,
              int&nbsp;numPartitions,
              scala.Function2&lt;U,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;seqOp,
              scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
              scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$2)</code>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, org.apache.spark.Partitioner, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregateByKey</a></strong>(U&nbsp;zeroValue,
              <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
              scala.Function2&lt;U,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;seqOp,
              scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
              scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</code>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</code>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, int)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
       int&nbsp;numPartitions)</code>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
       <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2)</code>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
       int&nbsp;numPartitions)</code>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
       <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3,
       int&nbsp;numPartitions)</code>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">cogroup</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
       <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3,
       <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#collectAsMap()">collectAsMap</a></strong>()</code>
<div class="block">Return the key-value pairs in this RDD to the master as a Map.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;C&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,C&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2)">combineByKey</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;createCombiner,
            scala.Function2&lt;C,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;mergeValue,
            scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiners)</code>
<div class="block">Simplified version of combineByKey that hash-partitions the resulting RDD using the
 existing partitioner/parallelism level.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;C&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,C&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, int)">combineByKey</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;createCombiner,
            scala.Function2&lt;C,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;mergeValue,
            scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiners,
            int&nbsp;numPartitions)</code>
<div class="block">Simplified version of combineByKey that hash-partitions the output RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;C&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,C&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, org.apache.spark.serializer.Serializer)">combineByKey</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;createCombiner,
            scala.Function2&lt;C,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;mergeValue,
            scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiners,
            <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
            boolean&nbsp;mapSideCombine,
            <a href="../../../../org/apache/spark/serializer/Serializer.html" title="interface in org.apache.spark.serializer">Serializer</a>&nbsp;serializer)</code>
<div class="block">Generic function to combine the elements for each key using a custom set of aggregation
 functions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double)">countApproxDistinctByKey</a></strong>(double&nbsp;relativeSD)</code>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double, int)">countApproxDistinctByKey</a></strong>(double&nbsp;relativeSD,
                        int&nbsp;numPartitions)</code>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double, org.apache.spark.Partitioner)">countApproxDistinctByKey</a></strong>(double&nbsp;relativeSD,
                        <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(int, int, org.apache.spark.Partitioner)">countApproxDistinctByKey</a></strong>(int&nbsp;p,
                        int&nbsp;sp,
                        <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">:: Experimental ::</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#countByKey()">countByKey</a></strong>()</code>
<div class="block">Count the number of elements for each key, and return the result to the master as a Map.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a>&lt;scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#countByKeyApprox(long, double)">countByKeyApprox</a></strong>(long&nbsp;timeout,
                double&nbsp;confidence)</code>
<div class="block">:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#flatMapValues(scala.Function1)">flatMapValues</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;f)</code>
<div class="block">Pass each value in the key-value pair RDD through a flatMap function without changing the
 keys; this also retains the original RDD's partitioning.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, scala.Function2)">foldByKey</a></strong>(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&nbsp;zeroValue,
         scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</code>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, int, scala.Function2)">foldByKey</a></strong>(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&nbsp;zeroValue,
         int&nbsp;numPartitions,
         scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</code>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, org.apache.spark.Partitioner, scala.Function2)">foldByKey</a></strong>(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&nbsp;zeroValue,
         <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
         scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</code>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#groupByKey()">groupByKey</a></strong>()</code>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#groupByKey(int)">groupByKey</a></strong>(int&nbsp;numPartitions)</code>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#groupByKey(org.apache.spark.Partitioner)">groupByKey</a></strong>(<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD)">groupWith</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</code>
<div class="block">Alias for cogroup.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">groupWith</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
         <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2)</code>
<div class="block">Alias for cogroup.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">groupWith</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
         <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
         <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3)</code>
<div class="block">Alias for cogroup.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD)">join</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</code>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD, int)">join</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
    int&nbsp;numPartitions)</code>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">join</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
    <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#keys()">keys</a></strong>()</code>
<div class="block">Return an RDD with the keys of each tuple.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD)">leftOuterJoin</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</code>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD, int)">leftOuterJoin</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
             int&nbsp;numPartitions)</code>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">leftOuterJoin</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
             <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.Seq&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#lookup(K)">lookup</a></strong>(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&nbsp;key)</code>
<div class="block">Return the list of values in the RDD for key <code>key</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#mapValues(scala.Function1)">mapValues</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;f)</code>
<div class="block">Pass each value in the key-value pair RDD through a map function without changing the keys;
 this also retains the original RDD's partitioning.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#partitionBy(org.apache.spark.Partitioner)">partitionBy</a></strong>(<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Return a copy of the RDD partitioned using the specified partitioner.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(scala.Function2)">reduceByKey</a></strong>(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</code>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(scala.Function2, int)">reduceByKey</a></strong>(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func,
           int&nbsp;numPartitions)</code>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(org.apache.spark.Partitioner, scala.Function2)">reduceByKey</a></strong>(<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
           scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</code>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#reduceByKeyLocally(scala.Function2)">reduceByKeyLocally</a></strong>(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</code>
<div class="block">Merge the values for each key using an associative reduce function, but return the results
 immediately to the master as a Map.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#reduceByKeyToDriver(scala.Function2)">reduceByKeyToDriver</a></strong>(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</code>
<div class="block">Alias for reduceByKeyLocally</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD)">rightOuterJoin</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</code>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD, int)">rightOuterJoin</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
              int&nbsp;numPartitions)</code>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">rightOuterJoin</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
              <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf)">saveAsHadoopDataset</a></strong>(org.apache.hadoop.mapred.JobConf&nbsp;conf)</code>
<div class="block">Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
 that storage system.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class)">saveAsHadoopFile</a></strong>(String&nbsp;path,
                Class&lt;?&gt;&nbsp;keyClass,
                Class&lt;?&gt;&nbsp;valueClass,
                Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec)</code>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf, scala.Option)">saveAsHadoopFile</a></strong>(String&nbsp;path,
                Class&lt;?&gt;&nbsp;keyClass,
                Class&lt;?&gt;&nbsp;valueClass,
                Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                org.apache.hadoop.mapred.JobConf&nbsp;conf,
                scala.Option&lt;Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&gt;&nbsp;codec)</code>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;<br>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, scala.reflect.ClassTag)">saveAsHadoopFile</a></strong>(String&nbsp;path,
                Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec,
                scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</code>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;<br>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, scala.reflect.ClassTag)">saveAsHadoopFile</a></strong>(String&nbsp;path,
                scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</code>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopDataset(org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopDataset</a></strong>(org.apache.hadoop.conf.Configuration&nbsp;conf)</code>
<div class="block">Output the RDD to any Hadoop-supported storage system with new Hadoop API, using a Hadoop
 Configuration object for that storage system.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopFile</a></strong>(String&nbsp;path,
                      Class&lt;?&gt;&nbsp;keyClass,
                      Class&lt;?&gt;&nbsp;valueClass,
                      Class&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                      org.apache.hadoop.conf.Configuration&nbsp;conf)</code>
<div class="block">Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;<br>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopFile(java.lang.String, scala.reflect.ClassTag)">saveAsNewAPIHadoopFile</a></strong>(String&nbsp;path,
                      scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</code>
<div class="block">Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">subtractByKey</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$4)</code>
<div class="block">Return an RDD with the pairs from <code>this</code> whose keys are not in <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, int, scala.reflect.ClassTag)">subtractByKey</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
             int&nbsp;numPartitions,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$5)</code>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.reflect.ClassTag)">subtractByKey</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
             <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$6)</code>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html#values()">values</a></strong>()</code>
<div class="block">Return an RDD with the values of each tuple.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../org/apache/spark/Logging.html#initialized()">initialized</a>, <a href="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../org/apache/spark/Logging.html#initLock()">initLock</a>, <a href="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="PairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>PairRDDFunctions</h4>
<pre>public&nbsp;PairRDDFunctions(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;self,
                scala.reflect.ClassTag&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&gt;&nbsp;kt,
                scala.reflect.ClassTag&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;vt,
                scala.math.Ordering&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&gt;&nbsp;ord)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, org.apache.spark.serializer.Serializer)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>combineByKey</h4>
<pre>public&nbsp;&lt;C&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,C&gt;&gt;&nbsp;combineByKey(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;createCombiner,
                                      scala.Function2&lt;C,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;mergeValue,
                                      scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiners,
                                      <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                      boolean&nbsp;mapSideCombine,
                                      <a href="../../../../org/apache/spark/serializer/Serializer.html" title="interface in org.apache.spark.serializer">Serializer</a>&nbsp;serializer)</pre>
<div class="block">Generic function to combine the elements for each key using a custom set of aggregation
 functions. Turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a "combined type" C
 Note that V and C can be different -- for example, one might group an RDD of type
 (Int, Int) into an RDD of type (Int, Seq[Int]). Users provide three functions:
 <p>
 - <code>createCombiner</code>, which turns a V into a C (e.g., creates a one-element list)
 - <code>mergeValue</code>, to merge a V into a C (e.g., adds it to the end of a list)
 - <code>mergeCombiners</code>, to combine two C's into a single one.
 <p>
 In addition, users can control the partitioning of the output RDD, and whether to perform
 map-side aggregation (if a mapper can produce multiple items with the same key).</div>
</li>
</ul>
<a name="combineByKey(scala.Function1, scala.Function2, scala.Function2, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>combineByKey</h4>
<pre>public&nbsp;&lt;C&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,C&gt;&gt;&nbsp;combineByKey(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;createCombiner,
                                      scala.Function2&lt;C,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;mergeValue,
                                      scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiners,
                                      int&nbsp;numPartitions)</pre>
<div class="block">Simplified version of combineByKey that hash-partitions the output RDD.</div>
</li>
</ul>
<a name="aggregateByKey(java.lang.Object,org.apache.spark.Partitioner,scala.Function2,scala.Function2,scala.reflect.ClassTag)">
<!--   -->
</a><a name="aggregateByKey(U, org.apache.spark.Partitioner, scala.Function2, scala.Function2, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>aggregateByKey</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;&nbsp;aggregateByKey(U&nbsp;zeroValue,
                                        <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                        scala.Function2&lt;U,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;seqOp,
                                        scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
                                        scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</pre>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".
 This function can return a different result type, U, than the type of the values in this RDD,
 V. Thus, we need one operation for merging a V into a U and one operation for merging two U's,
 as in scala.TraversableOnce. The former operation is used for merging values within a
 partition, and the latter is used for merging values between partitions. To avoid memory
 allocation, both of these functions are allowed to modify and return their first argument
 instead of creating a new U.</div>
</li>
</ul>
<a name="aggregateByKey(java.lang.Object,int,scala.Function2,scala.Function2,scala.reflect.ClassTag)">
<!--   -->
</a><a name="aggregateByKey(U, int, scala.Function2, scala.Function2, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>aggregateByKey</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;&nbsp;aggregateByKey(U&nbsp;zeroValue,
                                        int&nbsp;numPartitions,
                                        scala.Function2&lt;U,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;seqOp,
                                        scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
                                        scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$2)</pre>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".
 This function can return a different result type, U, than the type of the values in this RDD,
 V. Thus, we need one operation for merging a V into a U and one operation for merging two U's,
 as in scala.TraversableOnce. The former operation is used for merging values within a
 partition, and the latter is used for merging values between partitions. To avoid memory
 allocation, both of these functions are allowed to modify and return their first argument
 instead of creating a new U.</div>
</li>
</ul>
<a name="aggregateByKey(java.lang.Object,scala.Function2,scala.Function2,scala.reflect.ClassTag)">
<!--   -->
</a><a name="aggregateByKey(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>aggregateByKey</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;&nbsp;aggregateByKey(U&nbsp;zeroValue,
                                        scala.Function2&lt;U,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;seqOp,
                                        scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
                                        scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$3)</pre>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".
 This function can return a different result type, U, than the type of the values in this RDD,
 V. Thus, we need one operation for merging a V into a U and one operation for merging two U's,
 as in scala.TraversableOnce. The former operation is used for merging values within a
 partition, and the latter is used for merging values between partitions. To avoid memory
 allocation, both of these functions are allowed to modify and return their first argument
 instead of creating a new U.</div>
</li>
</ul>
<a name="foldByKey(java.lang.Object,org.apache.spark.Partitioner,scala.Function2)">
<!--   -->
</a><a name="foldByKey(V, org.apache.spark.Partitioner, scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foldByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;foldByKey(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&nbsp;zeroValue,
                               <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                               scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</pre>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</li>
</ul>
<a name="foldByKey(java.lang.Object,int,scala.Function2)">
<!--   -->
</a><a name="foldByKey(V, int, scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foldByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;foldByKey(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&nbsp;zeroValue,
                               int&nbsp;numPartitions,
                               scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</pre>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</li>
</ul>
<a name="foldByKey(java.lang.Object,scala.Function2)">
<!--   -->
</a><a name="foldByKey(V, scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foldByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;foldByKey(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&nbsp;zeroValue,
                               scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</pre>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</li>
</ul>
<a name="reduceByKey(org.apache.spark.Partitioner, scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;reduceByKey(<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                 scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</pre>
<div class="block">Merge the values for each key using an associative reduce function. This will also perform
 the merging locally on each mapper before sending results to a reducer, similarly to a
 "combiner" in MapReduce.</div>
</li>
</ul>
<a name="reduceByKeyLocally(scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyLocally</h4>
<pre>public&nbsp;scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;reduceByKeyLocally(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</pre>
<div class="block">Merge the values for each key using an associative reduce function, but return the results
 immediately to the master as a Map. This will also perform the merging locally on each mapper
 before sending results to a reducer, similarly to a "combiner" in MapReduce.</div>
</li>
</ul>
<a name="reduceByKeyToDriver(scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyToDriver</h4>
<pre>public&nbsp;scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;reduceByKeyToDriver(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</pre>
<div class="block">Alias for reduceByKeyLocally</div>
</li>
</ul>
<a name="countByKey()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countByKey</h4>
<pre>public&nbsp;scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&nbsp;countByKey()</pre>
<div class="block">Count the number of elements for each key, and return the result to the master as a Map.</div>
</li>
</ul>
<a name="countByKeyApprox(long, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countByKeyApprox</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a>&lt;scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a>&gt;&gt;&nbsp;countByKeyApprox(long&nbsp;timeout,
                                                                    double&nbsp;confidence)</pre>
<div class="block">:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.</div>
</li>
</ul>
<a name="countApproxDistinctByKey(int, int, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApproxDistinctByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;&nbsp;countApproxDistinctByKey(int&nbsp;p,
                                                   int&nbsp;sp,
                                                   <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">:: Experimental ::
 <p>
 Return approximate number of distinct values for each key in this RDD.
 <p>
 The algorithm used is based on streamlib's implementation of "HyperLogLog in Practice:
 Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm", available
 <a href="http://dx.doi.org/10.1145/2452376.2452456">here</a>.
 <p>
 The relative accuracy is approximately <code>1.054 / sqrt(2^p)</code>. Setting a nonzero <code>sp > p</code>
 would trigger sparse representation of registers, which may reduce the memory consumption
 and increase accuracy when the cardinality is small.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>p</code> - The precision value for the normal set.
          <code>p</code> must be a value between 4 and <code>sp</code> if <code>sp</code> is not zero (32 max).</dd><dd><code>sp</code> - The precision value for the sparse set, between 0 and 32.
           If <code>sp</code> equals 0, the sparse representation is skipped.</dd><dd><code>partitioner</code> - Partitioner to use for the resulting RDD.</dd></dl>
</li>
</ul>
<a name="countApproxDistinctByKey(double, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApproxDistinctByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;&nbsp;countApproxDistinctByKey(double&nbsp;relativeSD,
                                                   <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Return approximate number of distinct values for each key in this RDD.
 <p>
 The algorithm used is based on streamlib's implementation of "HyperLogLog in Practice:
 Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm", available
 <a href="http://dx.doi.org/10.1145/2452376.2452456">here</a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>relativeSD</code> - Relative accuracy. Smaller values create counters that require more space.
                   It must be greater than 0.000017.</dd><dd><code>partitioner</code> - partitioner of the resulting RDD</dd></dl>
</li>
</ul>
<a name="countApproxDistinctByKey(double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApproxDistinctByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;&nbsp;countApproxDistinctByKey(double&nbsp;relativeSD,
                                                   int&nbsp;numPartitions)</pre>
<div class="block">Return approximate number of distinct values for each key in this RDD.
 <p>
 The algorithm used is based on streamlib's implementation of "HyperLogLog in Practice:
 Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm", available
 <a href="http://dx.doi.org/10.1145/2452376.2452456">here</a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>relativeSD</code> - Relative accuracy. Smaller values create counters that require more space.
                   It must be greater than 0.000017.</dd><dd><code>numPartitions</code> - number of partitions of the resulting RDD</dd></dl>
</li>
</ul>
<a name="countApproxDistinctByKey(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApproxDistinctByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,Object&gt;&gt;&nbsp;countApproxDistinctByKey(double&nbsp;relativeSD)</pre>
<div class="block">Return approximate number of distinct values for each key in this RDD.
 <p>
 The algorithm used is based on streamlib's implementation of "HyperLogLog in Practice:
 Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm", available
 <a href="http://dx.doi.org/10.1145/2452376.2452456">here</a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>relativeSD</code> - Relative accuracy. Smaller values create counters that require more space.
                   It must be greater than 0.000017.</dd></dl>
</li>
</ul>
<a name="reduceByKey(scala.Function2, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;reduceByKey(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func,
                                 int&nbsp;numPartitions)</pre>
<div class="block">Merge the values for each key using an associative reduce function. This will also perform
 the merging locally on each mapper before sending results to a reducer, similarly to a
 "combiner" in MapReduce. Output will be hash-partitioned with numPartitions partitions.</div>
</li>
</ul>
<a name="groupByKey(org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKey(<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Group the values for each key in the RDD into a single sequence. Allows controlling the
 partitioning of the resulting key-value pair RDD by passing a Partitioner.
 <p>
 Note: This operation may be very expensive. If you are grouping in order to perform an
 aggregation (such as a sum or average) over each key, using <code>PairRDDFunctions.aggregateByKey</code>
 or <code>PairRDDFunctions.reduceByKey</code> will provide much better performance.</div>
</li>
</ul>
<a name="groupByKey(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKey(int&nbsp;numPartitions)</pre>
<div class="block">Group the values for each key in the RDD into a single sequence. Hash-partitions the
 resulting RDD with into <code>numPartitions</code> partitions.
 <p>
 Note: This operation may be very expensive. If you are grouping in order to perform an
 aggregation (such as a sum or average) over each key, using <code>PairRDDFunctions.aggregateByKey</code>
 or <code>PairRDDFunctions.reduceByKey</code> will provide much better performance.</div>
</li>
</ul>
<a name="partitionBy(org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionBy</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;partitionBy(<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Return a copy of the RDD partitioned using the specified partitioner.</div>
</li>
</ul>
<a name="join(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>join</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,W&gt;&gt;&gt;&nbsp;join(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                              <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>. Each
 pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in <code>this</code> and
 (k, v2) is in <code>other</code>. Uses the given Partitioner to partition the output RDD.</div>
</li>
</ul>
<a name="leftOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>leftOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;leftOuterJoin(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                     <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>. For each element (k, v) in <code>this</code>, the
 resulting RDD will either contain all pairs (k, (v, Some(w))) for w in <code>other</code>, or the
 pair (k, (v, None)) if no elements in <code>other</code> have key k. Uses the given Partitioner to
 partition the output RDD.</div>
</li>
</ul>
<a name="rightOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rightOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,W&gt;&gt;&gt;&nbsp;rightOuterJoin(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                      <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>. For each element (k, w) in <code>other</code>, the
 resulting RDD will either contain all pairs (k, (Some(v), w)) for v in <code>this</code>, or the
 pair (k, (None, w)) if no elements in <code>this</code> have key k. Uses the given Partitioner to
 partition the output RDD.</div>
</li>
</ul>
<a name="combineByKey(scala.Function1, scala.Function2, scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>combineByKey</h4>
<pre>public&nbsp;&lt;C&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,C&gt;&gt;&nbsp;combineByKey(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;createCombiner,
                                      scala.Function2&lt;C,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,C&gt;&nbsp;mergeValue,
                                      scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiners)</pre>
<div class="block">Simplified version of combineByKey that hash-partitions the resulting RDD using the
 existing partitioner/parallelism level.</div>
</li>
</ul>
<a name="reduceByKey(scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;reduceByKey(scala.Function2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;func)</pre>
<div class="block">Merge the values for each key using an associative reduce function. This will also perform
 the merging locally on each mapper before sending results to a reducer, similarly to a
 "combiner" in MapReduce. Output will be hash-partitioned with the existing partitioner/
 parallelism level.</div>
</li>
</ul>
<a name="groupByKey()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKey</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKey()</pre>
<div class="block">Group the values for each key in the RDD into a single sequence. Hash-partitions the
 resulting RDD with the existing partitioner/parallelism level.
 <p>
 Note: This operation may be very expensive. If you are grouping in order to perform an
 aggregation (such as a sum or average) over each key, using <code>PairRDDFunctions.aggregateByKey</code>
 or <code>PairRDDFunctions.reduceByKey</code> will provide much better performance.</div>
</li>
</ul>
<a name="join(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>join</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,W&gt;&gt;&gt;&nbsp;join(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</pre>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>. Each
 pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in <code>this</code> and
 (k, v2) is in <code>other</code>. Performs a hash join across the cluster.</div>
</li>
</ul>
<a name="join(org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>join</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,W&gt;&gt;&gt;&nbsp;join(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                              int&nbsp;numPartitions)</pre>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>. Each
 pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in <code>this</code> and
 (k, v2) is in <code>other</code>. Performs a hash join across the cluster.</div>
</li>
</ul>
<a name="leftOuterJoin(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>leftOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;leftOuterJoin(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</pre>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>. For each element (k, v) in <code>this</code>, the
 resulting RDD will either contain all pairs (k, (v, Some(w))) for w in <code>other</code>, or the
 pair (k, (v, None)) if no elements in <code>other</code> have key k. Hash-partitions the output
 using the existing partitioner/parallelism level.</div>
</li>
</ul>
<a name="leftOuterJoin(org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>leftOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;leftOuterJoin(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                     int&nbsp;numPartitions)</pre>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>. For each element (k, v) in <code>this</code>, the
 resulting RDD will either contain all pairs (k, (v, Some(w))) for w in <code>other</code>, or the
 pair (k, (v, None)) if no elements in <code>other</code> have key k. Hash-partitions the output
 into <code>numPartitions</code> partitions.</div>
</li>
</ul>
<a name="rightOuterJoin(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rightOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,W&gt;&gt;&gt;&nbsp;rightOuterJoin(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</pre>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>. For each element (k, w) in <code>other</code>, the
 resulting RDD will either contain all pairs (k, (Some(v), w)) for v in <code>this</code>, or the
 pair (k, (None, w)) if no elements in <code>this</code> have key k. Hash-partitions the resulting
 RDD using the existing partitioner/parallelism level.</div>
</li>
</ul>
<a name="rightOuterJoin(org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rightOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,W&gt;&gt;&gt;&nbsp;rightOuterJoin(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                      int&nbsp;numPartitions)</pre>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>. For each element (k, w) in <code>other</code>, the
 resulting RDD will either contain all pairs (k, (Some(v), w)) for v in <code>this</code>, or the
 pair (k, (None, w)) if no elements in <code>this</code> have key k. Hash-partitions the resulting
 RDD into the given number of partitions.</div>
</li>
</ul>
<a name="collectAsMap()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>collectAsMap</h4>
<pre>public&nbsp;scala.collection.Map&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;collectAsMap()</pre>
<div class="block">Return the key-value pairs in this RDD to the master as a Map.</div>
</li>
</ul>
<a name="mapValues(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapValues</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;&nbsp;mapValues(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,U&gt;&nbsp;f)</pre>
<div class="block">Pass each value in the key-value pair RDD through a map function without changing the keys;
 this also retains the original RDD's partitioning.</div>
</li>
</ul>
<a name="flatMapValues(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flatMapValues</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,U&gt;&gt;&nbsp;flatMapValues(scala.Function1&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;f)</pre>
<div class="block">Pass each value in the key-value pair RDD through a flatMap function without changing the
 keys; this also retains the original RDD's partitioning.</div>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
                                                                                                                                                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3,
                                                                                                                                                                           <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                       <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                          <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
                                                                                                                                          <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
                                                                                                                                                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3)</pre>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</pre>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                          <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2)</pre>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                       int&nbsp;numPartitions)</pre>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                          <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
                                                                                                                                          int&nbsp;numPartitions)</pre>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</li>
</ul>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
                                                                                                                                                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3,
                                                                                                                                                                           int&nbsp;numPartitions)</pre>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</li>
</ul>
<a name="groupWith(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupWith</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;&nbsp;groupWith(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other)</pre>
<div class="block">Alias for cogroup.</div>
</li>
</ul>
<a name="groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupWith</h4>
<pre>public&nbsp;&lt;W1,W2&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple3&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;&gt;&gt;&gt;&nbsp;groupWith(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                            <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2)</pre>
<div class="block">Alias for cogroup.</div>
</li>
</ul>
<a name="groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupWith</h4>
<pre>public&nbsp;&lt;W1,W2,W3&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,scala.Tuple4&lt;scala.collection.Iterable&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;,scala.collection.Iterable&lt;W1&gt;,scala.collection.Iterable&lt;W2&gt;,scala.collection.Iterable&lt;W3&gt;&gt;&gt;&gt;&nbsp;groupWith(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W1&gt;&gt;&nbsp;other1,
                                                                                                                                                                             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W2&gt;&gt;&nbsp;other2,
                                                                                                                                                                             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W3&gt;&gt;&nbsp;other3)</pre>
<div class="block">Alias for cogroup.</div>
</li>
</ul>
<a name="subtractByKey(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtractByKey</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;subtractByKey(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                       scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$4)</pre>
<div class="block">Return an RDD with the pairs from <code>this</code> whose keys are not in <code>other</code>.
 <p>
 Uses <code>this</code> partitioner/partition size, because even if <code>other</code> is huge, the resulting
 RDD will be <= us.</div>
</li>
</ul>
<a name="subtractByKey(org.apache.spark.rdd.RDD, int, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtractByKey</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;subtractByKey(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                       int&nbsp;numPartitions,
                                       scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$5)</pre>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</li>
</ul>
<a name="subtractByKey(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtractByKey</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;subtractByKey(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                       <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
                                       scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$6)</pre>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</li>
</ul>
<a name="lookup(java.lang.Object)">
<!--   -->
</a><a name="lookup(K)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>lookup</h4>
<pre>public&nbsp;scala.collection.Seq&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;lookup(<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&nbsp;key)</pre>
<div class="block">Return the list of values in the RDD for key <code>key</code>. This operation is done efficiently if the
 RDD has a known partitioner by only searching the partition that the key maps to.</div>
</li>
</ul>
<a name="saveAsHadoopFile(java.lang.String, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsHadoopFile</h4>
<pre>public&nbsp;&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;void&nbsp;saveAsHadoopFile(String&nbsp;path,
                                                                           scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</pre>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</li>
</ul>
<a name="saveAsHadoopFile(java.lang.String, java.lang.Class, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsHadoopFile</h4>
<pre>public&nbsp;&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;void&nbsp;saveAsHadoopFile(String&nbsp;path,
                                                                           Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec,
                                                                           scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</pre>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD. Compress the result with the
 supplied codec.</div>
</li>
</ul>
<a name="saveAsNewAPIHadoopFile(java.lang.String, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsNewAPIHadoopFile</h4>
<pre>public&nbsp;&lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&gt;&nbsp;void&nbsp;saveAsNewAPIHadoopFile(String&nbsp;path,
                                                                                    scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</pre>
<div class="block">Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.</div>
</li>
</ul>
<a name="saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsNewAPIHadoopFile</h4>
<pre>public&nbsp;void&nbsp;saveAsNewAPIHadoopFile(String&nbsp;path,
                          Class&lt;?&gt;&nbsp;keyClass,
                          Class&lt;?&gt;&nbsp;valueClass,
                          Class&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                          org.apache.hadoop.conf.Configuration&nbsp;conf)</pre>
<div class="block">Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.</div>
</li>
</ul>
<a name="saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsHadoopFile</h4>
<pre>public&nbsp;void&nbsp;saveAsHadoopFile(String&nbsp;path,
                    Class&lt;?&gt;&nbsp;keyClass,
                    Class&lt;?&gt;&nbsp;valueClass,
                    Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                    Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec)</pre>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD. Compress with the supplied codec.</div>
</li>
</ul>
<a name="saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf, scala.Option)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsHadoopFile</h4>
<pre>public&nbsp;void&nbsp;saveAsHadoopFile(String&nbsp;path,
                    Class&lt;?&gt;&nbsp;keyClass,
                    Class&lt;?&gt;&nbsp;valueClass,
                    Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                    org.apache.hadoop.mapred.JobConf&nbsp;conf,
                    scala.Option&lt;Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&gt;&nbsp;codec)</pre>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</li>
</ul>
<a name="saveAsNewAPIHadoopDataset(org.apache.hadoop.conf.Configuration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsNewAPIHadoopDataset</h4>
<pre>public&nbsp;void&nbsp;saveAsNewAPIHadoopDataset(org.apache.hadoop.conf.Configuration&nbsp;conf)</pre>
<div class="block">Output the RDD to any Hadoop-supported storage system with new Hadoop API, using a Hadoop
 Configuration object for that storage system. The Conf should set an OutputFormat and any
 output paths required (e.g. a table name to write to) in the same way as it would be
 configured for a Hadoop MapReduce job.</div>
</li>
</ul>
<a name="saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsHadoopDataset</h4>
<pre>public&nbsp;void&nbsp;saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf&nbsp;conf)</pre>
<div class="block">Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
 that storage system. The JobConf should set an OutputFormat and any output paths required
 (e.g. a table name to write to) in the same way as it would be configured for a Hadoop
 MapReduce job.</div>
</li>
</ul>
<a name="keys()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>keys</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>&gt;&nbsp;keys()</pre>
<div class="block">Return an RDD with the keys of each tuple.</div>
</li>
</ul>
<a name="values()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>values</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt;&nbsp;values()</pre>
<div class="block">Return an RDD with the values of each tuple.</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/PairRDDFunctions.html" target="_top">Frames</a></li>
<li><a href="PairRDDFunctions.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
